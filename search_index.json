[["index.html", "Tidy Survey Book Preface Why read this book Structure of the book Software information and conventions Acknowledgments", " Tidy Survey Book Stephanie Zimmer, Rebecca J. Powell, and Isabella Velásquez 2023-05-22 Preface Hi there, this is my great book. Why read this book It is very important… Structure of the book Chapters 1 introduces a new topic, and … Software information and conventions I used the knitr package (Xie 2015) and the bookdown package (Xie 2022) to compile my book. My R session information is shown below: xfun::session_info() ## R version 4.2.2 (2022-10-31) ## Platform: x86_64-apple-darwin17.0 (64-bit) ## Running under: macOS Big Sur ... 10.16 ## ## Locale: en_US.UTF-8 / en_US.UTF-8 / en_US.UTF-8 / C / en_US.UTF-8 / en_US.UTF-8 ## ## Package version: ## askpass_1.1 backports_1.4.1 ## base64enc_0.1.3 bit_4.0.5 ## bit64_4.0.5 blob_1.2.3 ## bookdown_0.30 broom_1.0.4 ## bslib_0.4.1 cachem_1.0.6 ## callr_3.7.3 cellranger_1.1.0 ## class_7.3-21 classInt_0.4-8 ## cli_3.6.1 clipr_0.8.0 ## colorspace_2.0-3 commonmark_1.8.1 ## compiler_4.2.2 conflicted_1.2.0 ## cpp11_0.4.3 crayon_1.5.2 ## curl_4.3.3 data.table_1.14.6 ## DBI_1.1.3 dbplyr_2.3.2 ## DiagrammeR_1.0.9 digest_0.6.30 ## downloader_0.4 dplyr_1.1.2 ## dtplyr_1.2.2 e1071_1.7-12 ## ellipsis_0.3.2 evaluate_0.18 ## fansi_1.0.3 farver_2.1.1 ## fastmap_1.1.0 forcats_1.0.0 ## foreign_0.8-83 fs_1.6.1 ## gargle_1.2.1 generics_0.1.3 ## ggplot2_3.4.2 glue_1.6.2 ## googledrive_2.0.0 googlesheets4_1.0.1 ## graphics_4.2.2 grDevices_4.2.2 ## grid_4.2.2 gridExtra_2.3 ## gtable_0.3.1 haven_2.5.1 ## here_1.0.1 highr_0.9 ## hms_1.1.2 htmltools_0.5.5 ## htmlwidgets_1.6.2 httr_1.4.4 ## ids_1.0.1 igraph_1.3.5 ## influenceR_0.1.0.1 isoband_0.2.6 ## jquerylib_0.1.4 jsonlite_1.8.4 ## KernSmooth_2.23-20 knitr_1.41 ## labeling_0.4.2 lattice_0.20-45 ## lifecycle_1.0.3 lubridate_1.9.2 ## magrittr_2.0.3 maptools_1.1-5 ## markdown_1.6 MASS_7.3.58.1 ## Matrix_1.5-3 memoise_2.0.1 ## methods_4.2.2 mgcv_1.8.41 ## mime_0.12 minqa_1.2.5 ## mitools_2.4 modelr_0.1.10 ## munsell_0.5.0 nlme_3.1.160 ## numDeriv_2016.8.1.1 openssl_2.0.4 ## pillar_1.9.0 pkgconfig_2.0.3 ## prettyunits_1.1.1 processx_3.8.0 ## progress_1.2.2 proxy_0.4-27 ## ps_1.7.2 purrr_1.0.1 ## R6_2.5.1 ragg_1.2.5 ## rappdirs_0.3.3 RColorBrewer_1.1-3 ## Rcpp_1.0.9 readr_2.1.4 ## readxl_1.4.2 rematch_1.0.1 ## rematch2_2.1.2 renv_0.16.0 ## reprex_2.0.2 rgdal_1.6-6 ## rlang_1.1.0 rmarkdown_2.18 ## rprojroot_2.0.3 rstudioapi_0.14 ## rvest_1.0.3 s2_1.1.1 ## sass_0.4.5 scales_1.2.1 ## selectr_0.4.2 sf_1.0-9 ## sp_1.5-1 splines_4.2.2 ## srvyr_1.2.0 stats_4.2.2 ## stringi_1.7.8 stringr_1.5.0 ## survey_4.1-1 survival_3.4-0 ## sys_3.4.1 systemfonts_1.0.4 ## textshaping_0.3.6 tibble_3.2.1 ## tidycensus_1.3 tidyr_1.3.0 ## tidyselect_1.2.0 tidyverse_2.0.0 ## tigris_1.6.1 timechange_0.1.1 ## tinytex_0.42 tools_4.2.2 ## tzdb_0.3.0 units_0.8-0 ## utf8_1.2.2 utils_4.2.2 ## uuid_1.1-0 vctrs_0.6.2 ## viridis_0.6.2 viridisLite_0.4.1 ## visNetwork_2.1.2 vroom_1.6.0 ## webshot_0.5.4 withr_2.5.0 ## wk_0.7.0 xfun_0.35 ## xml2_1.3.3 yaml_2.3.6 Package names are in bold text (e.g., rmarkdown), and inline code and filenames are formatted in a typewriter font (e.g., knitr::knit('foo.Rmd')). Function names are followed by parentheses (e.g., bookdown::render_book()). Acknowledgments A lot of people helped me when I was writing the book. Frida Gomam on the Mars References "],["c01.html", "Chapter 1 Introduction", " Chapter 1 Introduction "],["c02.html", "Chapter 2 Overview of Surveys 2.1 Study Design 2.2 Data Collection 2.3 Post Survey Processing 2.4 This book", " Chapter 2 Overview of Surveys Creating and fielding surveys to provide estimates of a population are much more complex than simply adding a few questions to an online platform. Survey researchers can spend months, or even years, developing the study design, questions, and other methods for a single survey to ensure high quality data is collected. While this book focuses on the analysis methods of surveys, understanding the entire survey process can provide a better insight into what types of analyses should be conducted on the data. To gain a deeper understanding of survey design and implementation, there are many pieces of existing literature that we recommend reviewing in detail (e.g., {cite: Dillman book, Groves book, education book?, Tourangeau book, Asking Questions book?, Valliant, Dever, and Krauter book (for design) Biemer and Lyberg: Introduction to Survey Quality}). The survey life cycle starts with a research topic or question of interest (e.g., what impact does childhood trauma have on health outcomes later in life). Researchers typically review existing data sources to determine if data are already available that can answer this question, as this can result in reduced burden on respondents, cheaper research costs, and faster research outcomes. However, if existing data cannot answer the nuances of the research question, a survey can be used to capture the exact data that the researcher needs. When starting a survey, there are multiple things to consider including the study population, how the sample is selected, and the way the question is worded. However, each step and decision can impact how the results can be interpreted, specifically related to the types of error that can be introduced into the data. Generally, survey researchers consider there to be 7 main sources of error ({Cite Groves book}): Representation Coverage Error: A mismatch between the target population (also known as the population of interest) and the sample frame available Sampling Error: Error produced when selecting a sample from the sample frame (none if conducting a census) Nonresponse Error: Differences between those who responded and did not respond to the survey (unit nonresponse) or to a given question (item nonresponse) Adjustment Error: Error introduced during post-survey statistical adjustments Measurement Validity: A mismatch between the topic of interest and the question used to collect that information Measurement Error: A mismatch between what the researcher asked and how the respondent answered Processing Error: Edits by the researcher to responses provided by the respondent (e.g., adjusts data based on illogical responses) Almost every survey conducted will have some of each of these types of error, and researchers attempt to conduct a survey that reduces this total survey error. One of the most common ways to reduce total survey error is through weighting. However, weighting may result in increased error on its own (adjustment error). Therefore when designing surveys, researchers should carefully think about ways to reduce each of these error sources. Additionally when analyzing survey data, understanding decisions that researchers took to minimize these error sources can impact how results are interpreted. The remainder of this chapter dives into considerations for survey development, places where each of these sources of error can be considered, and how these error sources can inform the interpretations of the data. 2.1 Study Design Study design is often used to encompass multiple parts of the survey planning process including decisions on target population, survey mode, and timeline. Multiple decisions made prior to the launch of the survey can assist researchers in reducing different error sources, and are fundamental in understanding how to interpret the results of the data. Knowing who and how to survey individuals depends on both the goals of the study and the feasibility of implementation. 2.1.1 Sampling Design Who we want to survey is known as the target population in the study. This could be broad, such as, “all adults age 18+ living in the U.S.”, or it could be a very specific target population based on a specific characteristic or location. For example, we may want to know about “adults age 18-24 who live in North Carolina” or “eligible voters living in Illinois”. However, to survey individuals in these target populations, a sampling frame is needed with contact information. If researchers are looking at eligible voters, the sampling frame could be the voting registry for a given state or area. For more broad target populations like all adults living in the U.S., the sampling frame will most likely be imperfect. In these cases, researchers may choose to use a sample frame of mailing addresses and send the survey to households, or they may choose to use random digit dialing (RDD) and call random phone numbers. These imperfect sampling frames can result in coverage error where there is a mismatch between the target population and the list of individuals researchers can select. For example, if a researcher is looking to obtain estimates for “all adults age 18+ living in the U.S.”, using a sample frame from mailing addresses will be missing specific types of individuals such as the homeless or transient populations. Additionally, many households have more than one adult living there, so researchers would need to consider how to get a specific individual to fill out the survey (called within household selection), or adjust the target population to report on “U.S. households” instead of “individuals”. Once the researchers have selected the sample frame, the next step is figuring out how to select individuals for the survey. In rare cases researchers may which to conduct a census and survey everyone on the sampling frame. However, the ability to implement a questionnaire at that scale is something few can do. Instead, researchers choose to sample individuals and use weights to estimate numbers in the target population. There are a variety of different sampling methods that can be used, and more information on these can be found in Chapter 5. This decision of which sampling method to use, impacts sampling error and can be adjusted for in weighting. Example: Number of Pets in a Household Let’s use a simple example where a researcher is interested in knowing the average number of pets in a household. Our researcher will need to consider what the target population is for this study. Specifically, are they interested in all of the U.S., a different country, or a more local area (e.g., city or state). Let’s assume our researcher is interested in the number of pets in a U.S. household where there is at least one adult living (18 years old or older). In this case, using a sampling frame of mailing addresses would provide the least amount of coverage error as the frame would closely match our target population. Specifically, our researcher would most likely want to use the Computerized Delivery Sequence File (CDSF), which is a file of mailing addresses that the United States Postal Service (USPS) creates and covers about 95% of U.S. households ({cite Iannichone}). To sample these households, for simplicity, we will use a stratified simple random sample design, where we stratify by state. Throughout this chapter we will build on this example research question to plan a survey. 2.1.2 Data Collection Planning With the sampling design decided, researchers can then make decisions on how to survey these individuals. Specifically, the modes used for contacting and surveying the sample, how frequently to send reminders and follow-ups, and the overall timeline of the study are four of the major data collection determinations. Traditionally, researchers have considered four main modes1 for conducting surveys: Computer Assisted Personal Interview (CAPI; also known as face-to-face or in-person interviewing) Computer Assisted Telephone Interview (CATI; also known as phone or telephone interviewing) Web (also known as Computer Assisted Web Interview or CAWI) Paper and Pencil (PAPI) Researchers can use a single mode to collect data, or multiple modes (also called mixed modes). Using mixed modes can allow for broader reach and can increase response rates depending on the target population ({CITE DeLeeuw mixed mode article}). For example, researchers could both call households to conduct a CATI survey and send mail with a PAPI survey to the household. Using both of these modes, reseachers could gain participation through the mail from individuals who do not pick up the phone to unknown numbers, or through the phone from individuals who do not open all of their mail. However, mode effects (where responses differ based on the mode of response) can be present in the data and may need to be considered during analysis. When selecting which mode, or modes, to use, understanding the unique aspects of the chosen target population and sampling frame will provide insight into how they can best be reached and engaged. For example, if we plan to survey adults age 18-24 who live in North Carolina, asking them to complete a survey using CATI (i.e., over the phone) would most likely not be as successful as other modes like web as this age group does not talk on the phone as much as other generations, and often do not answer their phones for unknown numbers. Additionally, the mode for contacting respondents relies on what information is available on the sample frame. For example, if our sampling frame includes email address, we could send email to our selected sample members to convince them to complete a survey. Or if the sampling frame is a list of mailing addresses, researchers would have to contact sample members with a letter. It is important to note that there can be a difference between the contact mode and the survey mode. For example, if we have a sample frame with addresses, we can send a letter to our sample members and provide information on how to complete a web survey. Or we could use mixed-mode surveys and send sample members a paper and pencil survey with our letter and also ask them to complete the survey online. Combining different contact modes and different survey modes can be useful in reducing unit nonresponse error, as different sample members may respond better to different contact and survey modes. However, when considering which modes to use, it is important to make access to the survey as easy as possible for sample members to reduce burden and unit nonresponse. Another way to reduce unit nonresponse error is though varying the language of the contact materials ({cite Dillman Book}). People are motivated by different things, so constantly repeating the same messaging may not be helpful. Instead, mixing up the messaging and the type of contact material the sample member receives can increase response rates and reduce unit nonresponse error. For example, instead of only sending standard letters, researchers could consider sending mailings that invoke “urgent” or “important” thoughts by sending priority letters, or using other delivery services like FedEx, UPS, or DHL. Determining the number and types of contacts may also be determined by a study timeline. If the timeline is long, then there is a lot of time for follow-ups and varying the message in contact materials. If the timeline is short, than fewer follow-ups can be implemented. Many studies will start with the tailored design method put forth by {Dillman et al. (2014)} and implement 5 contacts: (1) prenotice letting sample members know the survey is coming, (2) invitation to complete the survey, (3) reminder postcard that also thanks respondents that may have already completed the survey, (4) reminder letter (with a replacement paper survey if needed), and (5) final reminder postcard. This method is easily adaptable based on the study timeline and needs, but provides a good basis for most studies. Example: Number of Pets in a Household Let’s return to our example of a researcher who wants to know the average number of pets in a household. We are using a sample frame of mailing addresses, so we recommend starting our data collection with letters mailed to households, but later in data collection we want to send interviewers to the house to conduct an in-person (or CAPI) interview in an effort to decrease unit nonresponse error. This means we will have two contact modes (paper and in-person). As we mentioned above, the survey mode does not have to be the same as the contact mode, so we recommend a mixed-mode study with both Web and CAPI modes. Let’s assume we have 6 months for data collection, so we may want to recommend the following protocol: Protocol Example for 6-month Web and CAPI Data Collection Week Contact Mode Contact Message Survey Mode Offered 1 Mail: Letter Prenotice — 2 Mail: Letter Invitation Web 3 Mail: Postcard Thank You/Reminder Web 6 Mail: Letter in large envelope Animal Welfare Discussion Web 10 Mail: Postcard Inform Upcoming In-Person Visit Web 14 In-Person Visit — CAPI 16 Mail: Letter Reminder of In-Person Visit Web, but includes number to call to schedule CAPI 20 In-Person Visit — CAPI 25 Mail: Letter in large envelope Survey Closing Notice Web, but includes number to call to schedule CAPI This is just one possible protocol that could be used that starts respondents with web (typically done to reduce costs). However, researchers may want to start in-person data collection earlier during the data collection period, or ask their interviewers to attempt more than 2 visits with a household. 2.1.3 Questionnaire Design When developing the questionnaire, it can be helpful to first outline the topics to be asked and include the “why” each question or topic is important to the research question(s). This can help researchers better tailor the questionnaire and potentially reduce the number of questions (and thus burden on the respondent) if topics are deemed irrelevant to the research question. When making these decisions, researchers should also consider questions needed for weighting purposes. While we would love to have everyone sampled answer our survey, this is rarely the case. Thus, including questions about demographics in the survey can assist with weighting for nonresponse error (both unit and item nonresponse). Knowing details of the sampling plan and what may impact coverage error and sampling error can help guide researchers in determining what types of demographics to include. Researchers can benefit from the work of others by using questions from other surveys. This is common with demographic questions such as race and ethnicity that use questions from a government census or other official surveys. Other survey questions can be found using question banks which are a compilation of questions that have been asked across a variety of surveys such as the Inter-university Consortium for Political and Social Research (ICPSR) variable search. If a question does not already exist in a question bank, then researchers can craft their own. When creating their own questions, researchers should start with the research question or topic and attempt to write questions that match the concept. The closer the question asked is to the overall concept the better validity there is. For example, if the researcher wants to know how people consume TV series and movies, but only ask a question about how many TVs are in the house, then they would be missing other ways that people watch TV series and movies such as on other devices or at places outside of the home. Additionally, when designing questions, researchers should consider the mode the survey will be administered in and adjust language appropriately. In self-administered surveys (e.g., web or mail), respondents can see all of the questions and response options, but that is not the case in interviewer-administered surveys (e.g., CATI or CAPI). With interviewer-administered surveys, the response options need to be read out loud to the respondents, so the question may need to be adjusted to allow a better flow to the interview. Additionally, with self-administered surveys, because the respondents are viewing the questionnaire, the formatting of the questions is even more important to ensure accurate measurement. Incorrectly formatting or wording questions can result in measurement error, so following best practices or using existing validated questions can reduce error. There are multiple resources out there to help researchers draft questions for different modes (e.g., {CITE Dillman, fowler, ed book?, asking questions, tourangeau formatting article?}). Example: Number of Pets in a Household As part of our survey on the average number of pets in a household, researchers may want to know what animal the majority of people prefer to have as a pet. Let’s say we have the following question in our survey: What animal do you prefer to have as a pet? Dogs Cats This question may have validity issues as it is only providing the options of “dogs” and “cats” to respondents and interpretation of the data could be incorrect. For example, if we had 100 respondents who answered the question and 50 selected dogs, then the results of this question cannot be: 50% of the population perfers to have a dog as a pet as only two response options were provided. If a respondent taking our survey prefers turtles, they could either be forced to choose a response between these two (i.e., interpret the question as “between dogs and cats which do you prefer?” and result in measurement error), or they may not answer the question (which results in item nonresponse error). Based on this, the interpretation of this question should be When given the choice between dogs and cats, 50% of respondents preferred to have a dog as a pet. To avoid this issue, researchers should consider these possibilities and adjust the question accordingly. One simple way could be to add an “other” response option to give respondents a chance to provide a different response. The “other” response option could then include a way for respondents to write in what their other preference is. For example, this question could be rewritten as What animal do you prefer to have as a pet? Dogs Cats Other, please specify: Researchers can then code the responses from the open-ended box and get a better understanding of the respondent’s choice of preferred pet. Interpreting this question becomes easier as researchers no longer need to qualify the results with the choices provided. This is a very simple example of how the question presentation and options can impact the findings. More complex topics and questions will need researchers to thoroughly consider how to mitigate any impacts from the presentation, formatting, wording, and other aspects. As survey analysts, reviewing not only the data but also the wording of the questions is crucial to ensure the results are presented in a manner consistent with the question asked. 2.2 Data Collection Once the data collection starts, researchers try to stick to the data collection protocol designed during pre survey planning. However, a good researcher will adjust their plans and adapt as needed to the current progress of data collection ({cite Peytchev book on adaptive survey design}). Some extreme examples could be natural disasters that could prevent mail or interviewers from getting to the sample members. Others could be smaller in that something news worthy occurs that is connected to the survey, so researchers could choose to play this up in communication materials. In addition to these external factors, there could be factors unique to the survey such as the response rates are lower for a specific sub-group, so the data collection protocol may need to find ways to improve response rates for a specific group. 2.3 Post Survey Processing After data collection, there are a variety of activities that need to be conducted before the survey can be analyzed. Multiple decisions made during this post survey phase can assist researchers in reducing different error sources such as through weighting to account for the sample selection. Knowing the decisions researchers made in creating the final analytic data can impact how analysts use the data and interpret the results. 2.3.1 Data Cleaning and Imputation Post survey cleaning and imputation is one of the first steps researchers will do to get the survey responses into a dataset for use by analysts. Data cleaning can comprise of cleaning inconsistent data (e.g., with skip pattern errors or multiple questions throughout the survey being consistent with each other), editing numeric entry or open-ended responses for grammar and consistency, or recoding open-ended questions into categories for analysis. Each project should create their own rules for how to handle different cleaning situations, and there are no specific rules that must be followed. Instead, researchers should use their best judgement in ensuring data integrity remains and all decisions should be documented and available to those using the data in analysis. Each decision a researcher makes has an impact on processing error, so often researchers often will have multiple people review these rules or recode open-ended data and adjudicate any differences in an attempt to reduce this error. Another crucial step in post survey processing is imputation. Often times there is item nonresponse where respondents do not answer specific questions. If the questions are crucial to analysis efforts or to the research question, researchers will implement imputation in an effort to reduce item nonresponse error. However, as imputation is a way of assigning a value to missing data based on an algorithm or model, it can introduce processing error as well, so researchers should consider the overall implications of imputing data compared to having item nonresponse. There are multiple ways that imputation can be conducted, we recommend reviewing other resources like {cite Kim &amp; Shao, Statistical Methods for Handling Incomplete Data} for more information. Example: Number of Pets in a Household Let’s return to the question we created to ask about animal preference. The “other specify” invites respondents to specify the type of animal they prefer to have as a pet. If respondents entered answers such as “puppy”, “turtle”, “rabit”, “rabbit”, “bunny”, “ant farm”, “snake”, “Mr. Purr”, then researchers may wish to categorize these write-in responses to help with analysis. In this example, “puppy” could be assumed to be a reference to a Dog, and could be recoded there. The misspelling of “rabit” could be coded along with “rabbit” and “bunny” into a single category of Bunny or Rabbit. These are relatively standard decisions that a researcher could make. The remaining write-in responses could be categorized into a few different ways. “Mr. Purr”, which may be someone’s reference to their own cat, could be recoded to Cat, or it could remain as Other or some category that is Unknown. Depending on the number of responses related to each of others, they could all be combined into a single Other category, or maybe categories such as Reptiles or Insects could be created. Each of these decisions may impact the interpetation of the data, so our researcher should make sure to document the types of responses that fall into each of the new categories. 2.3.2 Weighting Weighting can typically be used to address some of the error sources identified in the previous sections. For example, weights may be used to address coverage, sampling, and nonresponse errors and many published surveys will include an “analysis weight” variable that combines these adjustments. However, weighting itself can also introduce adjustment error, so researchers need to balance which types of errors should be corrected with weighting. The construction of weights is outside the scope of this book and researchers should reference other materials if interested constructing their own (e.g., {CITE Jill’s Book}). Instead, this book assumes the survey has been completed, weights are constructed, and data is made available for users. We will walk users through how to read documentation and work with the data and analysis weights provided to analyze and interpret survey results correctly. Example: Number of Pets in a Household In the simple example of our survey, we decided to use a stratified sample by state to select our sample members. Knowing this sampling design our researcher can include selection weights for analysis that account for how the sample members were selected into the survey. Additionally, the sampling frame may have the type of building associated with each address, so we could include the building type as a potential nonresponse weighting variable, along with some interviewer observations that may be related to our research topic of average number of pets in a household. Combining these weights we could create an analytic weight that researchers can use when analyzing the data. 2.3.3 Disclosure Before data is allowed to be made publicly available, researchers will need to ensure that individual respondents can not be identified by the data when confidentiality is required. There are a variety of different methods that can be used, including data swapping, top or bottom coding, coarsening, and perturbation. In data swapping, researchers may swap specific data values across different respondents such that it does not impact insights that come from the data, but ensures that specific individuals cannot be identified. For extreme values, top and bottom coding is sometimes used. For example, researchers may top-code incomes values such that households with income greater than $99,999,999 are coded into a single category of $99,999,999 or more. Other methods for disclosure may include aggregating response categories or location information to avoid having only a few respondents in a given group, and thus be identified. For example, researchers couse use coarsening to display income in categories instead of as a continuous variable. Data producers may also perturb the data by adding random noise. There is as much art as there is science to the methods used for disclosure, and in documentation researchers should only provide a high level comments that disclosure was conducted and not specific details to ensure nobody can reverse the disclosure and thus identify individuals. For more information on different disclosure methods please see {CITE Skinner chapter in this book: https://www.sciencedirect.com/science/article/abs/pii/S0169716108000151 AAPOR checklist/standards: https://www-archive.aapor.org/Standards-Ethics/AAPOR-Code-of-Ethics/Survey-Disclosure-Checklist.aspx}. 2.4 This book After all of these steps are taken, the data is ready for use by analysts. The rest of this book works from this point. If you’re interested in learning more about the steps talked about here, we recommend you look into the references cited throughout this chapter. Other modes such as using mobile apps or text messaging can also be considered, but have typically smaller reach or are better for longitudinal studies (i.e., surveying the same individuals over many waves of a single study). For the purposes of this overview we will focus on these four main modes.↩︎ "],["understanding-survey-data-documentation.html", "Chapter 3 Understanding survey data documentation 3.1 Types of survey documentation 3.2 Working with missing data 3.3 Example: American National Election Studies (ANES) 2020 survey documentation 3.4 Searching for public-use survey data 3.5 Exercises", " Chapter 3 Understanding survey data documentation Before diving into survey analysis, it’s crucial to thoroughly review the survey documentation. This documentation includes technical guides, questionnaires, codebooks, errata, and other useful resources. By taking the time to review these materials, we can gain a comprehensive understanding of the survey data and effectively conduct our analysis. Survey documentation can vary in organization, type, and ease of use. The information may be stored in any format - PDFs, Excel spreadsheets, Word documents, etc. Some surveys save different documentation together, such as providing a single document that contains both the codebook and the questionnaire. Others keep them in separate files. Despite these differences, it’s important to know what kind of information is available in each documentation type and what to focus on in each one. 3.1 Types of survey documentation 3.1.1 Technical documentation The technical documentation, also known as user guides or methodology/analysis guides, highlights the variables necessary to specify the survey design. We recommend focusing on these key sections: Introduction: The introduction orients us to the survey. This section provides the project’s background, the study’s purpose, and the main research questions. Study design: The study design section describes how researchers prepared and administered the survey. Sample: The sample section describes how researchers selected cases, any sampling error that occurred, and the limitations of the sample. This section can contain recommendations on how to use sampling weights. Look for weight information, whether the survey design is strata and/or clusters/PSUs or replicate weights, and any population sizes or finite population correction. This documentation is critical in successfully running our analysis, and more detail on sample designs is available in Chapter 05: Specifying sample designs in srvyr. The technical documentation may include other helpful information. Some technical documentation includes syntax for SAS, SUDAAN, Stata, and/or R, meaning we don’t have to create this code from scratch. 3.1.2 Questionnaires A survey questionnaire is a series of questions asked to obtain information from survey respondents. A questionnaire gathers opinions, behaviors, or demographic data by employing different types of questions, such as multiple-choice, open-ended, Likert scales, or ranking questions. It may randomize responses or include instructions to help respondents understand the questions. A survey may have one questionnaire or multiple, depending on its scale and scope. The questionnaire is an essential resource for understanding and interpreting the survey data, and we should use it alongside any analysis. It provides details about each of the questions asked in the survey, such as question name, question wording, response options, skip logic, randomizations, display specification, mode differences, and the universe (if only a subset of respondents were asked the question). Below in Figure 3.1, we show a question from the ANES 2020 questionnaire. The screenshot shows a particular question’s question name (postvote_rvote), description (Did R Vote?), full wording of the question and responses, response order, universe, question logic (if vote_pre = 0), and other specifications. The section also includes the variable name, which we can link to the codebook. FIGURE 3.1: ANES 2020 Questionnaire Example The content and structure of questionnaires vary depending on the specific survey. For instance, question names may be informative (like the ANES example), sequential, or denoted by a code. In some cases, surveys may not use separate names for questions and variable. Here is a question from the Behavioral Risk Factor Surveillance System (BRFSS) questionnaire that shows a sequential question number and a coded variable name (as opposed to a question name): FIGURE 3.2: BRFSS 2021 Questionnaire Example Given the variety in documentation, it is essential to consider the specific survey when interpreting the information presented in a questionnaire. 3.1.3 Codebooks While a questionnaire provides information about the questions asked to respondents, the codebook explains how the survey data was coded and recorded. The codebook lists details such as variable names, variable label, variable meaning, codes for missing data, values labels, and value type (whether categorical or continuous, etc.). In particular, the codebook often includes information on missing data (as opposed to the questionnaire). The codebook enables us to understand and use the variables appropriately in our analysis. Below is a question from the ANES 2020 codebook. This part indicates a particular variable’s name (V202066), question wording, value labels, universe, and associated survey question (postvote_rvote). FIGURE 3.3: ANES 2020 Codebook Example Reviewing both questionnaires and codebooks in parallel is important, as questions and variables are not one-to-one. A single question may have multiple associated variables, or a single variable may summarize multiple questions. Reviewing the codebook clarifies how to interpret the variables. 3.1.4 Errata An erratum (singular) or errata (plural) is a document that lists errors found in a publication or dataset, such as a survey questionnaire. The purpose of an erratum is to correct or update mistakes or inaccuracies in the original document. For example, if a survey questionnaire contains an error, such as a typo or confusing wording, the researchers would release an erratum that provides a corrected version. Be sure to review these corrections before conducting any analysis to ensure the accuracy and reliability of the survey data and analysis. 3.1.5 Additional resources Surveys may have additional resources, such as interviewer instructions or “show cards” held up to respondents to help them answer questions. Explore the survey website to find out what resources were used and in what contexts. 3.2 Working with missing data Missing data in surveys refers to situations where participants do not provide complete responses to survey questions. Respondents may not have seen a question by design. Or, they may not respond to a question for various other reasons, such as not wanting to answer a particular question, not understanding the question, or simply forgetting to answer. Missing data can be a significant problem in survey analysis, as it can introduce bias and reduce the representativeness of the data. There are several different types of missing data2: Missing by design/questionnaire skip logic: This type of missingness occurs when certain respondents are intentionally directed to skip specific questions based on their previous responses or characteristics. For example, in a survey about employment, if a respondent indicates that they are not employed, they may be directed to skip questions related to their job responsibilities. Missing completely at random (MCAR): The missing data is unrelated to both observed and unobserved data, and the probability of being missing is the same across all cases. For example, if a respondent missed a question because they had to leave the survey early due to an emergency. Missing at random (MAR): The missing data is related to observed data but not unobserved data, and the probability of being missing is the same within groups. For example, if older respondents choose not to answer specific questions than younger respondents, and we ask about age in the demographic section. Missing not at random (MNAR): The missing data is related to unobserved data, and the probability of being missing varies for reasons we are not measuring. For example, if respondents with depression do not answer a question about depression severity. The survey documentation, often the codebook, represents the missing data with a code. For example, a survey may have “Yes” responses coded to 1, “No” responses coded to 2, and missing responses coded to -9. Or, the codebook may list different codes depending on why certain data is missing. In the example of variable V202066 from the ANES, -9 represents “Refused”, -7 means that the response was deleted due to incomplete interview, -6 means that there is no response because there was no follow-up interview, and -1 means “Inapplicable” (due to the designed skip pattern). See the codebook section for the variable below: FIGURE 3.4: ANES 2020 Codebook Example When running analysis in R, we must ensure that we treat missing responses as missing data (i.e., NA) and not numeric data. If missing responses are treated as zeros or another arbitrary values, they can artificially alter summary statistics or introduce spurious patterns in the analysis. There are various ways to handle missing data in R, such as using functions like na.omit(), complete.cases(), or specialized packages like tidyimpute or mice. These tools allow us to treat missing responses as missing data to conduct your analysis accurately and obtain valid results. 3.2.1 Accounting for questionnaire skip patterns Questionnaires may include skip patterns, in which specific questions are skipped based on the respondent’s answers to earlier questions. For example, if a respondent answers “no” to a question on whether they voted in the last election, they may be instructed to skip a series of questions related to that election. Skip patterns are used in surveys to streamline the data collection process and avoid asking irrelevant questions to certain respondents. However, they also result in missing data, as respondents cannot respond to questions they were instructed to skip. Analyzing the data that is missing by design requires understanding the underlying reasons for the skip patterns. We must properly account for skip patterns in our survey analysis to ensure unbiased and accurate population parameters. Dealing with missing data due to skip patterns requires careful consideration. We can treat skipped questions as missing data. Or, we can run an analysis that accounts for the conditional dependence between the skipped and answered questions. The appropriate method depends on the nature and extent of the skip patterns, the research questions, and the methodology. For example, if we wanted to know what proportion of eligible voters voted for a particular candidate, the denominator would be all eligible voters, while if we wanted to know what proportion voted for a particular candidate among those who voted, the denominator would be those who voted. We include or exclude missing values depending on our question. 3.2.2 Accounting for MCAR, MAR, and MNAR missingness When dealing with missing data that is MCAR, MAR, or MNAR, we must consider the implications of how we handle these missing data and avoid introducing more sources of bias. For instance, we can analyze only the respondents who answered all questions by performing listwise deletion, which drops all rows from a data frame with a missing value in any column. The function tidyr::drop_na() can be used for listwise deletion. In the example below, only the first row will remain: dat &lt;- tibble::tribble( ~col1, ~col2, ~col3, &quot;a&quot;, &quot;d&quot;, &quot;e&quot;, &quot;b&quot;, NA, NA, &quot;c&quot;, NA, &quot;f&quot; ) dat %&gt;% tidyr::drop_na() ## # A tibble: 1 × 3 ## col1 col2 col3 ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 a d e Suppose our data is not missing completely at random (MCAR). In that case, listwise deletion may produce biased estimates if there is a pattern of respondents who do not respond to specific questions. In these circumstances, we should explore other options, such as multiple imputation or weighted estimation. However, imputation is not always appropriate and can introduce its own sources of bias. See Allison (2002) for more detail. In summary, we need to deeply understand the types and reasons for missing data in our survey before running any analysis. The survey documentation is an important resource for understanding how to deal with missing data. Carefully review the documentation for guidance from the researchers. 3.3 Example: American National Election Studies (ANES) 2020 survey documentation Let’s look at the survey documentation for the American National Election Studies (ANES) 2020. The survey website is located at https://electionstudies.org/data-center/2020-time-series-study/. Navigating to “User Guide and Codebook,” we can download the PDF that contains the survey documentation, titled “ANES 2020 Time Series Study Full Release: User Guide and Codebook”. Don’t be daunted by the 796-page PDF. We can focus on the most critical information. Introduction The first section in the User Guide explains that the ANES 2020 Times Series Study continues a series of election surveys conducted since 1948. These surveys contain data on public opinion and voting behavior in the U.S. presidential elections. It states that interviewers used one of three modes (web, video, or telephone). The introduction then summarizes the number of pre-election interviews (8,280) and post-election re-interviews (7,449). Sample Design and Respondent Recruitment The section “Sample Design and Respondent Recruitment” describes how the survey was conducted: …a contactless, mixed-mode design…. a sequential mixed-mode design was implemented that included self-administered online surveys, live video interviews conducted online, and telephone interviews. In addition to respondents who participated in 2016 ANES, the 2020 survey included a freshly-drawn cross-section: The target population for the fresh cross-section was the 231 million non-institutional U.S. citizens aged 18 or older living in the 50 U.S. states or the District of Columbia. The document continues with more details on the sample groups. Data Analysis, Weights, and Variance Estimation The section “Data Analysis, Weights, and Variance Estimation” includes information on weights and strata/cluster variables. Reading through, we can find the full sample weight variables: For analysis of the complete set of cases using pre-election data only, including all cases and representative of the 2020 electorate, use the full sample pre-election weight, V200010a. For analysis including post-election data for the complete set of participants (i.e., analysis of post-election data only or a combination of pre- and post-election data), use the full sample post-election weight, V200010b. Additional weights are provided for analysis of subsets of the data… The document provides more information about the variables, summarized below: For weight Use variance unit/PSU/cluster and use variance stratum V200010a V200010c V200010d V200010b V200010c V200010d As mentioned above, we want to conduct ANES data analysis with weights to accurately represent the population. The user guide references a supplemental document called “How to Analyze ANES Survey Data”3 as a ‘how-to guide’ to help us with our analysis. Recall the “Sample Design and Respondent Recruitment” section: The target population for the fresh cross-section was the 231 million non-institutional U.S. citizens aged 18 or older living in the 50 US states or the District of Columbia. We will use Current Population Survey (CPS) to find a number of the non-institutional U.S. citizens aged 18 or older living in the 50 U.S. states or D.C. The {censusapi} package allows us to run a reproducible analysis of this data. library(censusapi) library(tidyverse) # Note that we need a Census key to access the Census API cps_state_in &lt;- getCensus( name = &quot;cps/basic/nov&quot;, vintage = 2020, region = &quot;state&quot;, vars = c(&quot;HRHHID&quot;, &quot;HRMONTH&quot;, &quot;HRYEAR4&quot;, &quot;PRTAGE&quot;, &quot;PRCITSHP&quot;, &quot;PWSSWGT&quot;), key = Sys.getenv(&quot;CENSUS_KEY&quot;) ) cps_state &lt;- cps_state_in %&gt;% as_tibble() %&gt;% mutate(across(.cols = everything(), .fns = as.numeric)) # Confirm this doesn&#39;t include territories cps_state %&gt;% count(state) ## # A tibble: 51 × 2 ## state n ## &lt;dbl&gt; &lt;int&gt; ## 1 1 2406 ## 2 2 1289 ## 3 4 1969 ## 4 5 1988 ## 5 6 9574 ## 6 8 1365 ## 7 9 1157 ## 8 10 1285 ## 9 11 1622 ## 10 12 5055 ## # ℹ 41 more rows # Confirm this is only November 2020 cps_state %&gt;% count(HRMONTH, HRYEAR4) ## # A tibble: 1 × 3 ## HRMONTH HRYEAR4 n ## &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; ## 1 11 2020 112037 # Voting age citizen population targetpop &lt;- cps_state %&gt;% as_tibble() %&gt;% filter(PRTAGE &gt;= 18, PRCITSHP %in% (1:4)) %&gt;% pull(PWSSWGT) %&gt;% sum() targetpop ## [1] 231592693 The target population in 2020 is 231,592,693. This information gives us what we need to create the post-election survey object with {srvyr}: library(tidyverse) library(here) library(srvyr) anes &lt;- read_rds(here(&quot;AnalysisData&quot;, &quot;anes_2020.rds&quot;)) %&gt;% mutate(Weight = V200010b / sum(V200010b) * 231592693) anes_des &lt;- anes %&gt;% as_survey_design( weights = Weight, strata = V200010d, ids = V200010c, nest = TRUE ) summary(anes_des) The next section of the survey documentation is the codebook. As mentioned above, the codebook provides information about the variables in a survey dataset. We can use it to select the variables for our analysis later on. 3.4 Searching for public-use survey data A common question for aspiring survey analysts is, “What are some examples of public-use survey data?”. When writing this book, we asked ourselves this question to find relevant, engaging, and high-quality examples for our readers. We considered whether a survey had continuous and discrete data, how difficult it was to analyze, and how recently the survey collection happened. We also investigated the accessibility and licensing agreements of the data. Finally, we wanted to expand our examples beyond North American surveys. Here are a few public-use survey resources that we recommend: Analyze Survey Data for Free - asdfree.com Residential Energy Consumption Survey (RECS) - https://www.eia.gov/consumption/residential/ The National Crime Victimization Survey (NCVS) - https://bjs.ojp.gov/data-collection/ncvs Afrobarometer - https://www.afrobarometer.org/ Latin American Public Opinion Project Research Institute - https://www.vanderbilt.edu/lapop/ 3.5 Exercises Mack C, Su Z, Westreich D. Managing Missing Data in Patient Registries: Addendum to Registries for Evaluating Patient Outcomes: A User’s Guide, Third Edition [Internet]. Rockville (MD): Agency for Healthcare Research and Quality (US); 2018 Feb. Types of Missing Data. Available from: https://www.ncbi.nlm.nih.gov/books/NBK493614/↩︎ DeBell, Matthew. 2010. How to Analyze ANES Survey Data. ANES Technical Report Series no. nes012492. Palo Alto, CA, and Ann Arbor, MI: Stanford University and the University of Michigan↩︎ "],["c04.html", "Chapter 4 Introducing the srvyr package", " Chapter 4 Introducing the srvyr package "],["c05.html", "Chapter 5 Specifying sample designs and replicate weights in srvyr 5.1 Common sampling designs 5.2 Replicate weights 5.3 Understanding survey design documentation 5.4 Exercises", " Chapter 5 Specifying sample designs and replicate weights in srvyr The primary reason for using packages like {survey} and {srvyr} are to incorporate the sampling design or replicate weights into estimates. By incorporating the sampling design or replicate weights, precision estimates (e.g., standard errors and confidence intervals) are appropriately calculated. In this chapter, we will introduce common sampling designs and common types of replicate weights, the mathematical methods for calculating estimates and standard errors for a given sampling design, and the R syntax to specify the sampling design or replicate weights. While we will show the math behind the estimates, the functions in these packages will do the calculation. To deeply understand the math and the derivation, refer to Särndal, Swensson, and Wretman (2003), Wolter (2007), or Fuller (2011). The general process for estimation in the {srvyr} package is to: Create a tbl_svy object (a survey object) using: as_survey_design or as_survey_rep Subset data (if needed) using filter (subpopulations) Specify domains of analysis using group_by Within summarize, specify variables to calculate including means, totals, proportions, quantiles, and more This chapter includes details on the first step - creating the survey object. The other steps are detailed in the next several chapters. 5.1 Common sampling designs A sampling design is the method used to draw a sample. Both logistical and statistical elements are considered when developing a sampling design. When specifying a sampling design in R, the levels of sampling are specified along with the weights. Each record of a weight is constructed so that the particular record represents that many units in the population. For example, in a survey of 6th grade students in the United States, the weight associated with each responding student reflects how many students that record represents. Generally, the sum of the weights sum to the population total though some studies have the sum of the weights sum to the number of respondent records. Some common terminology across the designs are: sample size, generally denoted as \\(n\\), is the number of units selected population size, generally denoted as \\(N\\), is the number of units in the population sampling frame is the list of units from which the sample is drawn 5.1.1 Simple random sample without replacement Description: The simple random sample (SRS) without replacement is a sampling design where a fixed sample size is selected from a sampling frame, and every possible subsample has equal probability of selection. Requirements: The sampling frame must include the entire population. Advantages: SRS requires no information about the units apart from contact information. Disadvantages: The sampling frame may not be available for entire population. This design is not generally feasible for in-person data collection. Example: Randomly students in a university from a roster provided by the registrar’s office. The math The estimate for the population mean of variable \\(y\\) is: \\[\\bar{y}=\\frac{1}{n}\\sum_{i=1}^n y_i\\] and the estimate of the standard error of mean is: \\[se(\\bar{y})=\\sqrt{\\frac{s^2}{n}\\left( 1-\\frac{n}{N} \\right)}\\] where \\[s^2=\\frac{1}{n-1}\\sum_{i=1}^n\\left(y_i-\\bar{y}\\right)^2.\\] This standard error estimate might look very similar to equations in other applications except for the part on the right side of the equation: \\(1-\\frac{n}{N}\\). This is called the finite population correction factor (FPC), and if the size of the frame, \\(N\\), is very large, the FPC is negligible so it is often ignored. To estimate proportions, we define \\(x_i\\) as the indicator if the outcome is observed. That is, \\(x_i=1\\) if the outcome is observed and \\(x_i=0\\) if the outcome is not observed. Then the estimated proportion from a SRS design is: \\[\\hat{p}=\\frac{1}{n}\\sum_{i=1}^n x_i \\] and the estimated standard error of the proportion is: \\[se(\\hat{p})=\\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n-1}\\left(1-\\frac{n}{N}\\right)} \\] The syntax If a sample was drawn through SRS and had no nonresponse or other weighting adjustments, in R specify this design as: des_srs1 &lt;- dat %&gt;% as_survey_design(fpc = fpcvar) where dat is a tibble or data.frame with the survey data and fpcvar is a variable on the tibble which indicates the size of the sampling frame. If the frame was very large, sometimes the frame size is not provided. In that case, the fpc is not needed and specify the design as: des_srs2 &lt;- dat %&gt;% as_survey_design() If some post-survey adjustments were implemented and the weights are not all equal, specify the design as: des_srs3 &lt;- dat %&gt;% as_survey_design(weights = wtvar, fpc = fpcvar) where wtvar is the variable for the weight on the data. Again, the fpc can be omitted if it is not necessary because the frame is large. Example The {survey} package in R provides some example datasets to use and those will be used throughout this chapter. Reading the documentation about these datasets provide detail on the variables. One of the example datasets we will use is from the Academic Performance Index (API). The API was a program administered by the California Department of Education and the {survey} package includes a population file (frame) of all schools with at least 100 students and several different samples pulled from that data using different sampling methods. For this first example, we will use the apisrs dataset, which contains a SRS of 200 schools. For printing purposes, we create a new dataset called apisrs_slim, which sorts the data by school district and school ID and subsets the data to only a few columns. The SRS sample data is illustrated below: options(tidyverse.quiet = TRUE) library(tidyverse) library(survey) library(srvyr) data(api) apisrs_slim &lt;- apisrs %&gt;% as_tibble() %&gt;% arrange(dnum, snum) %&gt;% select(cds, dnum, snum, dname, sname, fpc, pw) apisrs_slim ## # A tibble: 200 × 7 ## cds dnum snum dname sname fpc pw ## &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 19642126061220 1 1121 ABC Unified Haske… 6194 31.0 ## 2 19642126066716 1 1124 ABC Unified Stowe… 6194 31.0 ## 3 36675876035174 5 3895 Adelanto Elementary Adela… 6194 31.0 ## 4 33669776031512 19 3347 Alvord Unified Arlan… 6194 31.0 ## 5 33669776031595 19 3352 Alvord Unified Wells… 6194 31.0 ## 6 31667876031033 39 3271 Auburn Union Elementary Cain … 6194 31.0 ## 7 19642876011407 42 1169 Baldwin Park Unified Deanz… 6194 31.0 ## 8 19642876011464 42 1175 Baldwin Park Unified Heath… 6194 31.0 ## 9 19642956011589 48 1187 Bassett Unified Erwin… 6194 31.0 ## 10 41688586043392 49 4948 Bayshore Elementary Baysh… 6194 31.0 ## # ℹ 190 more rows School districts have identifiers dnum within counties and schools have identifiers of snum within districts along with their names, dname and sname. The unique identifier for a school is cds which is unique within the state. Additionally, the fpc is included as fpc and the weight as pw. To create the tbl_survey object for this SRS data, the design should be specified as: des_apisrs &lt;- apisrs_slim %&gt;% as_survey_design(weights = pw, fpc = fpc) des_apisrs ## Independent Sampling design ## Called via srvyr ## Sampling variables: ## - ids: `1` ## - fpc: fpc ## - weights: pw ## Data variables: cds (chr), dnum (int), snum (dbl), dname (chr), sname ## (chr), fpc (dbl), pw (dbl) summary(des_apisrs) ## Independent Sampling design ## Called via srvyr ## Probabilities: ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.0323 0.0323 0.0323 0.0323 0.0323 0.0323 ## Population size (PSUs): 6194 ## Data variables: ## [1] &quot;cds&quot; &quot;dnum&quot; &quot;snum&quot; &quot;dname&quot; &quot;sname&quot; &quot;fpc&quot; &quot;pw&quot; In the printed design object above, the design is described as an “Independent Sampling design” which is another terminology for SRS. The ids are specified as 1 which means there is no clustering (a topic described later in this chapter), the fpc variable is indicated, and the weights are indicated. When looking at the summary of the design object, the population size is given as a summary of the probabilities (inverse of the weights). 5.1.2 Simple random sample with replacement Description: The simple random sample with replacement (SRSWR) is a sampling design where a sample is selected from a sampling frame with the units being replaced before drawing again, so units can be selected more than once. Requirements: The sampling frame must include the entire population. Advantages: SRSWR requires no information about the units apart from contact information. Disadvantages: The sampling frame may not be available for entire population. This design is not generally feasible for in-person data collection. Units can be selected more than once resulting in a smaller realized sample size. For small populations, SRSWR has larger standard errors than SRS designs. Example: A professor puts all students names on paper slips and selects them randomly to ask students questions but the professor replaces the paper after calling on the student so they can be selected again at any time. The math The estimate for the population mean of variable \\(y\\) is: \\[\\bar{y}=\\frac{1}{n}\\sum_{i=1}^n y_i\\] and the estimate of the standard error of mean is: \\[se(\\bar{y})=\\sqrt{\\frac{s^2}{n}}\\] where \\[s^2=\\frac{1}{n-1}\\sum_{i=1}^n\\left(y_i-\\bar{y}\\right)^2.\\] To calculate the estimated proportion, we define \\(x_i\\) as the indicator that the outcome is observed (as we did with SRS): \\[\\hat{p}=\\frac{1}{n}\\sum_{i=1}^n x_i \\] and the estimated standard error of the proportion is: \\[se(\\hat{p})=\\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}} \\] The syntax If you had a sample that was drawn through SRSWR and had no nonresponse or other weighting adjustments, in R, you should specify this design as: des_srswr1 &lt;- dat %&gt;% as_survey_design() where dat is a tibble or data.frame with your survey data. If some post-survey adjustments were implemented and the weights are not all equal, specify the design as: des_srswr2 &lt;- dat %&gt;% as_survey_design(weights = wtvar) where wtvar is the variable for the weight on the data. Example The {survey} package does not include an example of SRSWR so we create an example from the population data provided. We call this new dataset apisrswr. set.seed(409963) apisrswr &lt;- apipop %&gt;% as_tibble() %&gt;% slice_sample(n = 200, replace = TRUE) %&gt;% select(cds, dnum, snum, dname, sname) %&gt;% mutate( weight = nrow(apipop)/200 ) head(apisrswr) ## # A tibble: 6 × 6 ## cds dnum snum dname sname weight ## &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 43696416060065 533 5348 Palo Alto Unified Jordan (Da… 31.0 ## 2 07618046005060 650 509 San Ramon Valley Unified Alamo Elem… 31.0 ## 3 19648086085674 457 2134 Montebello Unified La Merced … 31.0 ## 4 07617056003719 346 377 Knightsen Elementary Knightsen … 31.0 ## 5 19650606023022 744 2351 Torrance Unified Carr (Evel… 31.0 ## 6 01611196090120 6 13 Alameda City Unified Paden (Wil… 31.0 Because this is a SRS design with replacement there will be duplicates in the data. It is important to keep the duplicates in the data for proper estimation, but for reference here are the duplicates in the example we just created. apisrswr %&gt;% group_by(cds) %&gt;% filter(n()&gt;1) %&gt;% arrange(cds) ## # A tibble: 4 × 6 ## # Groups: cds [2] ## cds dnum snum dname sname weight ## &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 15633216008841 41 869 Bakersfield City Elem Chipman Junio… 31.0 ## 2 15633216008841 41 869 Bakersfield City Elem Chipman Junio… 31.0 ## 3 39686766042782 716 4880 Stockton City Unified Tyler Skills … 31.0 ## 4 39686766042782 716 4880 Stockton City Unified Tyler Skills … 31.0 A weight variable was added which is the inverse of the probability of selection. To specify the sampling design for apisrswr, the following syntax should be used: des_apisrswr &lt;- apisrswr %&gt;% as_survey_design(weights = weight) des_apisrswr ## Independent Sampling design (with replacement) ## Called via srvyr ## Sampling variables: ## - ids: `1` ## - weights: weight ## Data variables: cds (chr), dnum (int), snum (dbl), dname (chr), sname ## (chr), weight (dbl) summary(des_apisrswr) ## Independent Sampling design (with replacement) ## Called via srvyr ## Probabilities: ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.0323 0.0323 0.0323 0.0323 0.0323 0.0323 ## Data variables: ## [1] &quot;cds&quot; &quot;dnum&quot; &quot;snum&quot; &quot;dname&quot; &quot;sname&quot; &quot;weight&quot; In the chunk above, the design object is printed and the object summary is shown. Both of these note that the sampling is done “with replacement” because no fpc was specified. In the summary, the probabilities, which are derived from the weights, are summarized. 5.1.3 Stratified sampling Description: A population is divided into mutually exclusive subpopulations (strata) and then samples are selected independently within each stratum. Requirements: The sampling frame must include the information to divide the population into groups for every unit. Advantages: This design ensures sample representation in all subpopulations. Often, for the same sample size as a SRS sample, the standard errors are smaller so it is a more efficient design. This is true if the strata are correlated with outcomes. Disadvantages: Auxiliary data may not exist to divide sampling frame into groups or the data may be outdated. Examples: Example 1: A population of North Carolina residents could be separated into urban and rural areas and then a SRS of residents from both rural and urban areas is selected independently. This ensures there are rural residents in the sample. Example 2: There are 3 primary general purpose law enforcement agencies in the US - local police, sheriff’s departments, and state police. In a survey of law enforcement agencies, the agency type could be used to form strata. The math Let \\(\\bar{y}_h\\) be the sample mean for stratum \\(h\\), \\(N_h\\) be the population size of stratum \\(h\\), and \\(n_h\\) be the sample size of stratum \\(h\\). Then the estimate for the population mean under stratified SRS sampling is: \\[\\bar{y}=\\frac{1}{N}\\sum_{h=1}^H N_h\\bar{y}_h\\] and the estimate of the standard error of \\(\\bar{y}\\) is: \\[se(\\bar{y})=\\sqrt{\\frac{1}{N^2} \\sum_{h=1}^H N_h^2 s_h^2\\left(1-\\frac{n_h}{N_h}\\right)} \\] where \\[s_h^2=\\frac{1}{n_h-1}\\sum_{i=1}^{n_h}\\left(y_{i,h}-\\bar{y}_h\\right)^2.\\] For estimates of proportions, let \\(\\hat{p}_h\\) be the estimated proportion in stratum \\(h\\). Then the population proportion estimate is: \\[\\hat{p}= \\frac{1}{N}\\sum_{h=1}^H N_h \\hat{p}_h\\] and the standard error of the proportion is: \\[se(\\hat{p}) = \\frac{1}{N} \\sqrt{ \\sum_{h=1}^H N_h^2 \\frac{\\hat{p}_h(1-\\hat{p}_h)}{n_h-1} \\left(1-\\frac{n_h}{N_h}\\right)}\\] The syntax To specify a stratified SRS design in {srvyr} where the population sizes of the strata are not too large and are known, that is you are using the fpc, specify the design as: des_stsrs1 &lt;- dat %&gt;% as_survey_design(fpc = fpcvar, strata = stratvar) where fpcvar is a variable on your data which indicates \\(N_h\\) for each row and stratavar is a variable indicating the stratum for each row. You can omit the fpc if it is not applicable. Additionally, you can indicate the weight variable if it is present where wtvar is a variable on your data with a numeric weight. des_stsrs2 &lt;- dat %&gt;% as_survey_design(weights = wtvar, strata = stratvar) Example In the example API data, apistrat is a stratified random sample, stratified by school type (stype). As with the SRS example above, we sort and select specific variables for use of printing. The data are illustrated below including a count of the number of cases per stratum: apistrat_slim &lt;- apistrat %&gt;% as_tibble() %&gt;% arrange(dnum, snum) %&gt;% select(cds, dnum, snum, dname, sname, stype, fpc, pw) apistrat_slim %&gt;% count(stype, fpc) ## # A tibble: 3 × 3 ## stype fpc n ## &lt;fct&gt; &lt;dbl&gt; &lt;int&gt; ## 1 E 4421 100 ## 2 H 755 50 ## 3 M 1018 50 The fpc is the same within each stratum and 100 elementary schools were sampled while 50 schools were sampled from both the middle and high school levels. This design should be specified as: des_apistrat &lt;- apistrat_slim %&gt;% as_survey_design(strata = stype, weights = pw, fpc = fpc) des_apistrat ## Stratified Independent Sampling design ## Called via srvyr ## Sampling variables: ## - ids: `1` ## - strata: stype ## - fpc: fpc ## - weights: pw ## Data variables: cds (chr), dnum (int), snum (dbl), dname (chr), sname ## (chr), stype (fct), fpc (dbl), pw (dbl) summary(des_apistrat) ## Stratified Independent Sampling design ## Called via srvyr ## Probabilities: ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.0226 0.0226 0.0359 0.0401 0.0534 0.0662 ## Stratum Sizes: ## E H M ## obs 100 50 50 ## design.PSU 100 50 50 ## actual.PSU 100 50 50 ## Population stratum sizes (PSUs): ## E H M ## 4421 755 1018 ## Data variables: ## [1] &quot;cds&quot; &quot;dnum&quot; &quot;snum&quot; &quot;dname&quot; &quot;sname&quot; &quot;stype&quot; &quot;fpc&quot; &quot;pw&quot; When printing the object, it is specified as a “Stratified Independent Sampling design” also known as a stratified SRS and the strata variable is included. In the summary, a numeric summary of the probabilities of selection are displayed as well as the sample and population stratum sizes. 5.1.4 Clustered sampling Description: A population is divided into mutually exclusive subgroups called clusters or primary sampling units (PSUs). A random selection of PSUs are sampled and then another level of sampling is done within these clusters. There can be multiple levels of this selection. Clustered sampling is often used when a list of the entire population is not available or data collection involves interviewers needing direct contact with respondents. Requirements: There must have be a way to divide the population into clusters. Clusters are commonly structural such as institutions (e.g., schools, prisons) or geographic (e.g., states, counties). Advantages: Clustered sampling is advantageous when data collection is done in person so interviewers are sent to specific sampled areas rather than completely at random across a country. With cluster sampling, a list of the entire population is not necessary. For example, if sampling students, you do not need a list of all students but only a list of all schools. Once the schools are sampled, lists of students can be obtained within the sampled schools. Disadvantages: Compared to a simple random sample, for the same sample size, clustered samples generally have larger standard errors of estimates. Examples: Example 1: Consider a study needing a sample of 6th grade students in the United States, no list likely exists of all these students. However, it is more likely to be possible to obtain a list of schools that have 6th graders, so a study design could select a random sample of schools that have 6th graders. The selected schools can then provide a list of students to do a second stage of sampling where 6th grade students are randomly sampled within each of the sampled schools. This is a one-stage sample design and will be the type of design we will discuss in formulas below. Example 2: Consider a study sending interviewers to households for a survey. This is a more complicated example that requires two levels of selection, to efficiently use interviewers in geographic clusters. First, in the U.S. counties could be selected as the PSU, then Census block groups within counties could be selected as the secondary sampling unit (SSU). Households could then randomly sampled within the block groups. This type of design is popular for in-person survey as it reduces the travel necessary for interviewers. The math Consider a population where the are \\(N\\) clusters and \\(n\\) clusters are sampled via SRS. Units within each sampled cluster are sampled via SRS as well. Let \\(M_i\\) be the number of units in cluster \\(i\\) and \\(\\bar{y}_i\\) be the sample mean of cluster \\(i\\). Then, a ratio estimator of the population mean is: \\[\\bar{y}=\\frac{\\sum_{i=1}^n M_i \\bar{y}_i}{ \\sum_{i=1}^n M_i}\\] Note this is a consistent but biased estimator. Often the population size is not known so this is a method to estimate a mean without knowing the population size. The estimated standard error of the mean is: \\[se(\\bar{y})=\\frac{1}{\\hat{N}_{pop} } \\sqrt{\\frac{N^2 (1-\\frac{n}{N})}{n}\\frac{1}{n-1} \\sum_{i=1}^n (M_i\\bar{y}_i -\\hat{t}/N)^2 + \\frac{N}{n} \\sum_{i=1}^n \\frac{M_i^2}{m_i}\\left(1-\\frac{m_i}{M_i}\\right)s^2_i }\\] where \\(\\hat{N}_{pop}\\) is the estimated population size, \\(\\hat{t}\\) is the estimated total, and \\(s_i^2\\) is the sample variance of cluster \\(i\\). For estimates of proportions, the estimated proportion is: \\[\\hat{p}=\\frac{\\sum_{i=1}^n M_i \\hat{p}_i}{ \\sum_{i=1}^n M_i}\\] and the associated standard error estimate is: \\[se(\\hat{p})=\\frac{1}{\\hat{N}_{pop} } \\sqrt{\\frac{N^2 (1-\\frac{n}{N})}{n}\\frac{1}{n-1} \\sum_{i=1}^n (M_i\\hat{p}_i -\\hat{t}/N)^2 + \\frac{N}{n} \\sum_{i=1}^n \\frac{M_i^2}{m_i}\\left(1-\\frac{m_i}{M_i}\\right)s^2_i }\\] where \\(s^2_i\\) is defined as: \\[s^2_i = \\frac{m_hp_h(1-p_h)}{m_h-1}\\]. The syntax To specify a two-stage clustered design without replacement, use the following syntax: des_clus2 &lt;- dat %&gt;% as_survey_design(weights = wtvar, ids = c(PSU, SSU), fpc = c(N, M)) where PSU and SSU are the variables indicating the PSU and SSU identifiers and N and M are the variables indicating the population sizes for each level (i.e., N is the number of clusters and M is the number of units within each cluster). Note that N will be the same for all records (within a strata) and M will be the same for all records within the same cluster. If clusters were sampled with replacement or from a very large population, a fpc is not necessary. Additionally, only the first stage of selection is necessary regardless of whether the units were selected with replacement at any stage. The subsequent stages of selection are ignored in computation as their contribution to the variance is overpowered by the first stage, see Särndal, Swensson, and Wretman (2003) or Wolter (2007) for a more in-depth discussion. The syntax below will yield the same estimates in the end: des_clus2wra &lt;- dat %&gt;% as_survey_design(weights = wtvar, ids = c(PSU, SSU)) des_clus2wrb &lt;- dat %&gt;% as_survey_design(weights = wtvar, ids = PSU) Example The survey package includes a two-stage cluster sample data, apiclus2, in which school districts were sampled and then a random sample of 5 schools was selected within each district. For districts with fewer than 5 schools, all schools were sampled. School districts are identified by dnum and schools are identified by snum. The variable fpc1 indicates how many districts there are in California (N) and fpc2 indicates how many schools were in a given district with at least 100 students (M). The data has a row for each school. In the data printed below, there are 757 school districts as indicated by fpc1 and there are 9 schools in district 731, one school in district 742, 2 schools in district 768, and so on as indicated by fpc2. For illustration purposes, the object apiclus2_slim has been created from apiclus2, which subsets the data to only the necessary columns and sorts data. apiclus2_slim &lt;- apiclus2 %&gt;% as_tibble() %&gt;% arrange(desc(dnum), snum) %&gt;% select(cds, dnum, snum, fpc1, fpc2, pw) apiclus2_slim ## # A tibble: 126 × 6 ## cds dnum snum fpc1 fpc2 pw ## &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int[1d]&gt; &lt;dbl&gt; ## 1 47704826050942 795 5552 757 1 18.9 ## 2 07618126005169 781 530 757 6 22.7 ## 3 07618126005177 781 531 757 6 22.7 ## 4 07618126005185 781 532 757 6 22.7 ## 5 07618126005193 781 533 757 6 22.7 ## 6 07618126005243 781 535 757 6 22.7 ## 7 19650786023337 768 2371 757 2 18.9 ## 8 19650786023345 768 2372 757 2 18.9 ## 9 54722076054423 742 5898 757 1 18.9 ## 10 50712906053086 731 5781 757 9 34.1 ## # ℹ 116 more rows To specify this design in R, the following syntax should be used: des_apiclus2 &lt;- apiclus2_slim %&gt;% as_survey_design(ids = c(dnum, snum), fpc = c(fpc1, fpc2), weights=pw) des_apiclus2 ## 2 - level Cluster Sampling design ## With (40, 126) clusters. ## Called via srvyr ## Sampling variables: ## - ids: `dnum + snum` ## - fpc: `fpc1 + fpc2` ## - weights: pw ## Data variables: cds (chr), dnum (int), snum (dbl), fpc1 (dbl), fpc2 ## (int[1d]), pw (dbl) summary(des_apiclus2) ## 2 - level Cluster Sampling design ## With (40, 126) clusters. ## Called via srvyr ## Probabilities: ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.00367 0.03774 0.05284 0.04239 0.05284 0.05284 ## Population size (PSUs): 757 ## Data variables: ## [1] &quot;cds&quot; &quot;dnum&quot; &quot;snum&quot; &quot;fpc1&quot; &quot;fpc2&quot; &quot;pw&quot; The design objects are described as “2 - level Cluster Sampling design” and includes the ids (cluster), fpc, and weight variables. In the summary, it is noted that the sample includes 40 first-level clusters (PSUs) which are school districts and 126 second-level clusters (SSUs) which are schools. Additionally, the summary includes a numeric summary of the probabilities and the population size (number of PSUs) as 757. 5.2 Replicate weights Replicate weights are often included on analysis files instead of, or in addition to, the design variables (strata and PSUs). Replicate weights are used as another method to estimate variability and often used specifically so that design variables are not published as a measure to limit disclosure risk. There are several types of replicate weights including balanced repeated replication (BRR), Fay’s BRR, jackknife, and bootstrap methods. An overview of the process for using replicate weights is: Divide the sample into subsample replicates that mirror the design of the sample Calculate weights for each replicate using the same procedures for full-sample weight (i.e., nonresponse and post-stratification) Calculate estimates for each replicate using the same method as the full-sample estimate Calculate the estimated variance which will be proportional to the variance of the replicate estimates The different types of replicate weights largely differ in step 1 - how the sample is divided into subsamples and step 4 - which multiplication factors (scales) are used to multiply the variance. 5.2.1 BRR method The BRR method requires a stratified sample design with two PSUs in each stratum. Each replicate is constructed by deleting one PSU per stratum using a Hadamard matrix. For the PSU that is included, the weight is generally multiplied by 2 but may have other adjustments, such as post-stratification. A Hadamard matrix is a special square matrix with entries of +1 or -1 with mutually orthogonal rows. Hadamard matrices must have 1 row, 2 rows, or a multiple of 4 rows. An example of a \\(4\\times4\\) Hadamard matrix is below: \\[ \\begin{array}{rrrr} +1 &amp;+1 &amp;+1 &amp;+1\\\\ +1&amp;-1&amp;+1&amp;-1\\\\ +1&amp;+1&amp;-1&amp;-1\\\\ +1 &amp;-1&amp;-1&amp;+1 \\end{array} \\] The columns specify the strata and the rows the replicate. In the first replicate all the values are +1, so in each stratum the first PSU would be used in the estimate. In the second replicate, the first PSU would be used in stratum 1 and 3, while the second PSU would be used in stratum 2 and 4. In the third replicate, the first PSU would be used in stratum 1 and 2, while the second PSU would be used in stratum 3 and 4. Finally, in the fourth replicate, the first PSU would be used in stratum 1 and 4, while the second PSU would be used in stratum 2 and 3. The math A weighted estimate for the full sample is calculated as \\(\\hat{\\theta}\\) and then a weighted estimate for each replicate is calculated as \\(\\hat{\\theta}_r\\) for \\(R\\) replicates. Then the standard error of the estimate is calculated as: \\[se(\\hat{\\theta})=\\sqrt{\\frac{1}{R} \\sum_{r=1}^R \\left( \\hat{\\theta}_r-\\hat{\\theta}\\right)^2}\\] Specifying replicate weights in R requires specifying the type of replicate weights, the main weight variable, the replicate weight variables, and some other options. One of the key options is for mse. If mse=TRUE, variances are computed around the point estimate \\((\\hat{\\theta})\\), whereas if mse=FALSE, variances are computed around the mean of the replicates \\((\\bar{\\theta})\\) instead which looks like this: \\[se(\\hat{\\theta})=\\sqrt{\\frac{1}{R} \\sum_{r=1}^R \\left( \\hat{\\theta}_r-\\bar{\\theta}\\right)^2}\\] where \\[\\bar{\\theta}=\\frac{1}{R}\\sum_{r=1}^R \\hat{\\theta}_r\\] The default option for mse is to use the global option of “survey.replicates.mse” which is set to FALSE initially unless a user changes it. Unless documentation states otherwise, for BRR, set mse to TRUE. The syntax Replicate weights generally come in groups and are sequentially numbered such as PWGTP1, PWGTP2, …, PWGTP80 in the American Community Survey (ACS) or BRRWT1, BRRWT2, …, BRRWT96 in the 2015 Residential Energy Consumption Survey (RECS). The {srvyr} package relies on tidy selection4 to choose variables. If replicate weight variables need to be specified with a character vector, use the all_of function to select variables from a character vector. Some other methods are also illustrated below in the examples but these apply to any type of replicate weights and not just BRR. If a dataset had WT0 for the main weight and had 20 BRR weights indicated WT1, WT2, …, WT20, use the following syntax (both are equivalent): des_brr &lt;- dat %&gt;% as_survey_rep(weights = WT0, repweights= all_of(str_c(&quot;WT&quot;, 1:20)), type=&quot;BRR&quot;, mse=TRUE) des_brr &lt;- dat %&gt;% as_survey_rep(weights = WT0, repweights= num_range(&quot;WT&quot;, 1:20), type=&quot;BRR&quot;, mse=TRUE) If a dataset had WT for the main weight and had 20 BRR weights indicated REPWT1, REPWT2, …, REPWT20, the following syntax could be used (both are equivalent): des_brr &lt;- dat %&gt;% as_survey_rep(weights = WT, repweights= all_of(str_c(&quot;REPWT&quot;, 1:20)), type=&quot;BRR&quot;, mse=TRUE) des_brr &lt;- dat %&gt;% as_survey_rep(weights = WT, repweights= starts_with(&quot;REPWT&quot;), type=&quot;BRR&quot;, mse=TRUE) If the replicate weight variables are on the file consecutively, the following syntax can also be used: des_brr &lt;- dat %&gt;% as_survey_rep(weights = WT, repweights= REPWT1:REPWT20, type=&quot;BRR&quot;, mse=TRUE) Typically, the replicate weights sum to a value similar to the main weight as they are both supposed to provide population estimates. Rarely, an alternative method will be used where the replicate weights have values of 0 or 2 in the case of BRR weights. This would be indicated in the documentation and in Section 5.3, we discuss how to understand documentation. In this case, the replicate weights are not combined and the option combined_weights = FALSE should be indicated, as the default value for this argument is TRUE. This specific syntax is shown below: des_brr &lt;- dat %&gt;% as_survey_rep(weights = WT, repweights= starts_with(&quot;REPWT&quot;), type=&quot;BRR&quot;, combined_weights = FALSE, mse=TRUE) Example The {survey} package includes a data example from Section 12.2 of Levy and Lemeshow (2013). In this fictional data, two out of five ambulance stations were sampled from each of three emergency service areas (ESAs) thus BRR weights are appropriate with 2 PSUs (stations) sampled in each stratum (ESA). In the code below, BRR weights are created as was done in Levy and Lemeshow (2013). data(scd) scdbrr &lt;- scd %&gt;% as_tibble() %&gt;% mutate( wt=5/2, rep1 = 2 * c(1, 0, 1, 0, 1, 0), rep2 = 2 * c(1, 0, 0, 1, 0, 1), rep3 = 2 * c(0, 1, 1, 0, 0, 1), rep4 = 2 * c(0, 1, 0, 1, 1, 0)) scdbrr ## # A tibble: 6 × 9 ## ESA ambulance arrests alive wt rep1 rep2 rep3 rep4 ## &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 1 120 25 2.5 2 2 0 0 ## 2 1 2 78 24 2.5 0 0 2 2 ## 3 2 1 185 30 2.5 2 0 2 0 ## 4 2 2 228 49 2.5 0 2 0 2 ## 5 3 1 670 80 2.5 2 0 0 2 ## 6 3 2 530 70 2.5 0 2 2 0 To specify the BRR weights, the following syntax is used: des_brr_scd &lt;- scdbrr %&gt;% as_survey_rep(type = &quot;BRR&quot;, repweights = starts_with(&quot;rep&quot;), combined_weights = FALSE, weight=wt) des_brr_scd ## Call: Called via srvyr ## Balanced Repeated Replicates with 4 replicates. ## Sampling variables: ## - repweights: `rep1 + rep2 + rep3 + rep4` ## - weights: wt ## Data variables: ESA (int), ambulance (int), arrests (dbl), alive (dbl), ## wt (dbl), rep1 (dbl), rep2 (dbl), rep3 (dbl), rep4 (dbl) summary(des_brr_scd) ## Call: Called via srvyr ## Balanced Repeated Replicates with 4 replicates. ## Sampling variables: ## - repweights: `rep1 + rep2 + rep3 + rep4` ## - weights: wt ## Data variables: ESA (int), ambulance (int), arrests (dbl), alive (dbl), ## wt (dbl), rep1 (dbl), rep2 (dbl), rep3 (dbl), rep4 (dbl) ## Variables: ## [1] &quot;ESA&quot; &quot;ambulance&quot; &quot;arrests&quot; &quot;alive&quot; &quot;wt&quot; ## [6] &quot;rep1&quot; &quot;rep2&quot; &quot;rep3&quot; &quot;rep4&quot; Note that combined_weights was specified as FALSE because these weights are simply specified as 0 and 2 and do not incorporate the overall weight. When printing the object, the type of replication is noted as Balanced Repeated Replicates, the replicate weights are specified, and the weight variable. When looking at the summary, the only additional information provided are the variables included. 5.2.2 Fay’s BRR Method Fay’s BRR method for replicate weights still uses a Hadamard matrix to construct replicate weights but rather than deleting PSUs for each replicate, half of the PSUs have a replicate weight which is the main weight multiplied by \\(\\rho\\) and the other half have the main weight multiplied by \\((2-\\rho)\\) where \\(0 \\le \\rho &lt; 1\\). Note that when \\(\\rho=0\\), this is equivalent to the standard BRR weights and as \\(\\rho\\) becomes closer to 1, this method is more similar to jackknife discussed in the next section. To obtain the value of \\(\\rho\\), it is necessary to read the documentation as discussed in Section 5.3. The math The standard error estimate for \\(\\hat{\\theta}\\) is slightly different and calculated as: \\[se(\\hat{\\theta})=\\sqrt{\\frac{1}{R (1-\\rho)^2} \\sum_{r=1}^R \\left( \\hat{\\theta}_r-\\hat{\\theta}\\right)^2}\\] The syntax The syntax is very similar for BRR and Fay’s BRR. If a dataset had WT0 for the main weight and had 20 BRR weights indicated WT1, WT2, …, WT20, and Fay’s multiplier is 0.5, use the following syntax: des_fay &lt;- dat %&gt;% as_survey_rep(weights = WT0, repweights= num_range(&quot;WT&quot;, 1:20), type=&quot;Fay&quot;, mse=TRUE, rho=0.5) Example The 2015 RECS uses Fay’s BRR weights with the final weight as NWEIGHT and replicate weights as BRRWT1 - BRRWT96 with \\(\\rho=0.5\\)5. On the file, DOEID is a unique identifier for each respondent, TOTALDOL is the total cost of energy, TOTSQFT_EN is the total square footage of the residence, and REGOINC is the Census region. To specify this design, use the following syntax: recs_in &lt;- read_csv( here::here(&quot;RawData&quot;, &quot;RECS_2015&quot;, &quot;recs2015_public_v4.csv&quot;)) ## Rows: 5686 Columns: 759 ## ── Column specification ──────────────────────────────────────────────── ## Delimiter: &quot;,&quot; ## chr (4): METROMICRO, UATYP10, CLIMATE_REGION_PUB, IECC_CLIMATE_PUB ## dbl (755): DOEID, REGIONC, DIVISION, TYPEHUQ, ZTYPEHUQ, CELLAR, ZCEL... ## ## ℹ Use `spec()` to retrieve the full column specification for this data. ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message. des_recs &lt;- recs_in %&gt;% as_survey_rep( weights = NWEIGHT, repweights = BRRWT1:BRRWT96, type = &quot;Fay&quot;, rho = 0.5, mse = TRUE, variables = c(DOEID, TOTALDOL, TOTSQFT_EN, REGIONC) ) des_recs ## Call: Called via srvyr ## Fay&#39;s variance method (rho= 0.5 ) with 96 replicates and MSE variances. ## Sampling variables: ## - repweights: `BRRWT1 + BRRWT2 + BRRWT3 + BRRWT4 + BRRWT5 + BRRWT6 + BRRWT7 + BRRWT8 + BRRWT9 + BRRWT10 + BRRWT11 + BRRWT12 + BRRWT13 + BRRWT14 + BRRWT15 + BRRWT16 + BRRWT17 + BRRWT18 + BRRWT19 + BRRWT20 + BRRWT21 + BRRWT22 + BRRWT23 + BRRWT24 + BRRWT25 + BRRWT26 + BRRWT27 + BRRWT28 + BRRWT29 + BRRWT30 + BRRWT31 + BRRWT32 + BRRWT33 + BRRWT34 + BRRWT35 + BRRWT36 + BRRWT37 + BRRWT38 + BRRWT39 + BRRWT40 + BRRWT41 + BRRWT42 + BRRWT43 + BRRWT44 + BRRWT45 + BRRWT46 + BRRWT47 + BRRWT48 + BRRWT49 + BRRWT50 + BRRWT51 + \\n BRRWT52 + BRRWT53 + BRRWT54 + BRRWT55 + BRRWT56 + BRRWT57 + BRRWT58 + BRRWT59 + BRRWT60 + BRRWT61 + BRRWT62 + BRRWT63 + BRRWT64 + BRRWT65 + BRRWT66 + BRRWT67 + BRRWT68 + BRRWT69 + BRRWT70 + BRRWT71 + BRRWT72 + BRRWT73 + BRRWT74 + BRRWT75 + BRRWT76 + BRRWT77 + BRRWT78 + BRRWT79 + BRRWT80 + BRRWT81 + BRRWT82 + BRRWT83 + BRRWT84 + BRRWT85 + BRRWT86 + BRRWT87 + BRRWT88 + BRRWT89 + BRRWT90 + BRRWT91 + BRRWT92 + BRRWT93 + BRRWT94 + BRRWT95 + BRRWT96` ## - weights: NWEIGHT ## Data variables: DOEID (dbl), TOTALDOL (dbl), TOTSQFT_EN (dbl), REGIONC ## (dbl) summary(des_recs) ## Call: Called via srvyr ## Fay&#39;s variance method (rho= 0.5 ) with 96 replicates and MSE variances. ## Sampling variables: ## - repweights: `BRRWT1 + BRRWT2 + BRRWT3 + BRRWT4 + BRRWT5 + BRRWT6 + BRRWT7 + BRRWT8 + BRRWT9 + BRRWT10 + BRRWT11 + BRRWT12 + BRRWT13 + BRRWT14 + BRRWT15 + BRRWT16 + BRRWT17 + BRRWT18 + BRRWT19 + BRRWT20 + BRRWT21 + BRRWT22 + BRRWT23 + BRRWT24 + BRRWT25 + BRRWT26 + BRRWT27 + BRRWT28 + BRRWT29 + BRRWT30 + BRRWT31 + BRRWT32 + BRRWT33 + BRRWT34 + BRRWT35 + BRRWT36 + BRRWT37 + BRRWT38 + BRRWT39 + BRRWT40 + BRRWT41 + BRRWT42 + BRRWT43 + BRRWT44 + BRRWT45 + BRRWT46 + BRRWT47 + BRRWT48 + BRRWT49 + BRRWT50 + BRRWT51 + \\n BRRWT52 + BRRWT53 + BRRWT54 + BRRWT55 + BRRWT56 + BRRWT57 + BRRWT58 + BRRWT59 + BRRWT60 + BRRWT61 + BRRWT62 + BRRWT63 + BRRWT64 + BRRWT65 + BRRWT66 + BRRWT67 + BRRWT68 + BRRWT69 + BRRWT70 + BRRWT71 + BRRWT72 + BRRWT73 + BRRWT74 + BRRWT75 + BRRWT76 + BRRWT77 + BRRWT78 + BRRWT79 + BRRWT80 + BRRWT81 + BRRWT82 + BRRWT83 + BRRWT84 + BRRWT85 + BRRWT86 + BRRWT87 + BRRWT88 + BRRWT89 + BRRWT90 + BRRWT91 + BRRWT92 + BRRWT93 + BRRWT94 + BRRWT95 + BRRWT96` ## - weights: NWEIGHT ## Data variables: DOEID (dbl), TOTALDOL (dbl), TOTSQFT_EN (dbl), REGIONC ## (dbl) ## Variables: ## [1] &quot;DOEID&quot; &quot;TOTALDOL&quot; &quot;TOTSQFT_EN&quot; &quot;REGIONC&quot; In specifying the design, the variables option was also used to include which variables might be used in analyses. This is optional but can make your object smaller. When printing the design object or looking at the summary, the replicate weight type is re-iterated as Fay's variance method (rho= 0.5) with 96 replicates and MSE variances and the variables are included. No weight or probability summary is included as was done in some other design objects. 5.2.3 Jackknife method There are three jackknife estimators implemented in {srvyr} - Jackknife 1 (JK1), Jackknife n (JKn), and Jackknife 2 (JK2). The JK1 method can be used for unstratified designs and replicates are created by removing one PSU at a time so the number of replicates is the same as the number of PSUs. If there is no clustering, then the PSU is the ultimate sampling unit (e.g., unit). The JKn method is used for stratified designs and requires 2 or more PSUs per stratum. In this case, each replicate is created by deleting one PSU from each stratum so the number of replicates is the number of total PSUs across all strata. The JK2 method is a special case of JKn when there are exactly 2 PSUs sampled per stratum. For variance estimation, scaling constants must also be specified. The math For the JK1 method, the standard error estimate for \\(\\hat{\\theta}\\) is calculated as: \\[se(\\hat{\\theta})=\\sqrt{\\frac{R-1}{R} \\sum_{r=1}^R \\left( \\hat{\\theta}_r-\\hat{\\theta}\\right)^2}\\] The JKn method is a bit more complex but the coefficients are generally provided with restricted and public use files. For each replicate, one stratum has a PSU removed and the weights are adjusted by \\(n_h/(n_h-1)\\) where \\(n_h\\) is the number of PSUs in the stratum. The coefficients in other strata are set to 1. Denote the coefficient that results from this process for replicate \\(r\\) as \\(\\alpha_r\\) then the standard error estimate for \\(\\hat{\\theta}\\) is calculated as: \\[se(\\hat{\\theta})=\\sqrt{\\sum_{r=1}^R \\left(\\alpha_r \\hat{\\theta}_r-\\hat{\\theta}\\right)^2}\\] The syntax To specify the Jackknife method, the type would be JK1, JKn, or JK2. Additionally, the overall multiplier for JK1 is specified with the scale argument, whereas the replicate specific multiplier ($_r) is specified with the rscales argument. Consider a case for the JK1 method where the multiplier, \\((R-1)/R=19/20=0.95\\) and the dataset had WT0 for the main weight and had 20 JK1 weights indicated WT1, WT2, …, WT20, then the syntax would be des_jk1 &lt;- dat %&gt;% as_survey_rep(weights = WT0, repweights= num_range(&quot;WT&quot;, 1:20), type=&quot;JK1&quot;, mse=TRUE, scale=0.95) Consider a case for the JKn method where \\(\\alpha_r=0.1\\) for all replicates and the dataset had WT0 for the main weight and had 20 JK1 weights indicated WT1, WT2, …, WT20, then the syntax would be: des_jkn &lt;- dat %&gt;% as_survey_rep(weights = WT0, repweights= num_range(&quot;WT&quot;, 1:20), type=&quot;JKN&quot;, mse=TRUE, rscales=rep(0.1, 20)) Example The American Community Survey releases public use microdata with JK1 weights at the person and household level. This example includes data at the household level where the replicate weights are specified as WGTP1, …, WGTP80 and the main weight is WGTP6. Using the {tidycensus} package7, data is downloaded from the Census API. This request gets data for each person in each household in two Public Use Microdata Areas (PUMAs) in Durham County, NC8. The variables requested are NP (number of persons in household), BDSP (number of bedrooms), HINCP (household income), and TYPEHUGQ (type of household). By default, several other variables will come along including SERIALNO (a unique identifier for each household), SPORDER (a unique identifier for each person within each household), PUMA, ST (state), person weight (PWGTP), and the household weights (WGTP, WGTP1, …, WGTP80). Filtering to records where SPORDER=1 yields only one record per household and TYPEHUGQ=1 filters to only households and not group quarters. library(tidycensus) pums_in &lt;- get_pums(variables=c(&quot;NP&quot;, &quot;BDSP&quot;, &quot;HINCP&quot;), state=&quot;37&quot;, puma=c(&quot;01301&quot;, &quot;01302&quot;), rep_weights = &quot;housing&quot;, year=2020, survey=&quot;acs5&quot;, variables_filter=list(SPORDER=1, TYPEHUGQ=1)) ## Getting data from the 2016-2020 5-year ACS Public Use Microdata Sample ## Warning: • You have not set a Census API key. Users without a key are limited to 500 ## queries per day and may experience performance limitations. ## ℹ For best results, get a Census API key at ## http://api.census.gov/data/key_signup.html and then supply the key to the ## `census_api_key()` function to use it throughout your tidycensus session. ## This warning is displayed once per session. pums_in ## # A tibble: 4,853 × 90 ## SERIALNO SPORDER NP BDSP HINCP PUMA ST TYPEHUGQ WGTP PWGTP ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 20170009… 1 1 3 7400 01301 37 1 19 19 ## 2 20170009… 1 3 4 56700 01301 37 1 14 14 ## 3 20170009… 1 1 2 61000 01302 37 1 14 15 ## 4 20170009… 1 4 3 143000 01302 37 1 16 16 ## 5 20170009… 1 5 4 87700 01301 37 1 14 13 ## 6 20170009… 1 4 2 20500 01302 37 1 11 11 ## 7 20170009… 1 1 1 65000 01301 37 1 33 33 ## 8 20170009… 1 3 4 555000 01301 37 1 16 15 ## 9 20170009… 1 4 3 127000 01301 37 1 11 11 ## 10 20170009… 1 3 3 104260 01302 37 1 20 21 ## # ℹ 4,843 more rows ## # ℹ 80 more variables: WGTP1 &lt;dbl&gt;, WGTP2 &lt;dbl&gt;, WGTP3 &lt;dbl&gt;, ## # WGTP4 &lt;dbl&gt;, WGTP5 &lt;dbl&gt;, WGTP6 &lt;dbl&gt;, WGTP7 &lt;dbl&gt;, WGTP8 &lt;dbl&gt;, ## # WGTP9 &lt;dbl&gt;, WGTP10 &lt;dbl&gt;, WGTP11 &lt;dbl&gt;, WGTP12 &lt;dbl&gt;, ## # WGTP13 &lt;dbl&gt;, WGTP14 &lt;dbl&gt;, WGTP15 &lt;dbl&gt;, WGTP16 &lt;dbl&gt;, ## # WGTP17 &lt;dbl&gt;, WGTP18 &lt;dbl&gt;, WGTP19 &lt;dbl&gt;, WGTP20 &lt;dbl&gt;, ## # WGTP21 &lt;dbl&gt;, WGTP22 &lt;dbl&gt;, WGTP23 &lt;dbl&gt;, WGTP24 &lt;dbl&gt;, … des_acs &lt;- pums_in %&gt;% as_survey_rep(weights = WGTP, repweights= num_range(&quot;WGTP&quot;, 1:80), type=&quot;JK1&quot;, mse=TRUE, scale=4/80) des_acs ## Call: Called via srvyr ## Unstratified cluster jacknife (JK1) with 80 replicates and MSE variances. ## Sampling variables: ## - repweights: `WGTP1 + WGTP2 + WGTP3 + WGTP4 + WGTP5 + WGTP6 + WGTP7 + WGTP8 + WGTP9 + WGTP10 + WGTP11 + WGTP12 + WGTP13 + WGTP14 + WGTP15 + WGTP16 + WGTP17 + WGTP18 + WGTP19 + WGTP20 + WGTP21 + WGTP22 + WGTP23 + WGTP24 + WGTP25 + WGTP26 + WGTP27 + WGTP28 + WGTP29 + WGTP30 + WGTP31 + WGTP32 + WGTP33 + WGTP34 + WGTP35 + WGTP36 + WGTP37 + WGTP38 + WGTP39 + WGTP40 + WGTP41 + WGTP42 + WGTP43 + WGTP44 + WGTP45 + WGTP46 + WGTP47 + WGTP48 + WGTP49 + WGTP50 + WGTP51 + WGTP52 + WGTP53 + WGTP54 + WGTP55 + WGTP56 + WGTP57 + \\n WGTP58 + WGTP59 + WGTP60 + WGTP61 + WGTP62 + WGTP63 + WGTP64 + WGTP65 + WGTP66 + WGTP67 + WGTP68 + WGTP69 + WGTP70 + WGTP71 + WGTP72 + WGTP73 + WGTP74 + WGTP75 + WGTP76 + WGTP77 + WGTP78 + WGTP79 + WGTP80` ## - weights: WGTP ## Data variables: SERIALNO (chr), SPORDER (dbl), NP (dbl), BDSP (dbl), ## HINCP (dbl), PUMA (chr), ST (chr), TYPEHUGQ (chr), WGTP (dbl), PWGTP ## (dbl), WGTP1 (dbl), WGTP2 (dbl), WGTP3 (dbl), WGTP4 (dbl), WGTP5 ## (dbl), WGTP6 (dbl), WGTP7 (dbl), WGTP8 (dbl), WGTP9 (dbl), WGTP10 ## (dbl), WGTP11 (dbl), WGTP12 (dbl), WGTP13 (dbl), WGTP14 (dbl), WGTP15 ## (dbl), WGTP16 (dbl), WGTP17 (dbl), WGTP18 (dbl), WGTP19 (dbl), WGTP20 ## (dbl), WGTP21 (dbl), WGTP22 (dbl), WGTP23 (dbl), WGTP24 (dbl), WGTP25 ## (dbl), WGTP26 (dbl), WGTP27 (dbl), WGTP28 (dbl), WGTP29 (dbl), WGTP30 ## (dbl), WGTP31 (dbl), WGTP32 (dbl), WGTP33 (dbl), WGTP34 (dbl), WGTP35 ## (dbl), WGTP36 (dbl), WGTP37 (dbl), WGTP38 (dbl), WGTP39 (dbl), WGTP40 ## (dbl), WGTP41 (dbl), WGTP42 (dbl), WGTP43 (dbl), WGTP44 (dbl), WGTP45 ## (dbl), WGTP46 (dbl), WGTP47 (dbl), WGTP48 (dbl), WGTP49 (dbl), WGTP50 ## (dbl), WGTP51 (dbl), WGTP52 (dbl), WGTP53 (dbl), WGTP54 (dbl), WGTP55 ## (dbl), WGTP56 (dbl), WGTP57 (dbl), WGTP58 (dbl), WGTP59 (dbl), WGTP60 ## (dbl), WGTP61 (dbl), WGTP62 (dbl), WGTP63 (dbl), WGTP64 (dbl), WGTP65 ## (dbl), WGTP66 (dbl), WGTP67 (dbl), WGTP68 (dbl), WGTP69 (dbl), WGTP70 ## (dbl), WGTP71 (dbl), WGTP72 (dbl), WGTP73 (dbl), WGTP74 (dbl), WGTP75 ## (dbl), WGTP76 (dbl), WGTP77 (dbl), WGTP78 (dbl), WGTP79 (dbl), WGTP80 ## (dbl) summary(des_acs) ## Call: Called via srvyr ## Unstratified cluster jacknife (JK1) with 80 replicates and MSE variances. ## Sampling variables: ## - repweights: `WGTP1 + WGTP2 + WGTP3 + WGTP4 + WGTP5 + WGTP6 + WGTP7 + WGTP8 + WGTP9 + WGTP10 + WGTP11 + WGTP12 + WGTP13 + WGTP14 + WGTP15 + WGTP16 + WGTP17 + WGTP18 + WGTP19 + WGTP20 + WGTP21 + WGTP22 + WGTP23 + WGTP24 + WGTP25 + WGTP26 + WGTP27 + WGTP28 + WGTP29 + WGTP30 + WGTP31 + WGTP32 + WGTP33 + WGTP34 + WGTP35 + WGTP36 + WGTP37 + WGTP38 + WGTP39 + WGTP40 + WGTP41 + WGTP42 + WGTP43 + WGTP44 + WGTP45 + WGTP46 + WGTP47 + WGTP48 + WGTP49 + WGTP50 + WGTP51 + WGTP52 + WGTP53 + WGTP54 + WGTP55 + WGTP56 + WGTP57 + \\n WGTP58 + WGTP59 + WGTP60 + WGTP61 + WGTP62 + WGTP63 + WGTP64 + WGTP65 + WGTP66 + WGTP67 + WGTP68 + WGTP69 + WGTP70 + WGTP71 + WGTP72 + WGTP73 + WGTP74 + WGTP75 + WGTP76 + WGTP77 + WGTP78 + WGTP79 + WGTP80` ## - weights: WGTP ## Data variables: SERIALNO (chr), SPORDER (dbl), NP (dbl), BDSP (dbl), ## HINCP (dbl), PUMA (chr), ST (chr), TYPEHUGQ (chr), WGTP (dbl), PWGTP ## (dbl), WGTP1 (dbl), WGTP2 (dbl), WGTP3 (dbl), WGTP4 (dbl), WGTP5 ## (dbl), WGTP6 (dbl), WGTP7 (dbl), WGTP8 (dbl), WGTP9 (dbl), WGTP10 ## (dbl), WGTP11 (dbl), WGTP12 (dbl), WGTP13 (dbl), WGTP14 (dbl), WGTP15 ## (dbl), WGTP16 (dbl), WGTP17 (dbl), WGTP18 (dbl), WGTP19 (dbl), WGTP20 ## (dbl), WGTP21 (dbl), WGTP22 (dbl), WGTP23 (dbl), WGTP24 (dbl), WGTP25 ## (dbl), WGTP26 (dbl), WGTP27 (dbl), WGTP28 (dbl), WGTP29 (dbl), WGTP30 ## (dbl), WGTP31 (dbl), WGTP32 (dbl), WGTP33 (dbl), WGTP34 (dbl), WGTP35 ## (dbl), WGTP36 (dbl), WGTP37 (dbl), WGTP38 (dbl), WGTP39 (dbl), WGTP40 ## (dbl), WGTP41 (dbl), WGTP42 (dbl), WGTP43 (dbl), WGTP44 (dbl), WGTP45 ## (dbl), WGTP46 (dbl), WGTP47 (dbl), WGTP48 (dbl), WGTP49 (dbl), WGTP50 ## (dbl), WGTP51 (dbl), WGTP52 (dbl), WGTP53 (dbl), WGTP54 (dbl), WGTP55 ## (dbl), WGTP56 (dbl), WGTP57 (dbl), WGTP58 (dbl), WGTP59 (dbl), WGTP60 ## (dbl), WGTP61 (dbl), WGTP62 (dbl), WGTP63 (dbl), WGTP64 (dbl), WGTP65 ## (dbl), WGTP66 (dbl), WGTP67 (dbl), WGTP68 (dbl), WGTP69 (dbl), WGTP70 ## (dbl), WGTP71 (dbl), WGTP72 (dbl), WGTP73 (dbl), WGTP74 (dbl), WGTP75 ## (dbl), WGTP76 (dbl), WGTP77 (dbl), WGTP78 (dbl), WGTP79 (dbl), WGTP80 ## (dbl) ## Variables: ## [1] &quot;SERIALNO&quot; &quot;SPORDER&quot; &quot;NP&quot; &quot;BDSP&quot; &quot;HINCP&quot; &quot;PUMA&quot; ## [7] &quot;ST&quot; &quot;TYPEHUGQ&quot; &quot;WGTP&quot; &quot;PWGTP&quot; &quot;WGTP1&quot; &quot;WGTP2&quot; ## [13] &quot;WGTP3&quot; &quot;WGTP4&quot; &quot;WGTP5&quot; &quot;WGTP6&quot; &quot;WGTP7&quot; &quot;WGTP8&quot; ## [19] &quot;WGTP9&quot; &quot;WGTP10&quot; &quot;WGTP11&quot; &quot;WGTP12&quot; &quot;WGTP13&quot; &quot;WGTP14&quot; ## [25] &quot;WGTP15&quot; &quot;WGTP16&quot; &quot;WGTP17&quot; &quot;WGTP18&quot; &quot;WGTP19&quot; &quot;WGTP20&quot; ## [31] &quot;WGTP21&quot; &quot;WGTP22&quot; &quot;WGTP23&quot; &quot;WGTP24&quot; &quot;WGTP25&quot; &quot;WGTP26&quot; ## [37] &quot;WGTP27&quot; &quot;WGTP28&quot; &quot;WGTP29&quot; &quot;WGTP30&quot; &quot;WGTP31&quot; &quot;WGTP32&quot; ## [43] &quot;WGTP33&quot; &quot;WGTP34&quot; &quot;WGTP35&quot; &quot;WGTP36&quot; &quot;WGTP37&quot; &quot;WGTP38&quot; ## [49] &quot;WGTP39&quot; &quot;WGTP40&quot; &quot;WGTP41&quot; &quot;WGTP42&quot; &quot;WGTP43&quot; &quot;WGTP44&quot; ## [55] &quot;WGTP45&quot; &quot;WGTP46&quot; &quot;WGTP47&quot; &quot;WGTP48&quot; &quot;WGTP49&quot; &quot;WGTP50&quot; ## [61] &quot;WGTP51&quot; &quot;WGTP52&quot; &quot;WGTP53&quot; &quot;WGTP54&quot; &quot;WGTP55&quot; &quot;WGTP56&quot; ## [67] &quot;WGTP57&quot; &quot;WGTP58&quot; &quot;WGTP59&quot; &quot;WGTP60&quot; &quot;WGTP61&quot; &quot;WGTP62&quot; ## [73] &quot;WGTP63&quot; &quot;WGTP64&quot; &quot;WGTP65&quot; &quot;WGTP66&quot; &quot;WGTP67&quot; &quot;WGTP68&quot; ## [79] &quot;WGTP69&quot; &quot;WGTP70&quot; &quot;WGTP71&quot; &quot;WGTP72&quot; &quot;WGTP73&quot; &quot;WGTP74&quot; ## [85] &quot;WGTP75&quot; &quot;WGTP76&quot; &quot;WGTP77&quot; &quot;WGTP78&quot; &quot;WGTP79&quot; &quot;WGTP80&quot; When printing the design object or looking at the summary, the replicate weight type is re-iterated as Unstratified cluster jacknife (JK1) with 80 replicates and MSE variances and the variables are included. No weight or probability summary is included as was done in some other design objects. 5.2.4 Bootstrap method In bootstrap resampling, replicates are created by selecting random samples of the PSUs with replacement. If there are \\(M\\) PSUs in the sample, then each replicate will be created by selecting a random sample of \\(M\\) PSUs with replacement. Each replicate is created independently and the weights for each replicate are adjusted to reflect the population, generally using the same method as how the analysis weight was adjusted. The math A weighted estimate for the full sample is calculated as \\(\\hat{\\theta}\\) and then a weighted estimate for each replicate is calculated as \\(\\hat{\\theta}_r\\) for \\(R\\) replicates. Then the standard error of the estimate is calculated as: \\[se(\\hat{\\theta})=\\sqrt{\\alpha \\sum_{r=1}^R \\left( \\hat{\\theta}_r-\\hat{\\theta}\\right)^2}\\] The syntax If a dataset had WT0 for the main weight, 20 bootstrap weights indicated WT1, WT2, …, WT20, and \\(\\alpha=.02\\), use the following syntax: des_bs &lt;- dat %&gt;% as_survey_rep(weights = WT0, repweights= num_range(&quot;WT&quot;, 1:20), type=&quot;bootstrap&quot;, mse=TRUE, scale=.02) Note that the scale is usually provided in documentation and is a constant, so is not provided as a variable in the tibble. Example Returning to the api example, bootstrap weights were constructed for a one cluster design. 50 replicate weights were created on a dataset apiclus1_slim which has some familiar variables including cds, dnum, fpc, and pw but now additionally includes bootstrap weights pw1, …, pw50. The scale \\((\\alpha)\\) is \\(15/(14*49)=0.02186589\\) apiclus1_slim ## # A tibble: 183 × 54 ## cds dnum fpc pw pw1 pw2 pw3 pw4 pw5 pw6 pw7 ## &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 43693776… 61 757 33.8 33.8 0 0 33.8 0 33.8 0 ## 2 43693776… 61 757 33.8 33.8 0 0 33.8 0 33.8 0 ## 3 43693776… 61 757 33.8 33.8 0 0 33.8 0 33.8 0 ## 4 43693776… 61 757 33.8 33.8 0 0 33.8 0 33.8 0 ## 5 43693776… 61 757 33.8 33.8 0 0 33.8 0 33.8 0 ## 6 43693776… 61 757 33.8 33.8 0 0 33.8 0 33.8 0 ## 7 43693776… 61 757 33.8 33.8 0 0 33.8 0 33.8 0 ## 8 43693776… 61 757 33.8 33.8 0 0 33.8 0 33.8 0 ## 9 43693776… 61 757 33.8 33.8 0 0 33.8 0 33.8 0 ## 10 43693776… 61 757 33.8 33.8 0 0 33.8 0 33.8 0 ## # ℹ 173 more rows ## # ℹ 43 more variables: pw8 &lt;dbl&gt;, pw9 &lt;dbl&gt;, pw10 &lt;dbl&gt;, pw11 &lt;dbl&gt;, ## # pw12 &lt;dbl&gt;, pw13 &lt;dbl&gt;, pw14 &lt;dbl&gt;, pw15 &lt;dbl&gt;, pw16 &lt;dbl&gt;, ## # pw17 &lt;dbl&gt;, pw18 &lt;dbl&gt;, pw19 &lt;dbl&gt;, pw20 &lt;dbl&gt;, pw21 &lt;dbl&gt;, ## # pw22 &lt;dbl&gt;, pw23 &lt;dbl&gt;, pw24 &lt;dbl&gt;, pw25 &lt;dbl&gt;, pw26 &lt;dbl&gt;, ## # pw27 &lt;dbl&gt;, pw28 &lt;dbl&gt;, pw29 &lt;dbl&gt;, pw30 &lt;dbl&gt;, pw31 &lt;dbl&gt;, ## # pw32 &lt;dbl&gt;, pw33 &lt;dbl&gt;, pw34 &lt;dbl&gt;, pw35 &lt;dbl&gt;, pw36 &lt;dbl&gt;, … des_api1_bs &lt;- apiclus1_slim %&gt;% as_survey_rep(weights=pw, repweights=pw1:pw50, type=&quot;bootstrap&quot;, scale=0.02186589, mse=TRUE) des_api1_bs ## Call: Called via srvyr ## Survey bootstrap with 50 replicates and MSE variances. ## Sampling variables: ## - repweights: `pw1 + pw2 + pw3 + pw4 + pw5 + pw6 + pw7 + pw8 + pw9 + pw10 + pw11 + pw12 + pw13 + pw14 + pw15 + pw16 + pw17 + pw18 + pw19 + pw20 + pw21 + pw22 + pw23 + pw24 + pw25 + pw26 + pw27 + pw28 + pw29 + pw30 + pw31 + pw32 + pw33 + pw34 + pw35 + pw36 + pw37 + pw38 + pw39 + pw40 + pw41 + pw42 + pw43 + pw44 + pw45 + pw46 + pw47 + pw48 + pw49 + pw50` ## - weights: pw ## Data variables: cds (chr), dnum (int), fpc (dbl), pw (dbl), pw1 (dbl), ## pw2 (dbl), pw3 (dbl), pw4 (dbl), pw5 (dbl), pw6 (dbl), pw7 (dbl), pw8 ## (dbl), pw9 (dbl), pw10 (dbl), pw11 (dbl), pw12 (dbl), pw13 (dbl), ## pw14 (dbl), pw15 (dbl), pw16 (dbl), pw17 (dbl), pw18 (dbl), pw19 ## (dbl), pw20 (dbl), pw21 (dbl), pw22 (dbl), pw23 (dbl), pw24 (dbl), ## pw25 (dbl), pw26 (dbl), pw27 (dbl), pw28 (dbl), pw29 (dbl), pw30 ## (dbl), pw31 (dbl), pw32 (dbl), pw33 (dbl), pw34 (dbl), pw35 (dbl), ## pw36 (dbl), pw37 (dbl), pw38 (dbl), pw39 (dbl), pw40 (dbl), pw41 ## (dbl), pw42 (dbl), pw43 (dbl), pw44 (dbl), pw45 (dbl), pw46 (dbl), ## pw47 (dbl), pw48 (dbl), pw49 (dbl), pw50 (dbl) summary(des_api1_bs) ## Call: Called via srvyr ## Survey bootstrap with 50 replicates and MSE variances. ## Sampling variables: ## - repweights: `pw1 + pw2 + pw3 + pw4 + pw5 + pw6 + pw7 + pw8 + pw9 + pw10 + pw11 + pw12 + pw13 + pw14 + pw15 + pw16 + pw17 + pw18 + pw19 + pw20 + pw21 + pw22 + pw23 + pw24 + pw25 + pw26 + pw27 + pw28 + pw29 + pw30 + pw31 + pw32 + pw33 + pw34 + pw35 + pw36 + pw37 + pw38 + pw39 + pw40 + pw41 + pw42 + pw43 + pw44 + pw45 + pw46 + pw47 + pw48 + pw49 + pw50` ## - weights: pw ## Data variables: cds (chr), dnum (int), fpc (dbl), pw (dbl), pw1 (dbl), ## pw2 (dbl), pw3 (dbl), pw4 (dbl), pw5 (dbl), pw6 (dbl), pw7 (dbl), pw8 ## (dbl), pw9 (dbl), pw10 (dbl), pw11 (dbl), pw12 (dbl), pw13 (dbl), ## pw14 (dbl), pw15 (dbl), pw16 (dbl), pw17 (dbl), pw18 (dbl), pw19 ## (dbl), pw20 (dbl), pw21 (dbl), pw22 (dbl), pw23 (dbl), pw24 (dbl), ## pw25 (dbl), pw26 (dbl), pw27 (dbl), pw28 (dbl), pw29 (dbl), pw30 ## (dbl), pw31 (dbl), pw32 (dbl), pw33 (dbl), pw34 (dbl), pw35 (dbl), ## pw36 (dbl), pw37 (dbl), pw38 (dbl), pw39 (dbl), pw40 (dbl), pw41 ## (dbl), pw42 (dbl), pw43 (dbl), pw44 (dbl), pw45 (dbl), pw46 (dbl), ## pw47 (dbl), pw48 (dbl), pw49 (dbl), pw50 (dbl) ## Variables: ## [1] &quot;cds&quot; &quot;dnum&quot; &quot;fpc&quot; &quot;pw&quot; &quot;pw1&quot; &quot;pw2&quot; &quot;pw3&quot; &quot;pw4&quot; &quot;pw5&quot; ## [10] &quot;pw6&quot; &quot;pw7&quot; &quot;pw8&quot; &quot;pw9&quot; &quot;pw10&quot; &quot;pw11&quot; &quot;pw12&quot; &quot;pw13&quot; &quot;pw14&quot; ## [19] &quot;pw15&quot; &quot;pw16&quot; &quot;pw17&quot; &quot;pw18&quot; &quot;pw19&quot; &quot;pw20&quot; &quot;pw21&quot; &quot;pw22&quot; &quot;pw23&quot; ## [28] &quot;pw24&quot; &quot;pw25&quot; &quot;pw26&quot; &quot;pw27&quot; &quot;pw28&quot; &quot;pw29&quot; &quot;pw30&quot; &quot;pw31&quot; &quot;pw32&quot; ## [37] &quot;pw33&quot; &quot;pw34&quot; &quot;pw35&quot; &quot;pw36&quot; &quot;pw37&quot; &quot;pw38&quot; &quot;pw39&quot; &quot;pw40&quot; &quot;pw41&quot; ## [46] &quot;pw42&quot; &quot;pw43&quot; &quot;pw44&quot; &quot;pw45&quot; &quot;pw46&quot; &quot;pw47&quot; &quot;pw48&quot; &quot;pw49&quot; &quot;pw50&quot; As with other replicate design objects, when printing the object or looking at the summary, the replicate weights are provided along with the data variables. 5.3 Understanding survey design documentation SRS, stratified, and clustered designs are the backbone of sampling designs and the features are often combined in one design. Additionally, rather than using SRS for selection, other sampling mechanisms are commonly used such as probability proportional to size (PPS), systematic sampling, or selection with unequal probabilities which are briefly described here. In PPS sampling, a size measure is constructed for each unit - perhaps the population of the PSU or the number of occupied housing units, and then units with larger size measures are more likely to be sampled. Systematic sampling is commonly used to ensure representation across a population. Units are sorted by a feature and then every \\(k\\) units are selected from a random start point so the sample is spread across the population. In addition to PPS, other unequal probabilities of selection may be used. As an example, in a study of establishments that conducts a survey every year, an establishment that recently participated (e.g., participated last year) has a reduced chance of selection in a subsequent round to reduce the burden on the establishment. To learn more about sampling designs, refer to Valliant, Dever, and Kreuter (2013), Cox et al. (2011), Cochran (1977), and Deming (1991). A common method of sampling is to stratify PSUs, select PSUs within stratum using PPS selection, and then select units within the PSUs either with SRS or PPS. Reading survey documentation is an important first step of survey analysis to understand the design and variables necessary to specify the design. Good documentation will highlight the variables necessary to specify the design. This is often found in User’s Guides, methodology, analysis guides, or technical documentation. For example, the 2017-2019 National Survey of Family Growth (NSFG)9 had a stratified multi-stage area probability sample. Counties or collections of counties were the primary sampling units which were stratified by Census region/division, size (population), and MSA status. Within each stratum, PSUs were selected via PPS. At the second stage, neighborhoods were selected within the sampled PSUs using PPS selection. At the third stage, housing units were selected within the sampled neighborhoods. At the fourth stage, a person was randomly chosen within the selected housing units among eligible persons using unequal probabilities based on person’s age and sex. The public use file does not include all these levels of selection and instead includes pseudo-strata and pseudo-clusters which are the variables used in R to specify the design. As specified on page 4 of the documentation, the stratum variable is SEST, the cluster variable is SECU, and the weight variable is WGT2017_2019. Thus, to specify this design in R, one would use the following syntax: des_nsfg &lt;- nsfgdata %&gt;% as_survey_design(ids = SECU, strata = SEST, weights = WGT2017_2019) 5.4 Exercises The American National Election Studies (ANES) collect data before and after elections approximately every 4 years around the presidential election cycle. Each year with the data release, a user’s guide is also released10. What is the syntax for specifying the analysis of the full sample post-election data? svy_anes &lt;- anes_data %&gt;% as_survey_design(weight) The General Social Survey is a survey that has been administered since 1972 on social, behavioral, and attitudinal topics. The 2016-2020 GSS Panel codebook11 provides examples of setting up syntax in SAS and Stata but not R. How would you specify the design in R? svy_gss &lt;- gss_data %&gt;% as_survey_design(ids = VPSU_2, strata = VSTRAT_2, weights = WTSSNR_2) References "],["c06.html", "Chapter 6 Descriptive analyses in srvyr 6.1 Types of descriptive analyses 6.2 Deciding on descriptive analyses 6.3 Descriptive analysis using the {srvyr} package 6.4 Exercises", " Chapter 6 Descriptive analyses in srvyr Descriptive analyses describes and summarizes the basic quantitative information of survey data. Common descriptive analyses include the frequency of observations, distributions of responses, or the mean of a numeric variable. These analyses present large amounts of quantitative data in an understandable way and form the basis of every survey analysis. In addition to describing our data, we can use these analyses to compare across people or other units. Descriptive analyses help us identify potential errors and assess outliers. We gain crucial information for deciding on deeper analysis. In complex survey analysis, we must consider the available design and sampling elements when conducting descriptive analysis. This requires reading the survey documentation (as described in Chapter 5) to apply the appropriate sampling weights, PSUs, strata, and replicate weights. Neglecting to incorporate these elements can lead to inaccurate descriptive analyses. The functions in the {srvyr} package allow us to run descriptive analyses while applying design and sampling elements. We can run multiple calculations in the same command thanks to the ‘pipe-able’ functions. The package also provides consistent return types so we can use outputs with other packages like {ggplot2}. This chapter describes the types of descriptive analytics and the steps involved in running descriptive analysis with {srvyr}. Similarities between {dplyr} and {srvyr} functions One of the major advantages of using {srvyr} is that it applies {dplyr}-like syntax to the {survey} package. We can use pipes to specify a tbl_svy object, apply a function, and then take that output and feed it into the first argument of the next function. Functions follow the ‘tidy’ convention of snake_case functions names. # Example data manipulation using {srvyr} and pipes dstrata %&gt;% # A `tbl_svy` object summarize(api99_var = survey_var(api00), api99_sd = survey_sd(api00)) The functions in {srvyr} also play nicely with other tidyverse functions. If we wanted to create our survey object by selecting specific columns, we could use dplyr::select()’s special selection functions (such as starts_with(), one_of(), etc.). dstrata &lt;- dstrata %&gt;% as_survey_design( 1, strata = stype, fpc = fpc, weight = pw, variables = c(stype, starts_with(&quot;api&quot;)) ) We can use {dplyr} verbs such as mutate(), filter(), etc. on our survey object. dstrata &lt;- dstrata %&gt;% mutate(api_diff = api00 - api99) %&gt;% rename(api_students = api.stu) Instead of data frames or tibbles, {srvyr} functions are meant for tbl_svy objects. Attempting to run data manipulation on non-tbl_svy objects will result in an error: mtcars %&gt;% # An object of the type &#39;list&#39; summarize(survey_total()) ## Error in `summarize()`: ## ℹ In argument: `survey_total()`. ## Caused by error in `cur_svy()`: ## ! Survey context not set A few functions in {srvyr} parallel functions available in {dplyr}, such as srvyr::summarize() and srvyr::group_by(). Unlike {srvyr}-specific verbs, the package recognizes if you attempt to run these parallel functions on a non-survey object. It will not error and instead give you the equivalent output from {dplyr}: mtcars %&gt;% srvyr::summarize(mean_hp = mean(hp)) ## mean_hp ## 1 146.7 Because this book focuses on survey analysis, most of our pipes will stem from a survey object. We will not be including the namespace for each function (e.g., srvyr::summarize()). Several functions in {srvyr} must be called within srvyr::summarize(). Recall that dplyr::summarize() collapses many values down to a single summary: mtcars %&gt;% dplyr::summarize(mean_hp = mean(hp)) ## mean_hp ## 1 146.7 These verbs can be used in conjunction with group_by() or by/.by, applying the functions on a group-by-group basis to create grouped summaries. mtcars %&gt;% group_by(cyl) %&gt;% dplyr::summarize(mean_hp = mean(hp), .groups = &quot;drop&quot;) ## # A tibble: 3 × 2 ## cyl mean_hp ## &lt;dbl&gt; &lt;dbl&gt; ## 1 4 82.6 ## 2 6 122. ## 3 8 209. We use a similar setup to summarize data in {srvyr}. dstrata %&gt;% group_by(stype) %&gt;% summarize(api00_mean = survey_mean(api00), api00_median = survey_median(api00)) ## # A tibble: 3 × 5 ## stype api00_mean api00_mean_se api00_median api00_median_se ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 E 674. 12.5 671 20.7 ## 2 H 626. 15.5 635 21.6 ## 3 M 637. 16.6 648 24.1 Throughout the chapter, we’ll note when a {srvyr} function must be included within summarize(). 6.1 Types of descriptive analyses Descriptive analysis can be categorized into univariate and multivariate analysis, depending on the number of variables we include. Below, we describe the descriptive analysis for single or multiple variables and a description of the {srvyr} functions associated with the measures. In the next section, we will explain each of the functions in-depth. 6.1.1 Univariate analysis Univariate analysis examines a single variable at a time. A single variable has three categories of characteristics: distribution, central tendency, and dispersion. Each characteristic simplifies our dataset. Therefore, it is important to look at multiple characteristics rather than rely on a single one to describe the data. Measures of distribution Measures of distribution describe how often an event or response occurs. These measures include proportions and quantiles. Examples: the proportion of students in California who did or did not receive an award based on their Academic Performance score; the proportion of U.S. citizens who voted in the last election; the distribution of household income in India divided into quantiles The {srvyr} package includes several functions for determining measures of distribution. The survey_total() function calculates totals The survey_count() and survey_tally() functions calculate weighted observations by group The survey_prop() function calculates proportions The survey_quantile() function calculates quantiles The survey_ratio() function calculates ratios Measures of central tendency Measures of central tendency find the central (or average) responses. These include the mean, median, and mode. Examples: Average 2000 Academic Performance Index in California, the median house price in Canada The survey_mean() and survey_median() functions from {srvyr} calculate mean and median using survey data, respectively. These functions must be called from within summarize(). Measures of dispersion Measures of dispersion describe how data spreads around the central tendency. These measures include the range and standard deviation. Examples: The standard deviation of the 2000 Academic Performance Index in California, the range between the minimum and maximum electricity expenditure in Ohio The survey_var() and survey_sd() functions from the {srvyr} package calculate population variance and standard deviation using survey methods, respectively. 6.1.2 Bivariate/multivariate analysis Bivariate analysis concerns the relationship between two variables. Multivariate analysis studies the relationship between multiple variables. A common analysis includes correlation, which is a number between -1 and +1 that denotes the strength of the linear relationship between two variables. Examples: Relationship between academic performance scores in 1999 and 2000; relationship between age and income We can use the {srvyr} package’s survey_corr() function to calculate correlation and its variation using survey methods. 6.2 Deciding on descriptive analyses We select measures based on the type of variable we are analyzing. Variables are classified as categorical/nominal, ordinal, and interval/ratio. Categorical/nominal data: variables with levels or descriptions that cannot be ordered, such as region of the country (North, South, East, and West) Ordinal data: variables that can be ordered, such as those from a Likert scale (strongly disagree, disagree, agree, and strongly agree) Interval/ratio: variables that are counted or measured, such as the total cost of electricity Within interval/ratio data are discrete variables, whose values are whole numbers, such as number of children, and continuous variables, whose values can lie anywhere on an interval, such as weight. If our variable is categorical, such as gender or occupation, we might use frequency counts or percentages, while if the variable is continuous, such as income or age, we might use mean, median, or standard deviation. Choosing appropriate measures is important to reach valid conclusions. Different variable types have distinct properties and levels of measurement, and we cannot apply all measures to all variables. Our survey data may represent categorical variables using numeric codes. For example, the North, South, East, and West regions of the United States might be coded as 1, 2, 3, and 4, respectively. Though this is a categorical variable, this variable might be automatically read as numeric values when we import our data. This can lead to the common mistake of applying survey_mean() to all numeric columns in the dataset, including categorical values. This practice can lead to incorrect inferences because categorical variables lack a natural zero point or linear ordering, making measures like mean inappropriate. Instead, it is crucial to inspect the codebook, understand the type of variable, and choose appropriate measures such as frequency counts or percentages to describe the data across regions. 6.3 Descriptive analysis using the {srvyr} package 6.3.1 Setup Recall from Chapter 05 the general process for estimation with the {srvyr} package: Create a tbl_svy object using srvyr::as_survey_design() or srvyr::as_survey_rep(). Subset the data for subpopulations using dplyr::filter(), if needed. Specify domains of analysis using dplyr::group_by(), if needed. Within srvyr::summarize(), specify variables to calculate ,means, totals, proportions, quantiles, and more. Filtering should be done after creating the tbl_svy object using srvyr::as_survey_design() or srvyr::as_survey_rep() because these functions incorporate the survey design information into the resulting object. The Residential Energy Consumption Survey (RECS) provides data on energy consumption and expenditures. It is funded by Energy Information Administration and collects information through energy suppliers through in-person, phone, and web interviews. It has been fielded 14 times between 1950 and 2020. Topics include appliances, electronics, heating, air conditioning (A/C), temperatures, water heating, lighting, energy bills, respondent demographics, and energy assistance. The survey targets primary occupied housing units in the US. RECS uses Balanced Repeated Replication (BRR) to estimate the variances. The full sample information is available on the EIA website. To begin analyzing RECS, we create a tbl_svy object using srvyr::as_survey_design(): library(survey) # for survey analysis library(srvyr) # for tidy survey analysis library(readr) library(here) recs &lt;- read_rds(here::here(&quot;AnalysisData&quot;, &quot;recs_2015.rds&quot;)) recs_des &lt;- recs %&gt;% as_survey_rep( weights = NWEIGHT, repweights = starts_with(&quot;BRRWT&quot;), type = &quot;Fay&quot;, rho = 0.5, mse = TRUE ) 6.3.2 Count observations using survey methods with survey_count() With srvyr::survey_count(), we can calculate the number of observations or cases for a given variable or combination of variables. The syntax is very similar to the dplyr::count() syntax; however, as noted above, it can only be called on tbl_srvy() objects. Let’s explore the syntax: survey_count( x, ..., wt = NULL, sort = FALSE, name = &quot;n&quot;, .drop = dplyr::group_by_drop_default(x), vartype = c(&quot;se&quot;, &quot;ci&quot;, &quot;var&quot;, &quot;cv&quot;) ) The arguments are: x: a tbl_svy object created by as_survey ...: variables to group by, passed to group_by wt: a variable to weight on in addition to the survey weights, defaults to NULL sort: how to sort the variables, defaults to FALSE name: the name of the count variable, defaults to n .drop: whether to drop empty groups vartype: type(s) of variation estimate to calculate, defaults to se (standard error) The steps to use survey_count() are: Specify the sample design, Filter subsets using dplyr::filter(), if needed, Run survey_count(), specifying the required arguments within the function Let’s see the weighted count of responses in RECS: recs_des %&gt;% # Specify the sample design survey_count() # Run `survey_count()` ## # A tibble: 1 × 2 ## n n_se ## &lt;dbl&gt; &lt;dbl&gt; ## 1 118208250. 0.0320 There are 118,208,250 observations in the survey. srvyr::count() can take one or many variables. To calculate the number of observations for a combination of variables, such as Region and Division, we run the below: recs_des %&gt;% # Specify the required arguments within the function survey_count(Region, Division, name = &quot;N&quot;) ## # A tibble: 10 × 4 ## Region Division N N_se ## &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Northeast New England 5628844. 0.00642 ## 2 Northeast Middle Atlantic 15377694. 0.000130 ## 3 Midwest East North Central 18094391. 0.000274 ## 4 Midwest West North Central 8277344. 0.000113 ## 5 South South Atlantic 23474851. 0.00555 ## 6 South East South Central 7197189. 0.0240 ## 7 South West South Central 13769934. 0.000423 ## 8 West Mountain North 4246877. 0.000147 ## 9 West Mountain South 4266870. 0.0193 ## 10 West Pacific 17874256. 0.000481 When we run the crosstab, we see that there are 5,638,844 observations from the Northeast’s New England division, 15,377,694 from the Northeast’s Middle Atlantic division, and so on. 6.3.3 Calculate total sums using survey methods using survey_total() With srvyr::survey_total(), we can calculate the sum of numeric variable values. Let’s explore the syntax: survey_total( x, na.rm = FALSE, vartype = c(&quot;se&quot;, &quot;ci&quot;, &quot;var&quot;, &quot;cv&quot;), level = 0.95, deff = FALSE, df = NULL, ... ) x: a variable, expression, or empty na.rm: an indicator of whether missing values should be dropped, defaults to FALSE vartype: type(s) of variation estimate to calculate, defaults to se (standard error) level: a number or a vector indicating the confidence level, defaults to 0.95 deff: a logical value stating whether the design effect should be returned, defaults to FALSE df: for vartype = 'ci'), a numeric value indicating degrees of freedom for the t-distribution For the {srvyr} package, this defaults to NULL whereas the {survey} package defaults to Inf The steps to use survey_total() are: Specify the sample design, Specify the cross tab in group_by(), Within summarize, run survey_total(), specifying the required arguments within the function To calculate a population count estimate with survey_total(), we can run the below: recs_des %&gt;% summarize(survey_total(), .groups = &quot;drop&quot;) ## # A tibble: 1 × 2 ## coef `_se` ## &lt;dbl&gt; &lt;dbl&gt; ## 1 118208250. 0.0320 Note that the result from recs_des %&gt;% summarize(survey_total(), .groups = \"drop\") is equivalent to the survey_count() call. However, the survey_total() function is called within summarize, where as survey_count(), like dplyr::count(), is not. The differences between survey_total() and survey_count() is more evident when specifying numeric variables to sum. Let’s sum the total cost of electricity in whole dollars from variable DOLLAREL. We also calculate an unweighted estimate using unweighted. recs_des %&gt;% summarize( elec_bill = survey_total(DOLLAREL), elec_unweight = unweighted(sum(!is.na(DOLLAREL))), .groups = &quot;drop&quot; ) ## # A tibble: 1 × 3 ## elec_bill elec_bill_se elec_unweight ## &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; ## 1 162495237023. 1666895091. 5686 $162,495,237,023 was spent on electricity. The unweighted sum is $5686. Since we are using the {srvyr} package, we can use group_by() to calculate the cost of electricity by different groups. Let’s see how much the cost of electricity in whole dollars differed between regions: recs_des %&gt;% group_by(Region) %&gt;% cascade(elec_bill = survey_total(!is.na(DOLLAREL))) ## # A tibble: 5 × 3 ## Region elec_bill elec_bill_se ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Northeast 21006538. 0.00644 ## 2 Midwest 26371735. 0.000251 ## 3 South 44441974. 0.0252 ## 4 West 26388003. 0.0191 ## 5 &lt;NA&gt; 118208250. 0.0320 The Northeast spent $28,271,369,286 on electricity, the Midwest spent $31,527,659,004, the South spent $72,463,508,778, and the West spent $30,232,699,955. 6.3.4 Calculate mean/proportion using survey methods with survey_mean() and survey_prop() The srvyr::survey_mean() and survey_prop() functions calculate the means (of continuous variables) and proportions (of categorical variables) of survey data while accounting for complex survey design. Like survey_total(), they are called within summarize(). Let’s explore the syntax: survey_mean( x, na.rm = FALSE, vartype = c(&quot;se&quot;, &quot;ci&quot;, &quot;var&quot;, &quot;cv&quot;), level = 0.95, proportion = FALSE, prop_method = c(&quot;logit&quot;, &quot;likelihood&quot;, &quot;asin&quot;, &quot;beta&quot;, &quot;mean&quot;), deff = FALSE, df = NULL, ... ) survey_prop( vartype = c(&quot;se&quot;, &quot;ci&quot;, &quot;var&quot;, &quot;cv&quot;), level = 0.95, proportion = FALSE, prop_method = c(&quot;logit&quot;, &quot;likelihood&quot;, &quot;asin&quot;, &quot;beta&quot;, &quot;mean&quot;), deff = FALSE, df = NULL, ... ) The steps involved are: Specify the sample design, Specify the cross tab in group_by(), Run survey_mean() or survey_prop() within summarize() We can calculate the weighted average cost of electricity for each region in the U.S.: recs_des %&gt;% group_by(Region) %&gt;% summarize(elec_bill = survey_mean(DOLLAREL), .groups = &quot;drop&quot;) ## # A tibble: 4 × 3 ## Region elec_bill elec_bill_se ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Northeast 1346. 34.2 ## 2 Midwest 1196. 20.2 ## 3 South 1631. 25.3 ## 4 West 1146. 32.3 On average, respondents from the Northeast spent $1346 on electricity. In the Midwest, they spent $1196, in the South they spent $1631, and finally, $1146 in the West. We use srvyr::survey_prop() to estimate the proportion of categorical variables in a survey. recs_des %&gt;% group_by(Region) %&gt;% summarize(survey_prop(), .groups = &quot;drop&quot;) ## When `proportion` is unspecified, `survey_prop()` now defaults to `proportion = TRUE`. ## ℹ This should improve confidence interval coverage. ## This message is displayed once per session. ## # A tibble: 4 × 3 ## Region coef `_se` ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Northeast 0.178 6.84e-11 ## 2 Midwest 0.223 6.07e-11 ## 3 South 0.376 1.43e-10 ## 4 West 0.223 1.37e-10 17.8% of the observations are in the Northeast, 22.3% in the Midwest, and so on. survey_prop() is essentially the same as using survey_mean() with a categorical variable and without specifying a numeric variable in the x argument. The following code will give us the same results as above: recs_des %&gt;% group_by(Region) %&gt;% summarize(survey_mean(), .groups = &quot;drop&quot;) ## # A tibble: 4 × 3 ## Region coef `_se` ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Northeast 0.178 6.84e-11 ## 2 Midwest 0.223 6.07e-11 ## 3 South 0.376 1.43e-10 ## 4 West 0.223 1.37e-10 6.3.5 The proportion argument Note that when we run survey_prop(), we see a message that says: When `proportion` is unspecified, `survey_prop()` now defaults to `proportion = TRUE`. ℹ This should improve confidence interval coverage. If the proportion argument is not specified in the function call, survey_prop() defaults to proportion = TRUE. This change was made to improve the accuracy of the confidence intervals calculated by the function since the function defaulted to proportion = FALSE in the past. The warning message is intended to alert users to this change, and to suggest that any code relying on the previous default setting may need to be updated. 6.3.6 Print total overall numbers in our output If we want to see the total overall numbers from our survey_mean() function, we can use cascade. cascade is similar to summarize but calculates summary statistics for the total of a group in addition to each group. recs_des %&gt;% group_by(ACUsed) %&gt;% cascade(ElBill = survey_mean(DOLLAREL, na.rm = TRUE)) ## # A tibble: 3 × 3 ## ACUsed ElBill ElBill_se ## &lt;lgl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 FALSE 972. 25.8 ## 2 TRUE 1435. 15.8 ## 3 NA 1375. 14.1 Note that the overall average electricity cost appears as NA. The average electricity cost for those who do not use AC is $972. For those who do use AC, it is $1435. Overall, it is $1375. 6.3.7 Removing NA for calculating results If we run the example below, we get an error: recs_des %&gt;% summarize(TD_mean = survey_mean(x = SummerTempDay)) ## Error in `dplyr::summarise()`: ## ℹ In argument: `TD_mean = survey_mean(x = SummerTempDay)`. ## Caused by error in `svrVar()`: ## ! All replicates contained NAs Because of the NA in SummerTempDay, survey_mean() cannot calculate the average temperature. We can fix this with the argument na.rm = TRUE: recs_des %&gt;% summarize(TD_mean = survey_mean(x = SummerTempDay, na.rm = TRUE)) ## # A tibble: 1 × 2 ## TD_mean TD_mean_se ## &lt;dbl&gt; &lt;dbl&gt; ## 1 72.4 0.0793 The mean temperature set in a summer day in 72.4 degrees. 6.3.8 Calculate proportions with confidence intervals We calculate confidence intervals by setting the vartype to ci within summarize when using survey_mean() or survey_mean(). The confidence intervals provide us with an upper and lower column for each method. recs_des %&gt;% group_by(Urbanicity) %&gt;% summarize(pd = survey_prop(vartype = &quot;ci&quot;) %&gt;% round(4)) ## # A tibble: 3 × 4 ## Urbanicity pd pd_low pd_upp ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Urban Area 0.696 0.652 0.736 ## 2 Urban Cluster 0.106 0.082 0.136 ## 3 Rural 0.198 0.171 0.229 69.6% of the responses are from people in urban areas, with a lower confidence interval bound of 65.2% and a upper confidence interval bound of 73.62%. We can change the proportion method by adding prop_method. The available options are \"logit\", \"likelihood\", \"asin\", \"beta\", and \"mean\". As noted above, svy_prop() defaults to proportion = TRUE. Here, we rerun the previous function using the logit proportion method and with proportion = FALSE. recs_des %&gt;% group_by(Urbanicity) %&gt;% summarize(pl = survey_prop( proportion = FALSE, prop_method = &quot;xlogit&quot;, vartype = &quot;ci&quot; ) %&gt;% round(4)) ## # A tibble: 3 × 4 ## Urbanicity pl pl_low pl_upp ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Urban Area 0.696 0.653 0.738 ## 2 Urban Cluster 0.106 0.0792 0.133 ## 3 Rural 0.198 0.169 0.228 Our results have changed slightly: 69.6% of the responses are from people in urban areas, with a lower confidence interval bound of 65.3% and a upper confidence interval bound of 73.8%. 6.3.9 Other functions that use survey methods The {srvyr} package includes other functions for summarizing datasets, as mentioned in the section on types of descriptive analysis. Center: survey_mean(), survey_median() Count: survey_count(), survey_total() Distribution: survey_ratio(), survey_prop() Range: survey_quantile() Variance: survey_var(), survey_sd() We will not cover each one in depth; however, the same principles that we covered above apply. 6.3.10 Calculate conditional proportions with more than one group Specifying more than one group calculates conditional proportions. Say we wanted to know the proportion of respondents who live in rural regions in the Northeast. After the tbl_svy object, we specify the two variables we want to calculate proportions for: recs_des %&gt;% group_by(Region, Urbanicity) %&gt;% summarize( p = survey_mean(), N = survey_total(), n = unweighted(n()), .groups = &quot;drop&quot; ) ## # A tibble: 12 × 7 ## Region Urbanicity p p_se N N_se n ## &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; ## 1 Northeast Urban Area 0.742 0.0578 15595476. 1215149. 551 ## 2 Northeast Urban Cluster 0.103 0.0363 2153686. 763191. 86 ## 3 Northeast Rural 0.155 0.0310 3257375. 651505. 157 ## 4 Midwest Urban Area 0.652 0.0510 17198016. 1343922. 844 ## 5 Midwest Urban Cluster 0.135 0.0344 3549498. 907055. 194 ## 6 Midwest Rural 0.213 0.0292 5624221. 771356. 289 ## 7 South Urban Area 0.631 0.0337 28064377. 1495982. 1277 ## 8 South Urban Cluster 0.120 0.0216 5350796. 962050. 223 ## 9 South Rural 0.248 0.0287 11026801. 1274124. 510 ## 10 West Urban Area 0.810 0.0374 21376390. 987240. 1256 ## 11 West Urban Cluster 0.0554 0.0168 1460669. 444588. 95 ## 12 West Rural 0.135 0.0264 3550944. 696556. 204 From the table, we see that the weighted proportion is 15.5%. Note that column p is the proportion of respondents in rural areas by region. That is, it is the weighted number of people in rural areas in the Northeast (3,257,375), divided by the weighted number of respondents in the Northeast (15,595,476 + 2,153,686 + 3,257,375). 6.3.11 Calculate joint proportions with more than one group When we want to calculate proportions for multiple variables together as if they were a single variable, we use {srvyr}’s interact. We use interact within group_by() to calculate the joint proportions of two or more variables. For example, if we have a survey dataset with variables such as age, gender, and income, we could use interact to create summary statistics for each combination of age and gender, or for each combination of income and gender. We can examine how these variables are related to each other, and whether there are any differences or similarities between different groups. In the example below, we calculate Region and Urbanicity together: recs_des %&gt;% group_by(interact(Region, Urbanicity)) %&gt;% summarize(p = survey_mean(), N = survey_total(), .groups = &quot;drop&quot;) ## # A tibble: 12 × 6 ## Region Urbanicity p p_se N N_se ## &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Northeast Urban Area 0.132 0.0103 15595476. 1215149. ## 2 Northeast Urban Cluster 0.0182 0.00646 2153686. 763191. ## 3 Northeast Rural 0.0276 0.00551 3257375. 651505. ## 4 Midwest Urban Area 0.145 0.0114 17198016. 1343922. ## 5 Midwest Urban Cluster 0.0300 0.00767 3549498. 907055. ## 6 Midwest Rural 0.0476 0.00653 5624221. 771356. ## 7 South Urban Area 0.237 0.0127 28064377. 1495982. ## 8 South Urban Cluster 0.0453 0.00814 5350796. 962050. ## 9 South Rural 0.0933 0.0108 11026801. 1274124. ## 10 West Urban Area 0.181 0.00835 21376390. 987240. ## 11 West Urban Cluster 0.0124 0.00376 1460669. 444588. ## 12 West Rural 0.0300 0.00589 3550944. 696556. Running survey_mean() with interact, we see that 13.2% of the dataset is from the Northeast Urban Area, wherewas 0.182% is from the Northeast Urban Cluster. Since interact groups by multiple variables as if they were a single variable, the proportions in column p sum to 100% across more than a single grouping variable. recs_des %&gt;% group_by(interact(Region, Urbanicity)) %&gt;% summarize(p = survey_mean(), N = survey_total(), .groups = &quot;drop&quot;) %&gt;% summarize(p_sum = sum(p)) ## # A tibble: 1 × 1 ## p_sum ## &lt;dbl&gt; ## 1 1 6.3.12 Calculate proportions with design effects Note above that functions survey_total(), survey_mean(), and survey_prop() have the argument deff. deff stands for Design Effect, the ratio of two variances. Use deff = TRUE argument to specify whether to return the design effect. Calculating proportions with design effects is important when analyzing survey data that has been collected using a complex sampling design. Since a complex sampling design means that the probability of selecting each individual in the sample is different, this can lead to the observations in the sample being correlated with each other. Design effects account for this correlation and adjust the standard errors of estimates, which in turn can affect the significance of test statistics and the accuracy of confidence intervals. Calculating proportions with design effects is important because it helps to produce accurate estimates of population proportions that account for the complex nature of the survey data. Deff compares the variance of the current samplng, including its design elements, to the variance of a hypothetical simple random sample (SRS) of the same size. A Deff value less than 1 indicates that the sample design is more efficient than an SRS of the same size. recs_des %&gt;% group_by(interact(Region, Urbanicity)) %&gt;% summarize(p = survey_mean(deff = TRUE), N = survey_total(), .groups = &quot;drop&quot;) ## # A tibble: 12 × 7 ## Region Urbanicity p p_se p_deff N N_se ## &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Northeast Urban Area 0.132 0.0103 5.25 15595476. 1215149. ## 2 Northeast Urban Cluster 0.0182 0.00646 13.2 2153686. 763191. ## 3 Northeast Rural 0.0276 0.00551 6.44 3257375. 651505. ## 4 Midwest Urban Area 0.145 0.0114 5.91 17198016. 1343922. ## 5 Midwest Urban Cluster 0.0300 0.00767 11.5 3549498. 907055. ## 6 Midwest Rural 0.0476 0.00653 5.34 5624221. 771356. ## 7 South Urban Area 0.237 0.0127 5.03 28064377. 1495982. ## 8 South Urban Cluster 0.0453 0.00814 8.71 5350796. 962050. ## 9 South Rural 0.0933 0.0108 7.81 11026801. 1274124. ## 10 West Urban Area 0.181 0.00835 2.68 21376390. 987240. ## 11 West Urban Cluster 0.0124 0.00376 6.59 1460669. 444588. ## 12 West Rural 0.0300 0.00589 6.78 3550944. 696556. Rerunning survey_mean(), we see that p_deff is greater than 1 for the proportions. It is common for Deff to be greater than 1 when using complex sampling designs (such as in the case of RECS). A high Deff can occur due to various factors, such as stratification, clustering, or unequal selection probabilities, which are often used to improve the precision of estimates or to reduce sampling costs. These design features can increase the complexity of the sample design and lead to a higher Deff, but they can also improve the accuracy and representativeness of the survey estimates. 6.4 Exercises "],["c07.html", "Chapter 7 Statistical testing 7.1 Chapter Set-Up 7.2 Comparison of Proportions and Means 7.3 Chi-Square Tests", " Chapter 7 Statistical testing When analyzing results from a survey, the point estimates described in Chapter 6 are helpful for understanding the data at a high level, but researchers and the public often want to make comparisons between different groups. These comparisons are calculated through statistical testing where we compare the point estimates and the variance estimates of each statistic to see if there are statistically significant differences. The general idea of statistical testing is the same for data obtained through surveys and data obtained through other methods, but the importance lies in ensuring the variance is calculated correctly. Functions in the {survey} packages allow for the correct estimation of the variances. This chapter will cover the following statistical tests with survey data and functions: Comparison of proportions svyttest() Comparison of means svyttest() Goodness of fit tests svygofchisq() Tests of independence svychisq() Tests of homogeneity svychisq() Up to this point, the functions that we’ve provided have used the wrappers from the {srvyr} package. This means that the functions work with tidyverse syntax. However, the functions in this chapter do not have wrappers from the {srvyr} package and are instead used directly from the {survey} package. This means that the design object is not the first argument and that to use these functions with the magrittr pipe %&gt;% and tidyverse syntax we will need to use dot (.) notation. Functions that work with the magrittr pipe %&gt;% have the first argument as data. When data is run, it automatically places anything to the left of the pipe into the first argument of the function to the right of the pipe. For example, if we wanted to take the mtcars data and filter to only cars with 6 cylinders we can write the code in one of three ways: filter(mtcars, cyl == 6) mtcars %&gt;% filter(cyl == 6) mtcars %&gt;% filter(., cyl == 6) mtcars %&gt;% filter(.data= ., cyl == 6) Each of these lines of code will produce the same output since the argument that takes the data is in the first spot in filter(). Those who have worked with the tidyverse, the first two are probably familiar. The third option functions the same way as the second one, but is explicit that mtcars goes in the first argument and the fourth option indicates that mtcars is going into the named argument of .data. Here we’re telling R to take what’s on the left side of the pipe mtcars and pipe it into the spot with the dot (.)—the first argument. In functions that are not part of the tidyverse, the data argument may be in a different spot in the functions. For example, in svyttest() the data argument is in the second spot, which means we need to place the dot (.) in the second spot and not the first. For example: svydata_des %&gt;% svyttest(x~y, .) Placing the dot (.) in the second argument spot, indicates that the survey design object svydata_svy should be used in the second argument and not the first (which is the default). Alternatively, named arguments could be used to place the dot first as in the following: svydata_des %&gt;% svyttest(design = ., x~y) 7.1 Chapter Set-Up For this chapter, we will be using the same data as we did in 6: ANES and RECS. As a reminder, we will need to create survey design objects to work with. These design objects ensure that the variance estimation is calculated accurately, and thus we can accurately determine statistical significance. First, make sure install and load the following packages: library(tidyverse) library(survey) # for survey analysis library(srvyr) # for tidy survey analysis library(readr) library(here) library(gt) # for output of readable tables Second, we need to read in the data and create the design objects. Here is how to create the design object for the ANES data, remember that we need to adjust the weight so it sums to the population instead of the sample. We do that by multiplying the weights (see the ANES methodology documentation for more information). anes &lt;- read_rds(here(&quot;AnalysisData&quot;, &quot;anes_2020.rds&quot;)) %&gt;% mutate(Weight=Weight/sum(Weight)*231592693) anes_des &lt;- anes %&gt;% as_survey_design(weights = Weight, strata = Stratum, ids = VarUnit, nest = TRUE) Here is how to create the design object for the RECS data: recs &lt;-read_rds(here(&quot;AnalysisData&quot;, &quot;recs_2015.rds&quot;)) recs_des &lt;- recs %&gt;% as_survey_rep(weights = NWEIGHT, repweights = starts_with(&quot;BRRWT&quot;), type = &quot;Fay&quot;, rho = 0.5, mse = TRUE) 7.2 Comparison of Proportions and Means To compare two proportions or means, we use t-tests. This allows us to determine if one proportion or mean is statistically different from the other. T-tests are commonly used to determine if a single estimate is different from a known value (e.g., 0 or 50%) or to compare two group means (e.g., males vs females). For comparing a single estimate to a known value, this is called a one sample t-test and we can set up the hypothesis test as: \\(H_0: \\mu = 0\\) where \\(\\mu\\) is the is the mean outcome and \\(0\\) is the value we are comparing it to \\(H_A: \\mu \\neq 0\\) For comparing two estimates, this is called a two sample t-test and we can set up the hypothesis test as: \\(H_0: \\mu_1 = \\mu_2\\) where \\(\\mu_i\\) is the is the mean outcome for group \\(i\\) \\(H_A: \\mu_1 \\neq \\mu_2\\) Two sample t-tests can also be paired or unpaired. If the data come from two different populations (e.g., males vs females), then the t-test run will be an unpaired or independent samples t-test. Paired t-tests occur when the data come from the same population. This is commonly seen with data taken from the same population in two different time periods (e.g., before and after an intervention). The difference between using t-tests with non-survey data and with survey data is based on the underlying variance estimation difference. Chapter 5 provides the detailed overview of the math behind the mean and sampling error calculations for various sample designs. The functions in the {survey} package will account for these nuances provided the design object is correctly defined. 7.2.1 Syntax When we do not have survey data, we may be able to use the t.test() function. This function does not allow for weights or the variance structure to be accounted for with survey data. Therefore, when using survey data, we need to use the svyttest() function. Many of the arguments are the same between the two functions, but there are a two key differences: We need to use the survey design object, instead of data We can only use a formula and not separate x and y data Here is the syntax for the svyttest() function: svyttest(formula, design, na.rm=FALSE, level=0.95, ...) Notice that the first argument here is the formula and not the design. This means that we must use the dot (.) if we pipe in the survey design object (as described at the beginning of this chapter). The formula argument can take on a couple of different forms depending on what it is that we are measuring. Here are a few common scenarios: One-sample t-test: Comparison to 0: var ~ 0, where var is the measure of interest and 0 is the value we are comparing it to. For example, we could test if the proportion of the population that has blue eyes is different from 0. Comparison to a different value: I(var - value) ~ 0, where var is the measure of interest and value is what we are comparing to. We need to use the I() function, to tell the program to calculate the difference between the variable and the comparison value prior to testing. For example, we could test if the proportion of the population that has blue eyes is different from 25% by using I(var - 0.25)~0. Two-sample t-test: Unpaired: 2 level grouping variable: var ~ groupVar, where var is the measure of interest and groupVar is a variable with two categories. For example, we could test if the proportion of the population that has blue eyes is different for children aged 5-10 years old compared to children under 5 years old. 3+ level grouping variable: var ~ I(groupVar == level), where var is the measure of interest, groupVar is the categorical variable, and level is the category level to isolate. Again we need to use the I() function to tell the program to isolate the category before doing the comparison across groups. For example, we could test if the test scores in one classroom differed from all other classrooms. Paired: I(var_1 - var_2) ~ 0, where var_1 is the first variable of interest and var_2 is the second variable of interest. We again will have to use the I() function to have the program calculate the difference between the two variables before comparing it against 0. For example, we could test if test scores on a subject differed between the start and the end of a course. Additionally, the na.rm argument defaults to FALSE, which means if any data is missing the t-test will not compute. Throughout this chapter we will always set na.rm=TRUE, but before analyzing the survey data, make sure to review the notes provided in Chapter ?? to better understand how to handle missing data. Finally, the level argument is \\(1-\\alpha\\), or the amount of type 1 error. The default is \\(0.95\\). 7.2.2 Examples Let’s walk through a few examples using the ANES and RECS data. See Section 7.1 above to set up the design objects. Example 1: One-sample t-test ANES asked respondents if they voted for president in the 2020 election. In our data, we’ve called this variable VotedPres2020. Let’s look at the proportion of the U.S. voting eligible population that voted for president in 2020 using the survey_prop() function we learned in Chapter 6. voteprop&lt;-anes_des %&gt;% group_by(VotedPres2020) %&gt;% summarize(survey_prop()) voteprop ## # A tibble: 3 × 3 ## VotedPres2020 coef `_se` ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Yes 0.772 0.00757 ## 2 No 0.227 0.00763 ## 3 &lt;NA&gt; 0.00113 0.000464 Based on this, we see that 77.2% of the U.S. voting eligible population voted for president in 2020. If we wanted to know how this compares to other countries, we can use svyttest(). For example, if we know that the voter turnout in Germany in the 2017 general election was 76.2%, we could set up our hypothesis as: \\(H_0: p = 0.762\\) where \\(p\\) is the proportion of U.S. voting eligible population that voted for president in 2020 \\(H_A: p \\neq 0.762\\) To conduct this in R, we would then use the svyttest() function: ttest_ex1&lt;-anes_des %&gt;% svyttest(formula=I(I(VotedPres2020==&quot;Yes&quot;)-0.762)~0, design=., na.rm=TRUE) ttest_ex1 ## ## Design-based one-sample t-test ## ## data: I(I(VotedPres2020 == &quot;Yes&quot;) - 0.762) ~ 0 ## t = 1.4, df = 50, p-value = 0.2 ## alternative hypothesis: true mean is not equal to 0 ## 95 percent confidence interval: ## -0.004729 0.025899 ## sample estimates: ## mean ## 0.01058 Note that because VotedPres2020 is a factor, we need to specify which level we are interested in. In this case we want to isolate those that did vote for president in 2020. The output from the svyttest() function can be a bit hard to read. Using the {broom} package from the tidyverse we can clean up the output into a tibble to more easily what the test is telling us. broom::tidy(ttest_ex1) ## # A tibble: 1 × 8 ## estimate statistic p.value parameter conf.low conf.high method ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 0.0106 1.39 0.171 50 -0.00473 0.0259 Design-based … ## # ℹ 1 more variable: alternative &lt;chr&gt; The estimate that is presented here is actually the difference between the U.S. proportion and the Germany proportion we are comparing to. We can see that there is a difference of 1.06 percentage points. Additionally, we can see the t-statistic value in the statistic column is 1.39 and the p-value is 0.171. These results indicate that the U.S. and Germany have similar voter turnout. Example 2: One-sample t-test RECS asks respondents to indicate what temperature they set their house to during the summer at night. In our data, we’ve called this variable SummerTempNight. If we want to see if the U.S. household sets their temperature at a value different from 68\\(^\\circ\\)F, we could set up the hypothesis as follows: \\(H_0: \\mu = 68\\) where \\(\\mu\\) is the is average temperature U.S. Households set their thermostat to in the summer at night \\(H_A: \\mu \\neq 68\\) To conduct this in R, we would then use the svyttest() function, and the I() function in the formula: ttest_ex2&lt;-recs_des %&gt;% svyttest(formula=I(SummerTempNight-68)~0, design=., na.rm=TRUE) ttest_ex2 ## ## Design-based one-sample t-test ## ## data: I(SummerTempNight - 68) ~ 0 ## t = 41, df = 94, p-value &lt;2e-16 ## alternative hypothesis: true mean is not equal to 0 ## 95 percent confidence interval: ## 3.425 3.773 ## sample estimates: ## mean ## 3.599 The estimate in this case differs from example one in that the estimate is not displaying \\(\\mu\\) but rather \\(\\mu - 68\\). If we wanted the average we could do one of the following: recs_des %&gt;% summarize(mu=survey_mean(SummerTempNight,na.rm=TRUE)) ## # A tibble: 1 × 2 ## mu mu_se ## &lt;dbl&gt; &lt;dbl&gt; ## 1 71.6 0.0878 Or, we could take our t-test estimate (ttest_ex2$estimate) and add it to 68: ttest_ex2$estimate + 68 ## mean ## 71.6 The result is the same in both methods, so we see that the average temperature U.S. Households set their thermostat to in the summer at night is 71.6. Looking at the output from the svyttest(), the t-statistic is 41.013 and the p-value is 8.6732^{-62}, indicating that the average is statistically different from 68\\(^\\circ\\)F at an \\(\\alpha\\) level of \\(0.05\\). Example 3: Unpaired two-sample t-test Two additional variables we have on the RECS data are the electric bill cost (DOLLAREL) and whether the house used AC or not (ACUsed). If we want to know if the U.S. households that used AC had higher electrical bills compared to those that did not, we could set up the hypothesis as follows: \\(H_0: \\mu_{AC} = \\mu_{noAC}\\) where \\(\\mu_{AC}\\) is the electrical bill cost for U.S. households that used AC and \\(\\mu_{noAC}\\) is the electrical bill cost for U.S. household that did not use AC \\(H_A: \\mu_{AC} \\neq \\mu_{noAC}\\) Let’s take a quick look at the data to see the format the data are in: recs_des %&gt;% group_by(ACUsed) %&gt;% summarize(mean=survey_mean(DOLLAREL,na.rm=TRUE)) ## # A tibble: 2 × 3 ## ACUsed mean mean_se ## &lt;lgl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 FALSE 972. 25.8 ## 2 TRUE 1435. 15.8 To conduct this in R, we would then use svyttest(): ttest_ex3&lt;-recs_des %&gt;% svyttest(formula=DOLLAREL~ACUsed, design=., na.rm=TRUE) ttest_ex3 ## ## Design-based t-test ## ## data: DOLLAREL ~ ACUsed ## t = 15, df = 94, p-value &lt;2e-16 ## alternative hypothesis: true difference in mean is not equal to 0 ## 95 percent confidence interval: ## 400.7 525.1 ## sample estimates: ## difference in mean ## 462.9 The results indicate that the difference in electrical bill for those that used AC and those that did not is on average $462.87. The difference does appear to be statistically significant as the t-statistic is 14.772 and the p-value is 3.0763^{-26}. Example 4: Paired two-sample t-test To conduct a paired t-test that looks at differences at two time points, we use the same I() notatation we’ve been using. For example, let’s say we want to test whether the temperature that U.S. households set their thermostat to differs depending on the season (comparing summer temperature and winter temperature). We could set up the hypothesis as follows: \\(H_0: \\mu_{summer} = \\mu_{winter}\\) where \\(\\mu_{summer}\\) is the temperature that U.S. households set their thermostat to during summer nights, and \\(\\mu_{winter}\\) is the temperature that U.S. households set their thermostat to during winter nights \\(H_A: \\mu_{summer} \\neq \\mu_{winter}\\) To conduct this in R, we would then use svyttest() and I(): ttest_ex4&lt;-recs_des %&gt;% svyttest(design=., formula=I(SummerTempNight-WinterTempNight)~0, na.rm=TRUE) ttest_ex4 ## ## Design-based one-sample t-test ## ## data: I(SummerTempNight - WinterTempNight) ~ 0 ## t = 29, df = 94, p-value &lt;2e-16 ## alternative hypothesis: true mean is not equal to 0 ## 95 percent confidence interval: ## 2.995 3.434 ## sample estimates: ## mean ## 3.215 U.S. households set their thermostat on average 3.2\\(^\\circ\\)F warmer in summer nights than winter nights, and it is statistically significant (t=29.0788, p-value=8.8271^{-49}). 7.2.3 Exercises Here are some exercises for practicing conducting t-tests using svyttest(): Using the RECS data, do more than 50% of U.S. household use AC (ACUsed)? ttest_solution1&lt;-recs_des %&gt;% svyttest(design=., formula=I((ACUsed==TRUE)-0.5)~0, na.rm=TRUE) ttest_solution1 ## ## Design-based one-sample t-test ## ## data: I((ACUsed == TRUE) - 0.5) ~ 0 ## t = 45, df = 94, p-value &lt;2e-16 ## alternative hypothesis: true mean is not equal to 0 ## 95 percent confidence interval: ## 0.3533 0.3861 ## sample estimates: ## mean ## 0.3697 Using the RECS data, does the average temperature that U.S. households set their thermostats to differ between the day and night in the winter (WinterTempDay and WinterTempNight)? ttest_solution2&lt;-recs_des %&gt;% svyttest(design=., formula=I(WinterTempDay-WinterTempNight)~0, na.rm=TRUE) ttest_solution2 ## ## Design-based one-sample t-test ## ## data: I(WinterTempDay - WinterTempNight) ~ 0 ## t = 31, df = 94, p-value &lt;2e-16 ## alternative hypothesis: true mean is not equal to 0 ## 95 percent confidence interval: ## 1.787 2.028 ## sample estimates: ## mean ## 1.907 Using the ANES data, does the average age (Age) of those who voted for Biden in 2020 (VotedPres2020_selection) differ from those that voted for another candidate? ttest_solution3&lt;-anes_des %&gt;% svyttest(design=., formula=Age~I(VotedPres2020_selection==&quot;Biden&quot;), na.rm=TRUE) ttest_solution3 ## ## Design-based t-test ## ## data: Age ~ I(VotedPres2020_selection == &quot;Biden&quot;) ## t = -6, df = 50, p-value = 2e-07 ## alternative hypothesis: true difference in mean is not equal to 0 ## 95 percent confidence interval: ## -4.824 -2.395 ## sample estimates: ## difference in mean ## -3.61 7.3 Chi-Square Tests Chi-square tests (\\(\\chi^2\\)) allow us to examine multiple proportions using goodness-of-fit test, test of independence, or test of homogeneity. All three of these tests the same \\(\\chi^2\\) distributions but with slightly different underlying assumptions. First, goodness-of-fit tests are used when comparing observed data to expected data. For example, this could be used to determine if respondent demographics (the observed data) match known population information (the expected data). In this case, we can set up the hypothesis test as: \\(H_0: p_1 = \\pi_1, ~ p_2 = \\pi_2, ~ ..., ~ p_k = \\pi_k\\) where \\(p_i\\) is the observed proportion for category \\(i\\), \\(\\pi_i\\) is expected proportion for category \\(i\\), and \\(k\\) is the number of categories \\(H_A:\\) at least one level of \\(p_i\\) does not match \\(\\pi_i\\) Second, tests of independence are used when comparing two types of observed data to see if there is a relationship. For example, this could be used to determine if the proportion of respondents who voted for each political party in the Presidential election matches the proportion of respondents who voted for each political party in a local election. In this case, we can set up the hypothesis test as: \\(H_0:\\) The two variables/factors are independent \\(H_A:\\) The two variables/factors are not independent Third, tests of homogeneity are used to compare two distributions to see if they match. For example, this could be used to determine if the highest education achieved is the same for both men and women. In this case, we can set up the hypothesis test as: \\(H_0: p_{1a} = p_{1b}, ~ p_{2a} = p_{2b}, ~ ..., ~ p_{ka} = p_{kb}\\) where \\(p_{ia}\\) is the observed proportion of category \\(i\\) for subgroup \\(a\\), \\(p_{ib}\\) is the observed proportion of category \\(i\\) for subgroup \\(a\\), and \\(k\\) is the number of categories \\(H_A:\\) at least one category of \\(p_{ia}\\) does not match \\(p_{ib}\\) The difference between using \\(\\chi^2\\) tests with non-survey data and with survey data is based on the underlying variance estimation difference. The functions in the {survey} package will account for these nuances provided the design object is correctly defined. For basic variance estimation formulas for different survey design types, refer to Chapter 5. 7.3.1 Syntax As with t-tests, when we do not have survey data, we may be able to use the chisq.test() function. However, this function does not allow for weights or the variance structure to be accounted for with survey data. Therefore, when using survey data, we need to use one of two functions: svygofchisq(): For goodness of fit tests svychisq(): For tests of independence and homogeneity The non-survey data function of chisq.test() requires either a single set of counts and given proportions (for goodness of fit tests), or two sets of counts for tests of independence and homogeneity. The functions that we use with survey data require respondent level data and formulas instead of counts. This ensures that the variances are correctly calculated. First, the function for the goodness of fit tests is svygofchisq(): svygofchisq(formula, p, design, na.rm=TRUE, ...) In this function, you’ll notice that the first argument is the formula, the second argument is p which are the expected proportions, and the third argument is the design. Therefore, we again must use the dot (.) notation if we pipe in the survey design object (as described at the beginning of this chapter). For the goodness of fit tests, the formula will be a single variable formula=~VARIABLE as we are comparing the observed data from this variable to expected data. The expected probabilities are then entered in the p argument, and needs to be a vector of the same length as the number of categories in the variable. For example, if we want to know if the proportion of males and females match a distribution of 30/70, then the sex variable (with 2 categories) would be used in the formula formula=~SEX and the proportions would be included as p=c(.3,.7). It is important to note that the variable entered into the formula should be formatted as either a factor or a character. The examples below provide more detail and tips on how to make sure the levels are matching up correctly. The function for tests of independence and homogeneity (svychisq()) is similar to the goodness of fit function in that the formula argument is first. However, instead of an argument for the expected proportions, the svychisq() function has an argument to select the statistic used for the test: svychisq(formula, design, statistic = c(&quot;F&quot;, &quot;Chisq&quot;, &quot;Wald&quot;, &quot;adjWald&quot;, &quot;lincom&quot;, &quot;saddlepoint&quot;), na.rm=TRUE, ...) There are 6 statistics that are accepted in this formula. For tests of homogeneity (when comparing cross tabulations) the F or Chisq statistics should be used.12 The F statistic is the default and uses the Rao-Scott second-order correction. This correction is designed to assist with complicated sampling design (i.e., those other than a simple random sample) (CITE)13. The Chisq statistic is an adjusted version of the Pearson \\(\\chi^2\\) statistic. The version of this statistic in the svychisq() function compares the design effect estimate from the provided survey data to what the \\(\\chi^2\\) distribution would have been if the data came from a simple random sampling.For tests of independence, the Wald and adjWald are recommended as they provide a better adjustment for variable comparisons. If the data has a small number of primary sampling units (PSUs) in comparison to the degrees of freedom, then the adjWald statistic should be used to account for this. The lincom and saddlepoint statistics are available for more complicated data structures. The formula argument will always be one sided unlike the svyttest() function. The two variables of interest should be included with a plus sign: formula=~VAR1+VAR2. As with the svygofchisq() function, the variables entered into the formula should be formatted as either a factor or a character. Additionally, as with the t-test function, both svygofchisq() and svychisq() have the na.rm argument. This argument defaults to FALSE, however, unlike the t-test function if any data is missing the \\(\\chi^2\\) tests will assume that NA is a category and will include it in the calculation. Throughout this chapter we will always set na.rm=TRUE, but before analyzing the survey data, make sure to review the notes provided in Chapter ?? to better understand how to handle missing data. 7.3.2 Examples Let’s walk through a few examples using the ANES data. See Section 7.1 above to set up the design object. Example 1: Goodness of Fit Test ANES asked respondents their highest education level. Based on the data from the 2020 American Community Survey (ACS) 5-year estimates14, the education distribution of those 18+ in the U.S. is as follows: - 11% had less than High School degree - 27% had a High School degree - 29% had some college or associate’s degree - 33% had a bachelor’s degree or higher If we want to see if the weighted distribution from the ANES 2020 data matches this distribution, we could set up the hypothesis as follows: \\(H_0: p_1 = 0.11, ~ p_2 = 0.27, ~ p_3 = 0.29, ~ p_4 = 0.33\\) \\(H_A:\\) at least one of the education levels does not match between the ANES and the ACS To conduct this in R, let’s first take a look at the education variable (Education) we have on the ANES data. Using the survey_mean() function discussed in Chapter 6, we can see the different levels of education we have and estimated proportion. anes_des %&gt;% group_by(Education) %&gt;% filter(!is.na(Education)) %&gt;% summarise(p=survey_mean()) ## # A tibble: 5 × 3 ## Education p p_se ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Less than HS 0.0805 0.00568 ## 2 High school 0.277 0.0102 ## 3 Post HS 0.290 0.00713 ## 4 Bachelor&#39;s 0.226 0.00633 ## 5 Graduate 0.126 0.00499 Based on this output, we can see that we have different levels than the ACS data provides. Specifically, the education data from ANES has two levels for Bachelor’s Degree or Higher (Bachelor’s and Graduate), so these two categories need to be collapsed into a single category to match the ACS data. We case use the {forcats} package and the fct_collapse() function to create a new variable to use. Then we will use the svygofchisq() function to compare the ANES data to the ACS data: anes_des_educ&lt;-anes_des %&gt;% mutate(Education2= fct_collapse(Education, &quot;Bachelor or Higher&quot;=c(&quot;Bachelor&#39;s&quot;, &quot;Graduate&quot;))) chi_ex1&lt;-anes_des_educ %&gt;% svygofchisq(formula=~Education2, p=c(0.11,0.27,0.29,0.33), design=., na.rm=TRUE) chi_ex1 ## ## Design-based chi-squared test for given probabilities ## ## data: ~Education2 ## X-squared = 2177472, scale = 1.1e+05, df = 2.3e+00, p-value = ## 9e-05 The output from the svygofchisq() indicates that at least one proportion from ANES does not match the ACS data ( \\(\\chi^2=\\) 2.1775^{6}; \\(p-value=\\) 8.74^{-5} ). To get a better idea of the differences, we can use the expected output along with survey_mean() to create a comparison table: ex1_expected&lt;-tibble(ExpectedCount=chi_ex1$expected) %&gt;% mutate(Education=names(chi_ex1$expected), Education=str_sub(Education,11,nchar(Education)), ExpectedProb=ExpectedCount/sum(ExpectedCount)) %&gt;% select(Education,Expected=ExpectedProb) ex1_observed&lt;-anes_des_educ %&gt;% filter(!is.na(Education2)) %&gt;% group_by(Education2) %&gt;% summarize(Observed=survey_mean(vartype = &quot;ci&quot;)) %&gt;% rename(Education=Education2) ex1_table&lt;-ex1_expected %&gt;% left_join(ex1_observed,by=&quot;Education&quot;) %&gt;% mutate(Education=factor(Education, levels=c(&quot;Less than HS&quot;,&quot;High school&quot;, &quot;Post HS&quot;,&quot;Bachelor or Higher&quot;))) ex1_table ## # A tibble: 4 × 5 ## Education Expected Observed Observed_low Observed_upp ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Less than HS 0.11 0.0805 0.0691 0.0919 ## 2 High school 0.27 0.277 0.257 0.298 ## 3 Post HS 0.29 0.290 0.276 0.305 ## 4 Bachelor or Higher 0.33 0.352 0.337 0.367 This output includes our expected proportions from the ACS that we provided the svygofchisq() function along with output of the observed proportions and their confidence intervals. From this table we can see that the “High school” and “Post HS” categories have proportions that are nearly identical, but that the other two categories are slightly different. Looking at the confidence intervals we can see that the ANES data skews to include fewer people in the “Less than HS” category and more people in the “Bachelor or Higher” category. This may be easier to see in graphical form: ex1_table %&gt;% pivot_longer(cols=c(&quot;Expected&quot;,&quot;Observed&quot;), names_to=&quot;Names&quot;, values_to=&quot;Proportion&quot;) %&gt;% mutate(Observed_low=case_when(Names==&quot;Observed&quot;~Observed_low), Observed_upp=case_when(Names==&quot;Observed&quot;~Observed_upp)) %&gt;% ggplot(aes(x=Education,y=Proportion,color=Names)) + geom_point(alpha=0.5) + geom_errorbar(aes(ymin=Observed_low,ymax=Observed_upp)) + theme_bw() Example 2: Test of Independence ANES asked respondents two questions about trust: - How often can you trust the federal government to do what is right? - How often can you trust other people? If we want to see if the distributions of these two questions are similar or not we can conduct a test of independence. Here is how the hypothesis could be set up: \\(H_0:\\) People’s trust in the federal government and their trust in other people are independent (i.e, not related) \\(H_A:\\) People’s trust in the federal government and their trust in other people are not independent (i.e, they are related) To conduct this in R, we will use the svychisq() function to compare the two variables: chi_ex2&lt;-anes_des %&gt;% svychisq(formula=~TrustGovernment+TrustPeople, design=., statistic=&quot;Wald&quot;, na.rm=TRUE) chi_ex2 ## ## Design-based Wald test of association ## ## data: NextMethod() ## F = 21, ndf = 16, ddf = 51, p-value &lt;2e-16 The output from svychisq() indicates that at the distribution of people’s trust in the federal government and their trust in other people are not independent, meaning that they are related. Let’s out put the distributions in a table to see the relationship. The observed output from the test provides a cross tabulation of the counts for each category: chi_ex2$observed ## TrustPeople ## TrustGovernment Always Most of the time About half the time ## Always 16.470 25.009 31.848 ## Most of the time 11.020 539.377 196.258 ## About half the time 11.772 934.858 861.971 ## Some of the time 17.007 1353.779 839.863 ## Never 3.174 236.785 174.272 ## TrustPeople ## TrustGovernment Some of the time Never ## Always 36.854 5.523 ## Most of the time 206.556 27.184 ## About half the time 428.871 65.024 ## Some of the time 932.628 89.596 ## Never 217.994 189.307 However, as researchers, we often want to know about the proportions and not just the respondent counts from the survey. There are a couple of different ways that you can do this. The first is using the counts from chi_ex2$observed and calculating the proportion from that. We can then pivot the table to create a cross tabulation similar to the counts table above. Adding in group_by() to the code, means that we are obtaining the proportions within each level of that variable. In this case, we are looking at the distribution of TrustGovernment for each level of TrustPeople. chi_ex2$observed %&gt;% as_tibble() %&gt;% group_by(TrustPeople) %&gt;% mutate(prop=round(n/sum(n),3)) %&gt;% select(-n) %&gt;% pivot_wider(names_from=TrustPeople,values_from=prop) %&gt;% gt(rowname_col = &quot;TrustGovernment&quot;) %&gt;% tab_stubhead(label = &quot;Trust in Government&quot;) %&gt;% tab_spanner( label = &quot;Trust in People&quot;, columns = everything() ) #edxahdlkim table { font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji'; -webkit-font-smoothing: antialiased; -moz-osx-font-smoothing: grayscale; } #edxahdlkim thead, #edxahdlkim tbody, #edxahdlkim tfoot, #edxahdlkim tr, #edxahdlkim td, #edxahdlkim th { border-style: none; } #edxahdlkim p { margin: 0; padding: 0; } #edxahdlkim .gt_table { display: table; border-collapse: collapse; line-height: normal; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #edxahdlkim .gt_caption { padding-top: 4px; padding-bottom: 4px; } #edxahdlkim .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #edxahdlkim .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 3px; padding-bottom: 5px; padding-left: 5px; padding-right: 5px; border-top-color: #FFFFFF; border-top-width: 0; } #edxahdlkim .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #edxahdlkim .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #edxahdlkim .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #edxahdlkim .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #edxahdlkim .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #edxahdlkim .gt_column_spanner_outer:first-child { padding-left: 0; } #edxahdlkim .gt_column_spanner_outer:last-child { padding-right: 0; } #edxahdlkim .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #edxahdlkim .gt_spanner_row { border-bottom-style: hidden; } #edxahdlkim .gt_group_heading { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; text-align: left; } #edxahdlkim .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #edxahdlkim .gt_from_md > :first-child { margin-top: 0; } #edxahdlkim .gt_from_md > :last-child { margin-bottom: 0; } #edxahdlkim .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #edxahdlkim .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; } #edxahdlkim .gt_stub_row_group { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; vertical-align: top; } #edxahdlkim .gt_row_group_first td { border-top-width: 2px; } #edxahdlkim .gt_row_group_first th { border-top-width: 2px; } #edxahdlkim .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #edxahdlkim .gt_first_summary_row { border-top-style: solid; border-top-color: #D3D3D3; } #edxahdlkim .gt_first_summary_row.thick { border-top-width: 2px; } #edxahdlkim .gt_last_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #edxahdlkim .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #edxahdlkim .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #edxahdlkim .gt_last_grand_summary_row_top { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: double; border-bottom-width: 6px; border-bottom-color: #D3D3D3; } #edxahdlkim .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #edxahdlkim .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #edxahdlkim .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #edxahdlkim .gt_footnote { margin: 0px; font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #edxahdlkim .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #edxahdlkim .gt_sourcenote { font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #edxahdlkim .gt_left { text-align: left; } #edxahdlkim .gt_center { text-align: center; } #edxahdlkim .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #edxahdlkim .gt_font_normal { font-weight: normal; } #edxahdlkim .gt_font_bold { font-weight: bold; } #edxahdlkim .gt_font_italic { font-style: italic; } #edxahdlkim .gt_super { font-size: 65%; } #edxahdlkim .gt_footnote_marks { font-size: 75%; vertical-align: 0.4em; position: initial; } #edxahdlkim .gt_asterisk { font-size: 100%; vertical-align: 0; } #edxahdlkim .gt_indent_1 { text-indent: 5px; } #edxahdlkim .gt_indent_2 { text-indent: 10px; } #edxahdlkim .gt_indent_3 { text-indent: 15px; } #edxahdlkim .gt_indent_4 { text-indent: 20px; } #edxahdlkim .gt_indent_5 { text-indent: 25px; } Trust in Government Trust in People Always Most of the time About half the time Some of the time Never Always 0.277 0.008 0.015 0.020 0.015 Most of the time 0.185 0.175 0.093 0.113 0.072 About half the time 0.198 0.303 0.410 0.235 0.173 Some of the time 0.286 0.438 0.399 0.512 0.238 Never 0.053 0.077 0.083 0.120 0.503 The second option is to use group_by() and survey_mean() functions to calculate the proportions from the ANES design object. A reminder, that with more than one variable listed in the group_by() statement, the proportions are within the first variable listed. As above, we are looking at the distribution of TrustGovernment for each level of TrustPeople. chi_ex2_obs&lt;-anes_des %&gt;% filter(!is.na(TrustPeople),!is.na(TrustGovernment)) %&gt;% group_by(TrustPeople,TrustGovernment) %&gt;% summarize(Observed=round(survey_mean(vartype = &quot;ci&quot;),3)) chi_ex2_obs %&gt;% mutate(prop=paste0(Observed,&quot; (&quot;,Observed_low,&quot;, &quot;, Observed_upp,&quot;)&quot;)) %&gt;% select(TrustGovernment,TrustPeople,prop) %&gt;% pivot_wider(names_from=TrustPeople,values_from=prop) %&gt;% gt(rowname_col = &quot;TrustGovernment&quot;) %&gt;% tab_stubhead(label = &quot;Trust in Government&quot;) %&gt;% tab_spanner( label = &quot;Trust in People&quot;, columns = everything() ) #jslvphoojc table { font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji'; -webkit-font-smoothing: antialiased; -moz-osx-font-smoothing: grayscale; } #jslvphoojc thead, #jslvphoojc tbody, #jslvphoojc tfoot, #jslvphoojc tr, #jslvphoojc td, #jslvphoojc th { border-style: none; } #jslvphoojc p { margin: 0; padding: 0; } #jslvphoojc .gt_table { display: table; border-collapse: collapse; line-height: normal; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #jslvphoojc .gt_caption { padding-top: 4px; padding-bottom: 4px; } #jslvphoojc .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #jslvphoojc .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 3px; padding-bottom: 5px; padding-left: 5px; padding-right: 5px; border-top-color: #FFFFFF; border-top-width: 0; } #jslvphoojc .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #jslvphoojc .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #jslvphoojc .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #jslvphoojc .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #jslvphoojc .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #jslvphoojc .gt_column_spanner_outer:first-child { padding-left: 0; } #jslvphoojc .gt_column_spanner_outer:last-child { padding-right: 0; } #jslvphoojc .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #jslvphoojc .gt_spanner_row { border-bottom-style: hidden; } #jslvphoojc .gt_group_heading { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; text-align: left; } #jslvphoojc .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #jslvphoojc .gt_from_md > :first-child { margin-top: 0; } #jslvphoojc .gt_from_md > :last-child { margin-bottom: 0; } #jslvphoojc .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #jslvphoojc .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; } #jslvphoojc .gt_stub_row_group { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; vertical-align: top; } #jslvphoojc .gt_row_group_first td { border-top-width: 2px; } #jslvphoojc .gt_row_group_first th { border-top-width: 2px; } #jslvphoojc .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #jslvphoojc .gt_first_summary_row { border-top-style: solid; border-top-color: #D3D3D3; } #jslvphoojc .gt_first_summary_row.thick { border-top-width: 2px; } #jslvphoojc .gt_last_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #jslvphoojc .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #jslvphoojc .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #jslvphoojc .gt_last_grand_summary_row_top { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: double; border-bottom-width: 6px; border-bottom-color: #D3D3D3; } #jslvphoojc .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #jslvphoojc .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #jslvphoojc .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #jslvphoojc .gt_footnote { margin: 0px; font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #jslvphoojc .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #jslvphoojc .gt_sourcenote { font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #jslvphoojc .gt_left { text-align: left; } #jslvphoojc .gt_center { text-align: center; } #jslvphoojc .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #jslvphoojc .gt_font_normal { font-weight: normal; } #jslvphoojc .gt_font_bold { font-weight: bold; } #jslvphoojc .gt_font_italic { font-style: italic; } #jslvphoojc .gt_super { font-size: 65%; } #jslvphoojc .gt_footnote_marks { font-size: 75%; vertical-align: 0.4em; position: initial; } #jslvphoojc .gt_asterisk { font-size: 100%; vertical-align: 0; } #jslvphoojc .gt_indent_1 { text-indent: 5px; } #jslvphoojc .gt_indent_2 { text-indent: 10px; } #jslvphoojc .gt_indent_3 { text-indent: 15px; } #jslvphoojc .gt_indent_4 { text-indent: 20px; } #jslvphoojc .gt_indent_5 { text-indent: 25px; } Trust in Government Trust in People Always Most of the time About half the time Some of the time Never Always 0.277 (0.11, 0.444) 0.008 (0.004, 0.012) 0.015 (0.006, 0.024) 0.02 (0.008, 0.033) 0.015 (0, 0.029) Most of the time 0.185 (-0.009, 0.38) 0.175 (0.157, 0.192) 0.093 (0.078, 0.109) 0.113 (0.085, 0.141) 0.072 (0.021, 0.123) About half the time 0.198 (0.046, 0.35) 0.303 (0.281, 0.324) 0.41 (0.378, 0.441) 0.235 (0.2, 0.271) 0.173 (0.099, 0.246) Some of the time 0.286 (0.069, 0.503) 0.438 (0.415, 0.462) 0.399 (0.365, 0.433) 0.512 (0.481, 0.543) 0.238 (0.178, 0.298) Never 0.053 (-0.01, 0.117) 0.077 (0.064, 0.089) 0.083 (0.063, 0.103) 0.12 (0.097, 0.142) 0.503 (0.422, 0.583) Both methods produce the same output as the the svychisq() function does account for the survey design. However, calculating the proportions directly from the design object means that you can also obtain the variance information. In this case, the table output displays the survey estimate followed by the confidence intervals. Based on the output, we can see that of those that never trust people 50.3% also never trust the government, while the proportions of never trusting the government are much lower for each of the other levels of trusting people. We may find it easier to look at these proportions graphically. We can use gglot() and facets to provide an overview: chi_ex2_obs %&gt;% ggplot(aes(x=TrustGovernment,y=Observed,color=TrustGovernment)) + facet_wrap(~TrustPeople,ncol=5) + geom_point() + geom_errorbar(aes(ymin=Observed_low,ymax=Observed_upp)) + ylab(&quot;Proportion&quot;) + theme_bw() Example 3: Test of Homogeneity Each election cycle, researchers and politicians often look at specific demographics to understand how each group is leaning or voting towards candidates. The ANES data is post-election, but we can still look to see if there are differences in how specific demographic groups voted. If we want to see if there is a difference in how each age group voted for the 2020 candidates, this would be a test of homogeneity and the hypothesis could be set up as: \\(H_0: p_{1_{Biden}} = p_{1_{Trump}} = p_{1_{Other}},\\\\ p_{2_{Biden}} = p_{2_{Trump}} = p_{2_{Other}},\\\\ p_{3_{Biden}} = p_{3_{Trump}} = p_{3_{Other}},\\\\ p_{4_{Biden}} = p_{4_{Trump}} = p_{4_{Other}},\\\\ p_{5_{Biden}} = p_{5_{Trump}} = p_{5_{Other}},\\\\ p_{6_{Biden}} = p_{6_{Trump}} = p_{6_{Other}}\\) where \\(p_{i_{Biden}}\\) is the observed proportion of each age group (\\(i\\)) that voted for Biden, \\(p_{i_{Trump}}\\) is the observed proportion of each age group (\\(i\\)) that voted for Trump, and \\(p_{i_{Other}}\\) is the observed proportion of each age group (\\(i\\)) that voted for another candidate \\(H_A:\\) at least one category of \\(p_{i_{Biden}}\\) does not match \\(p_{i_{Trump}}\\) or \\(p_{i_{Other}}\\) To conduct this in R, we will use the svychisq() function to compare the two variables: chi_ex3&lt;-anes_des %&gt;% filter(VotedPres2020==&quot;Yes&quot; &amp; !is.na(VotedPres2020_selection) &amp; !is.na(AgeGroup)) %&gt;% svychisq(formula=~AgeGroup+VotedPres2020_selection, design=., statistic=&quot;Chisq&quot;, na.rm=TRUE) chi_ex3 ## ## Pearson&#39;s X^2: Rao &amp; Scott adjustment ## ## data: NextMethod() ## X-squared = 169, df = 10, p-value &lt;2e-16 The output from svychisq() indicates that there is a difference in how each age group voted in the 2020 election. To get a better idea of the different distributions, let’s out put proportions to see the relationship. As we learned in Example 2 above, we can use chi_ex3$observed or if we want to get the variance information (which is crucial with survey data), we can use survey_mean(). Remember, when we have two variables in group_by(), we are obtaining the proportions within each level of the variable listed. In this case, we are looking at the distribution of AgeGroup for each level of VotedPres2020_selection. chi_ex3_obs&lt;-anes_des %&gt;% filter(VotedPres2020==&quot;Yes&quot; &amp; !is.na(VotedPres2020_selection) &amp; !is.na(AgeGroup)) %&gt;% group_by(VotedPres2020_selection,AgeGroup) %&gt;% summarize(Observed=round(survey_mean(vartype = &quot;ci&quot;),3)) chi_ex3_obs %&gt;% mutate(prop=paste0(Observed,&quot; (&quot;,Observed_low,&quot;, &quot;, Observed_upp,&quot;)&quot;)) %&gt;% select(AgeGroup,VotedPres2020_selection,prop) %&gt;% pivot_wider(names_from=VotedPres2020_selection,values_from=prop) %&gt;% gt(rowname_col = &quot;AgeGroup&quot;) %&gt;% tab_stubhead(label = &quot;Age Group&quot;) #uphlolqabb table { font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji'; -webkit-font-smoothing: antialiased; -moz-osx-font-smoothing: grayscale; } #uphlolqabb thead, #uphlolqabb tbody, #uphlolqabb tfoot, #uphlolqabb tr, #uphlolqabb td, #uphlolqabb th { border-style: none; } #uphlolqabb p { margin: 0; padding: 0; } #uphlolqabb .gt_table { display: table; border-collapse: collapse; line-height: normal; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #uphlolqabb .gt_caption { padding-top: 4px; padding-bottom: 4px; } #uphlolqabb .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #uphlolqabb .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 3px; padding-bottom: 5px; padding-left: 5px; padding-right: 5px; border-top-color: #FFFFFF; border-top-width: 0; } #uphlolqabb .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #uphlolqabb .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #uphlolqabb .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #uphlolqabb .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #uphlolqabb .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #uphlolqabb .gt_column_spanner_outer:first-child { padding-left: 0; } #uphlolqabb .gt_column_spanner_outer:last-child { padding-right: 0; } #uphlolqabb .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #uphlolqabb .gt_spanner_row { border-bottom-style: hidden; } #uphlolqabb .gt_group_heading { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; text-align: left; } #uphlolqabb .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #uphlolqabb .gt_from_md > :first-child { margin-top: 0; } #uphlolqabb .gt_from_md > :last-child { margin-bottom: 0; } #uphlolqabb .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #uphlolqabb .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; } #uphlolqabb .gt_stub_row_group { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; vertical-align: top; } #uphlolqabb .gt_row_group_first td { border-top-width: 2px; } #uphlolqabb .gt_row_group_first th { border-top-width: 2px; } #uphlolqabb .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #uphlolqabb .gt_first_summary_row { border-top-style: solid; border-top-color: #D3D3D3; } #uphlolqabb .gt_first_summary_row.thick { border-top-width: 2px; } #uphlolqabb .gt_last_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #uphlolqabb .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #uphlolqabb .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #uphlolqabb .gt_last_grand_summary_row_top { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: double; border-bottom-width: 6px; border-bottom-color: #D3D3D3; } #uphlolqabb .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #uphlolqabb .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #uphlolqabb .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #uphlolqabb .gt_footnote { margin: 0px; font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #uphlolqabb .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #uphlolqabb .gt_sourcenote { font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #uphlolqabb .gt_left { text-align: left; } #uphlolqabb .gt_center { text-align: center; } #uphlolqabb .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #uphlolqabb .gt_font_normal { font-weight: normal; } #uphlolqabb .gt_font_bold { font-weight: bold; } #uphlolqabb .gt_font_italic { font-style: italic; } #uphlolqabb .gt_super { font-size: 65%; } #uphlolqabb .gt_footnote_marks { font-size: 75%; vertical-align: 0.4em; position: initial; } #uphlolqabb .gt_asterisk { font-size: 100%; vertical-align: 0; } #uphlolqabb .gt_indent_1 { text-indent: 5px; } #uphlolqabb .gt_indent_2 { text-indent: 10px; } #uphlolqabb .gt_indent_3 { text-indent: 15px; } #uphlolqabb .gt_indent_4 { text-indent: 20px; } #uphlolqabb .gt_indent_5 { text-indent: 25px; } Age Group Biden Trump Other 18-29 0.204 (0.177, 0.231) 0.114 (0.095, 0.133) 0.227 (0.15, 0.304) 30-39 0.169 (0.153, 0.185) 0.147 (0.123, 0.17) 0.306 (0.214, 0.398) 40-49 0.163 (0.146, 0.18) 0.157 (0.136, 0.178) 0.209 (0.128, 0.29) 50-59 0.154 (0.136, 0.173) 0.234 (0.207, 0.261) 0.107 (0.041, 0.172) 60-69 0.179 (0.16, 0.199) 0.192 (0.172, 0.213) 0.102 (0.025, 0.178) 70 or older 0.13 (0.118, 0.143) 0.156 (0.139, 0.174) 0.049 (0, 0.098) We can see that the age group distribution was younger for Biden and other candidates, and older for Trump. For example, of those that voted for Biden, 20.4% were in the 18-29 age group compared to only 11.4% of those that voted for Trump where in that age group. On the other side, 23.4% of those that voted for Trump were in the 50-59 age group compared to only 15.4% of those that voted for Biden. 7.3.3 Exercises Here are some exercises for practicing conducting chi-squared tests using svygofchisq() and svychisq(): If you wanted to determine if the political party affiliation differed for males and females, what test would you use? Goodness of fit test (svygofchisq()) Test of independence (svychisq()) Test of homogeneity (svychisq()) chisq_solution1&lt;-&quot;c. Test of homogeneity (`svychisq()`)&quot; chisq_solution1 ## [1] &quot;c. Test of homogeneity (`svychisq()`)&quot; In the RECS data, is there a relationship between the type of housing unit (HousingUnitType) and the year the house was built (YearMade)? chisq_solution2&lt;-recs_des %&gt;% svychisq(formula=~HousingUnitType+YearMade, design=., statistic=&quot;Wald&quot;, na.rm=TRUE) chisq_solution2 ## ## Design-based Wald test of association ## ## data: NextMethod() ## F = 32, ndf = 28, ddf = 95, p-value &lt;2e-16 In the ANES data, is there a difference in the distribution of gender (Gender) across early voting status in 2020 (EarlyVote2020)? chisq_solution3&lt;-anes_des %&gt;% svychisq(formula=~Gender+EarlyVote2020, design=., statistic=&quot;F&quot;, na.rm=TRUE) chisq_solution3 ## ## Pearson&#39;s X^2: Rao &amp; Scott adjustment ## ## data: NextMethod() ## F = 0.27, ndf = 1, ddf = 51, p-value = 0.6 These two statistics can also be used for goodness of fit tests, if the svygofchisq() function is not used.↩︎ http://www.asasrms.org/Proceedings/y2007/Files/JSM2007-000874.pdf↩︎ Data was pulled from data.census.gov using the S1501 Education Attainment 2020: ACS 5-Year Estimates Subject Tables↩︎ "],["c08.html", "Chapter 8 Modeling", " Chapter 8 Modeling "],["c09.html", "Chapter 9 Presenting results", " Chapter 9 Presenting results "],["more-to-say.html", "A More to Say", " A More to Say Yeah! I have finished my book, but I have more to say about some topics. Let me explain them in this appendix. To know more about bookdown, see https://bookdown.org. This is for testing GH Actions. "],["references.html", "References", " References "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
