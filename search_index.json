[["index.html", "Tidy Survey Book Preface Why read this book Structure of the book Software information and conventions Acknowledgments", " Tidy Survey Book Stephanie Zimmer, Rebecca J. Powell, and Isabella Velásquez 2023-03-19 Preface Hi there, this is my great book. Why read this book It is very important… Structure of the book Chapters 1 introduces a new topic, and … Software information and conventions I used the knitr package (Xie 2015) and the bookdown package (Xie 2022) to compile my book. My R session information is shown below: xfun::session_info() ## R version 4.2.3 (2023-03-15) ## Platform: x86_64-apple-darwin17.0 (64-bit) ## Running under: macOS Big Sur ... 10.16 ## ## Locale: en_US.UTF-8 / en_US.UTF-8 / en_US.UTF-8 / C / en_US.UTF-8 / en_US.UTF-8 ## ## Package version: ## askpass_1.1 assertthat_0.2.1 ## backports_1.4.1 base64enc_0.1.3 ## bit_4.0.5 bit64_4.0.5 ## blob_1.2.3 bookdown_0.30 ## broom_1.0.1 bslib_0.4.1 ## cachem_1.0.6 callr_3.7.3 ## cellranger_1.1.0 class_7.3-20 ## classInt_0.4-8 cli_3.4.1 ## clipr_0.8.0 colorspace_2.0-3 ## commonmark_1.8.1 compiler_4.2.3 ## cpp11_0.4.3 crayon_1.5.2 ## curl_4.3.3 data.table_1.14.6 ## DBI_1.1.3 dbplyr_2.2.1 ## DiagrammeR_1.0.9 digest_0.6.30 ## downloader_0.4 dplyr_1.1.0 ## dtplyr_1.2.2 e1071_1.7-12 ## ellipsis_0.3.2 evaluate_0.18 ## fansi_1.0.3 farver_2.1.1 ## fastmap_1.1.0 forcats_0.5.2 ## foreign_0.8-83 fs_1.5.2 ## gargle_1.2.1 generics_0.1.3 ## ggplot2_3.4.0 glue_1.6.2 ## googledrive_2.0.0 googlesheets4_1.0.1 ## graphics_4.2.3 grDevices_4.2.3 ## grid_4.2.3 gridExtra_2.3 ## gtable_0.3.1 haven_2.5.1 ## here_1.0.1 highr_0.9 ## hms_1.1.2 htmltools_0.5.3 ## htmlwidgets_1.5.4 httr_1.4.4 ## ids_1.0.1 igraph_1.3.5 ## influenceR_0.1.0.1 isoband_0.2.6 ## jquerylib_0.1.4 jsonlite_1.8.3 ## KernSmooth_2.23-20 knitr_1.41 ## labeling_0.4.2 lattice_0.20-45 ## lifecycle_1.0.3 lubridate_1.9.0 ## magrittr_2.0.3 maptools_1.1-5 ## markdown_1.4 MASS_7.3.58.1 ## Matrix_1.5-3 memoise_2.0.1 ## methods_4.2.3 mgcv_1.8.41 ## mime_0.12 minqa_1.2.5 ## mitools_2.4 modelr_0.1.10 ## munsell_0.5.0 nlme_3.1.160 ## numDeriv_2016.8.1.1 openssl_2.0.4 ## pillar_1.8.1 pkgconfig_2.0.3 ## prettyunits_1.1.1 processx_3.8.0 ## progress_1.2.2 proxy_0.4-27 ## ps_1.7.2 purrr_0.3.5 ## R6_2.5.1 rappdirs_0.3.3 ## RColorBrewer_1.1-3 Rcpp_1.0.9 ## readr_2.1.3 readxl_1.4.1 ## rematch_1.0.1 rematch2_2.1.2 ## renv_0.16.0 reprex_2.0.2 ## rgdal_1.6-2 rlang_1.0.6 ## rmarkdown_2.18 rprojroot_2.0.3 ## rstudioapi_0.14 rvest_1.0.3 ## s2_1.1.1 sass_0.4.4 ## scales_1.2.1 selectr_0.4.2 ## sf_1.0-9 sp_1.5-1 ## splines_4.2.3 srvyr_1.2.0 ## stats_4.2.3 stringi_1.7.8 ## stringr_1.5.0 survey_4.1-1 ## survival_3.4-0 sys_3.4.1 ## tibble_3.1.8 tidycensus_1.3 ## tidyr_1.2.1 tidyselect_1.2.0 ## tidyverse_1.3.2 tigris_1.6.1 ## timechange_0.1.1 tinytex_0.42 ## tools_4.2.3 tzdb_0.3.0 ## units_0.8-0 utf8_1.2.2 ## utils_4.2.3 uuid_1.1-0 ## vctrs_0.5.2 viridis_0.6.2 ## viridisLite_0.4.1 visNetwork_2.1.2 ## vroom_1.6.0 webshot_0.5.4 ## withr_2.5.0 wk_0.7.0 ## xfun_0.35 xml2_1.3.3 ## yaml_2.3.6 Package names are in bold text (e.g., rmarkdown), and inline code and filenames are formatted in a typewriter font (e.g., knitr::knit('foo.Rmd')). Function names are followed by parentheses (e.g., bookdown::render_book()). Acknowledgments A lot of people helped me when I was writing the book. Frida Gomam on the Mars References "],["c01.html", "Chapter 1 Introduction", " Chapter 1 Introduction "],["c02.html", "Chapter 2 Overview of Surveys 2.1 Study Design 2.2 Data Collection 2.3 Post Survey Processing 2.4 This book", " Chapter 2 Overview of Surveys Creating and fielding surveys to provide estimates of a population are much more complex than simply adding a few questions to an online platform. Survey researchers can spend months, or even years, developing the study design, questions, and other methods for a single survey to ensure high quality data is collected. While this book focuses on the analysis methods of surveys, understanding the entire survey process can provide a better insight into what types of analyses should be conducted on the data. To gain a deeper understanding of survey design and implementation, there are many pieces of existing literature that we recommend reviewing in detail (e.g., {cite: Dillman book, Groves book, education book?, Tourangeau book, Asking Questions book?, Valliant, Dever, and Krauter book (for design) Biemer and Lyberg: Introduction to Survey Quality}). The survey life cycle starts with a research topic or question of interest (e.g., what impact does childhood trauma have on health outcomes later in life). Researchers typically review existing data sources to determine if data are already available that can answer this question, as this can result in reduced burden on respondents, cheaper research costs, and faster research outcomes. However, if existing data cannot answer the nuances of the research question, a survey can be used to capture the exact data that the researcher needs. When starting a survey, there are multiple things to consider including the study population, how the sample is selected, and the way the question is worded. However, each step and decision can impact how the results can be interpreted, specifically related to the types of error that can be introduced into the data. Generally, survey researchers consider there to be 7 main sources of error ({Cite Groves book}): Representation Coverage Error: A mismatch between the target population (also known as the population of interest) and the sample frame available Sampling Error: Error produced when selecting a sample from the sample frame (none if conducting a census) Nonresponse Error: Differences between those who responded and did not respond to the survey (unit nonresponse) or to a given question (item nonresponse) Adjustment Error: Error introduced during post-survey statistical adjustments Measurement Validity: A mismatch between the topic of interest and the question used to collect that information Measurement Error: A mismatch between what the researcher asked and how the respondent answered Processing Error: Edits by the researcher to responses provided by the respondent (e.g., adjusts data based on illogical responses) Almost every survey conducted will have some of each of these types of error, and researchers attempt to conduct a survey that reduces this total survey error. One of the most common ways to reduce total survey error is through weighting. However, weighting may result in increased error on its own (adjustment error). Therefore when designing surveys, researchers should carefully think about ways to reduce each of these error sources. Additionally when analyzing survey data, understanding decisions that researchers took to minimize these error sources can impact how results are interpreted. The remainder of this chapter dives into considerations for survey development, places where each of these sources of error can be considered, and how these error sources can inform the interpretations of the data. 2.1 Study Design Study design is often used to encompass multiple parts of the survey planning process including decisions on target population, survey mode, and timeline. Multiple decisions made prior to the launch of the survey can assist researchers in reducing different error sources, and are fundamental in understanding how to interpret the results of the data. Knowing who and how to survey individuals depends on both the goals of the study and the feasibility of implementation. 2.1.1 Sampling Design Who we want to survey is known as the target population in the study. This could be broad, such as, “all adults age 18+ living in the U.S.”, or it could be a very specific target population based on a specific characteristic or location. For example, we may want to know about “adults age 18-24 who live in North Carolina” or “eligible voters living in Illinois”. However, to survey individuals in these target populations, a sampling frame is needed with contact information. If researchers are looking at eligible voters, the sampling frame could be the voting registry for a given state or area. For more broad target populations like all adults living in the U.S., the sampling frame will most likely be imperfect. In these cases, researchers may choose to use a sample frame of mailing addresses and send the survey to households, or they may choose to use random digit dialing (RDD) and call random phone numbers. These imperfect sampling frames can result in coverage error where there is a mismatch between the target population and the list of individuals researchers can select. For example, if a researcher is looking to obtain estimates for “all adults age 18+ living in the U.S.”, using a sample frame from mailing addresses will be missing specific types of individuals such as the homeless or transient populations. Additionally, many households have more than one adult living there, so researchers would need to consider how to get a specific individual to fill out the survey (called within household selection), or adjust the target population to report on “U.S. households” instead of “individuals”. Once the researchers have selected the sample frame, the next step is figuring out how to select individuals for the survey. In rare cases researchers may which to conduct a census and survey everyone on the sampling frame. However, the ability to implement a questionnaire at that scale is something few can do. Instead, researchers choose to sample individuals and use weights to estimate numbers in the target population. There are a variety of different sampling methods that can be used, and more information on these can be found in Chapter 5. This decision of which sampling method to use, impacts sampling error and can be adjusted for in weighting. Example: Number of Pets in a Household Let’s use a simple example where a researcher is interested in knowing the average number of pets in a household. Our researcher will need to consider what the target population is for this study. Specifically, are they interested in all of the U.S., a different country, or a more local area (e.g., city or state). Let’s assume our researcher is interested in the number of pets in a U.S. household where there is at least one adult living (18 years old or older). In this case, using a sampling frame of mailing addresses would provide the least amount of coverage error as the frame would closely match our target population. Specifically, our researcher would most likely want to use the Computerized Delivery Sequence File (CDSF), which is a file of mailing addresses that the United States Postal Service (USPS) creates and covers about 95% of U.S. households ({cite Iannichone}). To sample these households, for simplicity, we will use a stratified simple random sample design, where we stratify by state. Throughout this chapter we will build on this example research question to plan a survey. 2.1.2 Data Collection Planning With the sampling design decided, researchers can then make decisions on how to survey these individuals. Specifically, the modes used for contacting and surveying the sample, how frequently to send reminders and follow-ups, and the overall timeline of the study are four of the major data collection determinations. Traditionally, researchers have considered four main modes1 for conducting surveys: Computer Assisted Personal Interview (CAPI; also known as face-to-face or in-person interviewing) Computer Assisted Telephone Interview (CATI; also known as phone or telephone interviewing) Web (also known as Computer Assisted Web Interview or CAWI) Paper and Pencil (PAPI) Researchers can use a single mode to collect data, or multiple modes (also called mixed modes). Using mixed modes can allow for broader reach and can increase response rates depending on the target population ({CITE DeLeeuw mixed mode article}). For example, researchers could both call households to conduct a CATI survey and send mail with a PAPI survey to the household. Using both of these modes, reseachers could gain participation through the mail from individuals who do not pick up the phone to unknown numbers, or through the phone from individuals who do not open all of their mail. However, mode effects (where responses differ based on the mode of response) can be present in the data and may need to be considered during analysis. When selecting which mode, or modes, to use, understanding the unique aspects of the chosen target population and sampling frame will provide insight into how they can best be reached and engaged. For example, if we plan to survey adults age 18-24 who live in North Carolina, asking them to complete a survey using CATI (i.e., over the phone) would most likely not be as successful as other modes like web as this age group does not talk on the phone as much as other generations, and often do not answer their phones for unknown numbers. Additionally, the mode for contacting respondents relies on what information is available on the sample frame. For example, if our sampling frame includes email address, we could send email to our selected sample members to convince them to complete a survey. Or if the sampling frame is a list of mailing addresses, researchers would have to contact sample members with a letter. It is important to note that there can be a difference between the contact mode and the survey mode. For example, if we have a sample frame with addresses, we can send a letter to our sample members and provide information on how to complete a web survey. Or we could use mixed-mode surveys and send sample members a paper and pencil survey with our letter and also ask them to complete the survey online. Combining different contact modes and different survey modes can be useful in reducing unit nonresponse error, as different sample members may respond better to different contact and survey modes. However, when considering which modes to use, it is important to make access to the survey as easy as possible for sample members to reduce burden and unit nonresponse. Another way to reduce unit nonresponse error is though varying the language of the contact materials ({cite Dillman Book}). People are motivated by different things, so constantly repeating the same messaging may not be helpful. Instead, mixing up the messaging and the type of contact material the sample member receives can increase response rates and reduce unit nonresponse error. For example, instead of only sending standard letters, researchers could consider sending mailings that invoke “urgent” or “important” thoughts by sending priority letters, or using other delivery services like FedEx, UPS, or DHL. Determining the number and types of contacts may also be determined by a study timeline. If the timeline is long, then there is a lot of time for follow-ups and varying the message in contact materials. If the timeline is short, than fewer follow-ups can be implemented. Many studies will start with the tailored design method put forth by {Dillman et al. (2014)} and implement 5 contacts: (1) prenotice letting sample members know the survey is coming, (2) invitation to complete the survey, (3) reminder postcard that also thanks respondents that may have already completed the survey, (4) reminder letter (with a replacement paper survey if needed), and (5) final reminder postcard. This method is easily adaptable based on the study timeline and needs, but provides a good basis for most studies. Example: Number of Pets in a Household Let’s return to our example of a researcher who wants to know the average number of pets in a household. We are using a sample frame of mailing addresses, so we recommend starting our data collection with letters mailed to households, but later in data collection we want to send interviewers to the house to conduct an in-person (or CAPI) interview in an effort to decrease unit nonresponse error. This means we will have two contact modes (paper and in-person). As we mentioned above, the survey mode does not have to be the same as the contact mode, so we recommend a mixed-mode study with both Web and CAPI modes. Let’s assume we have 6 months for data collection, so we may want to recommend the following protocol: Protocol Example for 6-month Web and CAPI Data Collection Week Contact Mode Contact Message Survey Mode Offered 1 Mail: Letter Prenotice — 2 Mail: Letter Invitation Web 3 Mail: Postcard Thank You/Reminder Web 6 Mail: Letter in large envelope Animal Welfare Discussion Web 10 Mail: Postcard Inform Upcoming In-Person Visit Web 14 In-Person Visit — CAPI 16 Mail: Letter Reminder of In-Person Visit Web, but includes number to call to schedule CAPI 20 In-Person Visit — CAPI 25 Mail: Letter in large envelope Survey Closing Notice Web, but includes number to call to schedule CAPI This is just one possible protocol that could be used that starts respondents with web (typically done to reduce costs). However, researchers may want to start in-person data collection earlier during the data collection period, or ask their interviewers to attempt more than 2 visits with a household. 2.1.3 Questionnaire Design When developing the questionnaire, it can be helpful to first outline the topics to be asked and include the “why” each question or topic is important to the research question(s). This can help researchers better tailor the questionnaire and potentially reduce the number of questions (and thus burden on the respondent) if topics are deemed irrelevant to the research question. When making these decisions, researchers should also consider questions needed for weighting purposes. While we would love to have everyone sampled answer our survey, this is rarely the case. Thus, including questions about demographics in the survey can assist with weighting for nonresponse error (both unit and item nonresponse). Knowing details of the sampling plan and what may impact coverage error and sampling error can help guide researchers in determining what types of demographics to include. Researchers can benefit from the work of others by using questions from other surveys. This is common with demographic questions such as race and ethnicity that use questions from a government census or other official surveys. Other survey questions can be found using question banks which are a compilation of questions that have been asked across a variety of surveys such as the Inter-university Consortium for Political and Social Research (ICPSR) variable search. If a question does not already exist in a question bank, then researchers can craft their own. When creating their own questions, researchers should start with the research question or topic and attempt to write questions that match the concept. The closer the question asked is to the overall concept the better validity there is. For example, if the researcher wants to know how people consume TV series and movies, but only ask a question about how many TVs are in the house, then they would be missing other ways that people watch TV series and movies such as on other devices or at places outside of the home. Additionally, when designing questions, researchers should consider the mode the survey will be administered in and adjust language appropriately. In self-administered surveys (e.g., web or mail), respondents can see all of the questions and response options, but that is not the case in interviewer-administered surveys (e.g., CATI or CAPI). With interviewer-administered surveys, the response options need to be read out loud to the respondents, so the question may need to be adjusted to allow a better flow to the interview. Additionally, with self-administered surveys, because the respondents are viewing the questionnaire, the formatting of the questions is even more important to ensure accurate measurement. Incorrectly formatting or wording questions can result in measurement error, so following best practices or using existing validated questions can reduce error. There are multiple resources out there to help researchers draft questions for different modes (e.g., {CITE Dillman, fowler, ed book?, asking questions, tourangeau formatting article?}). Example: Number of Pets in a Household As part of our survey on the average number of pets in a household, researchers may want to know what animal the majority of people prefer to have as a pet. Let’s say we have the following question in our survey: What animal do you prefer to have as a pet? Dogs Cats This question may have validity issues as it is only providing the options of “dogs” and “cats” to respondents and interpretation of the data could be incorrect. For example, if we had 100 respondents who answered the question and 50 selected dogs, then the results of this question cannot be: 50% of the population perfers to have a dog as a pet as only two response options were provided. If a respondent taking our survey prefers turtles, they could either be forced to choose a response between these two (i.e., interpret the question as “between dogs and cats which do you prefer?” and result in measurement error), or they may not answer the question (which results in item nonresponse error). Based on this, the interpretation of this question should be When given the choice between dogs and cats, 50% of respondents preferred to have a dog as a pet. To avoid this issue, researchers should consider these possibilities and adjust the question accordingly. One simple way could be to add an “other” response option to give respondents a chance to provide a different response. The “other” response option could then include a way for respondents to write in what their other preference is. For example, this question could be rewritten as What animal do you prefer to have as a pet? Dogs Cats Other, please specify: Researchers can then code the responses from the open-ended box and get a better understanding of the respondent’s choice of preferred pet. Interpreting this question becomes easier as researchers no longer need to qualify the results with the choices provided. This is a very simple example of how the question presentation and options can impact the findings. More complex topics and questions will need researchers to thoroughly consider how to mitigate any impacts from the presentation, formatting, wording, and other aspects. As survey analysts, reviewing not only the data but also the wording of the questions is crucial to ensure the results are presented in a manner consistent with the question asked. 2.2 Data Collection Once the data collection starts, researchers try to stick to the data collection protocol designed during pre survey planning. However, a good researcher will adjust their plans and adapt as needed to the current progress of data collection ({cite Peytchev book on adaptive survey design}). Some extreme examples could be natural disasters that could prevent mail or interviewers from getting to the sample members. Others could be smaller in that something news worthy occurs that is connected to the survey, so researchers could choose to play this up in communication materials. In addition to these external factors, there could be factors unique to the survey such as the response rates are lower for a specific sub-group, so the data collection protocol may need to find ways to improve response rates for a specific group. 2.3 Post Survey Processing After data collection, there are a variety of activities that need to be conducted before the survey can be analyzed. Multiple decisions made during this post survey phase can assist researchers in reducing different error sources such as through weighting to account for the sample selection. Knowing the decisions researchers made in creating the final analytic data can impact how analysts use the data and interpret the results. 2.3.1 Data Cleaning and Imputation Post survey cleaning and imputation is one of the first steps researchers will do to get the survey responses into a dataset for use by analysts. Data cleaning can comprise of cleaning inconsistent data (e.g., with skip pattern errors or multiple questions throughout the survey being consistent with each other), editing numeric entry or open-ended responses for grammar and consistency, or recoding open-ended questions into categories for analysis. Each project should create their own rules for how to handle different cleaning situations, and there are no specific rules that must be followed. Instead, researchers should use their best judgement in ensuring data integrity remains and all decisions should be documented and available to those using the data in analysis. Each decision a researcher makes has an impact on processing error, so often researchers often will have multiple people review these rules or recode open-ended data and adjudicate any differences in an attempt to reduce this error. Another crucial step in post survey processing is imputation. Often times there is item nonresponse where respondents do not answer specific questions. If the questions are crucial to analysis efforts or to the research question, researchers will implement imputation in an effort to reduce item nonresponse error. However, as imputation is a way of assigning a value to missing data based on an algorithm or model, it can introduce processing error as well, so researchers should consider the overall implications of imputing data compared to having item nonresponse. There are multiple ways that imputation can be conducted, we recommend reviewing other resources like {cite Kim &amp; Shao, Statistical Methods for Handling Incomplete Data} for more information. Example: Number of Pets in a Household Let’s return to the question we created to ask about animal preference. The “other specify” invites respondents to specify the type of animal they prefer to have as a pet. If respondents entered answers such as “puppy”, “turtle”, “rabit”, “rabbit”, “bunny”, “ant farm”, “snake”, “Mr. Purr”, then researchers may wish to categorize these write-in responses to help with analysis. In this example, “puppy” could be assumed to be a reference to a Dog, and could be recoded there. The misspelling of “rabit” could be coded along with “rabbit” and “bunny” into a single category of Bunny or Rabbit. These are relatively standard decisions that a researcher could make. The remaining write-in responses could be categorized into a few different ways. “Mr. Purr”, which may be someone’s reference to their own cat, could be recoded to Cat, or it could remain as Other or some category that is Unknown. Depending on the number of responses related to each of others, they could all be combined into a single Other category, or maybe categories such as Reptiles or Insects could be created. Each of these decisions may impact the interpetation of the data, so our researcher should make sure to document the types of responses that fall into each of the new categories. 2.3.2 Weighting Weighting can typically be used to address some of the error sources identified in the previous sections. For example, weights may be used to address coverage, sampling, and nonresponse errors and many published surveys will include an “analysis weight” variable that combines these adjustments. However, weighting itself can also introduce adjustment error, so researchers need to balance which types of errors should be corrected with weighting. The construction of weights is outside the scope of this book and researchers should reference other materials if interested constructing their own (e.g., {CITE Jill’s Book}). Instead, this book assumes the survey has been completed, weights are constructed, and data is made available for users. We will walk users through how to read documentation and work with the data and analysis weights provided to analyze and interpret survey results correctly. Example: Number of Pets in a Household In the simple example of our survey, we decided to use a stratified sample by state to select our sample members. Knowing this sampling design our researcher can include selection weights for analysis that account for how the sample members were selected into the survey. Additionally, the sampling frame may have the type of building associated with each address, so we could include the building type as a potential nonresponse weighting variable, along with some interviewer observations that may be related to our research topic of average number of pets in a household. Combining these weights we could create an analytic weight that researchers can use when analyzing the data. 2.3.3 Disclosure Before data is allowed to be made publicly available, researchers will need to ensure that individual respondents can not be identified by the data when confidentiality is required. There are a variety of different methods that can be used, including data swapping, top or bottom coding, coarsening, and perturbation. In data swapping, researchers may swap specific data values across different respondents such that it does not impact insights that come from the data, but ensures that specific individuals cannot be identified. For extreme values, top and bottom coding is sometimes used. For example, researchers may top-code incomes values such that households with income greater than $99,999,999 are coded into a single category of $99,999,999 or more. Other methods for disclosure may include aggregating response categories or location information to avoid having only a few respondents in a given group, and thus be identified. For example, researchers couse use coarsening to display income in categories instead of as a continuous variable. Data producers may also perturb the data by adding random noise. There is as much art as there is science to the methods used for disclosure, and in documentation researchers should only provide a high level comments that disclosure was conducted and not specific details to ensure nobody can reverse the disclosure and thus identify individuals. For more information on different disclosure methods please see {CITE Skinner chapter in this book: https://www.sciencedirect.com/science/article/abs/pii/S0169716108000151 AAPOR checklist/standards: https://www-archive.aapor.org/Standards-Ethics/AAPOR-Code-of-Ethics/Survey-Disclosure-Checklist.aspx}. 2.4 This book After all of these steps are taken, the data is ready for use by analysts. The rest of this book works from this point. If you’re interested in learning more about the steps talked about here, we recommend you look into the references cited throughout this chapter. Other modes such as using mobile apps or text messaging can also be considered, but have typically smaller reach or are better for longitudinal studies (i.e., surveying the same individuals over many waves of a single study). For the purposes of this overview we will focus on these four main modes.↩︎ "],["c03.html", "Chapter 3 Understanding survey data files", " Chapter 3 Understanding survey data files "],["c04.html", "Chapter 4 Introducing the srvyr package", " Chapter 4 Introducing the srvyr package "],["c05.html", "Chapter 5 Specifying sample designs and replicate weights in srvyr 5.1 Common sampling designs 5.2 Replicate weights 5.3 Understanding survey design documentation 5.4 Exercises", " Chapter 5 Specifying sample designs and replicate weights in srvyr The primary reason for using packages like {survey} and {srvyr} are to incorporate the sampling design or replicate weights into estimates. By incorporating the sampling design or replicate weights, precision estimates (e.g., standard errors and confidence intervals) are appropriately calculated. In this chapter, we will introduce common sampling designs and common types of replicate weights, the mathematical methods for calculating estimates and standard errors for a given sampling design, and the R syntax to specify the sampling design or replicate weights. While we will show the math behind the estimates, the functions in these packages will do the calculation. To deeply understand the math and the derivation, refer to Särndal, Swensson, and Wretman (2003), Wolter (2007), or Fuller (2011). The general process for estimation in the {srvyr} package is to: Create a tbl_svy object (a survey object) using: as_survey_design or as_survey_rep Subset data (if needed) using filter (subpopulations) Specify domains of analysis using group_by Within summarize, specify variables to calculate including means, totals, proportions, quantiles, and more This chapter includes details on the first step - creating the survey object. The other steps are detailed in the next several chapters. 5.1 Common sampling designs A sampling design is the method used to draw a sample. Both logistical and statistical elements are considered when developing a sampling design. When specifying a sampling design in R, the levels of sampling are specified along with the weights. Each record of a weight is constructed so that the particular record represents that many units in the population. For example, in a survey of 6th grade students in the United States, the weight associated with each responding student reflects how many students that record represents. Generally, the sum of the weights sum to the population total though some studies have the sum of the weights sum to the number of respondent records. Some common terminology across the designs are: sample size, generally denoted as \\(n\\), is the number of units selected population size, generally denoted as \\(N\\), is the number of units in the population sampling frame is the list of units from which the sample is drawn 5.1.1 Simple random sample without replacement Description: The simple random sample (SRS) without replacement is a sampling design where a fixed sample size is selected from a sampling frame, and every possible subsample has equal probability of selection. Requirements: The sampling frame must include the entire population. Advantages: SRS requires no information about the units apart from contact information. Disadvantages: The sampling frame may not be available for entire population. This design is not generally feasible for in-person data collection. Example: Randomly students in a university from a roster provided by the registrar’s office. The math The estimate for the population mean of variable \\(y\\) is: \\[\\bar{y}=\\frac{1}{n}\\sum_{i=1}^n y_i\\] and the estimate of the standard error of mean is: \\[se(\\bar{y})=\\sqrt{\\frac{s^2}{n}\\left( 1-\\frac{n}{N} \\right)}\\] where \\[s^2=\\frac{1}{n-1}\\sum_{i=1}^n\\left(y_i-\\bar{y}\\right)^2.\\] This standard error estimate might look very similar to equations in other applications except for the part on the right side of the equation: \\(1-\\frac{n}{N}\\). This is called the finite population correction factor (FPC), and if the size of the frame, \\(N\\), is very large, the FPC is negligible so it is often ignored. To estimate proportions, we define \\(x_i\\) as the indicator if the outcome is observed. That is, \\(x_i=1\\) if the outcome is observed and \\(x_i=0\\) if the outcome is not observed. Then the estimated proportion from a SRS design is: \\[\\hat{p}=\\frac{1}{n}\\sum_{i=1}^n x_i \\] and the estimated standard error of the proportion is: \\[se(\\hat{p})=\\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n-1}\\left(1-\\frac{n}{N}\\right)} \\] The syntax If a sample was drawn through SRS and had no nonresponse or other weighting adjustments, in R specify this design as: des_srs1 &lt;- dat %&gt;% as_survey_design(fpc = fpcvar) where dat is a tibble or data.frame with the survey data and fpcvar is a variable on the tibble which indicates the size of the sampling frame. If the frame was very large, sometimes the frame size is not provided. In that case, the fpc is not needed and specify the design as: des_srs2 &lt;- dat %&gt;% as_survey_design() If some post-survey adjustments were implemented and the weights are not all equal, specify the design as: des_srs3 &lt;- dat %&gt;% as_survey_design(weights = wtvar, fpc = fpcvar) where wtvar is the variable for the weight on the data. Again, the fpc can be omitted if it is not necessary because the frame is large. Example The {survey} package in R provides some example datasets to use and those will be used throughout this chapter. Reading the documentation about these datasets provide detail on the variables. One of the example datasets we will use is from the Academic Performance Index (API). The API was a program administered by the California Department of Education and the {survey} package includes a population file (frame) of all schools with at least 100 students and several different samples pulled from that data using different sampling methods. For this first example, we will use the apisrs dataset, which contains a SRS of 200 schools. For printing purposes, we create a new dataset called apisrs_slim, which sorts the data by school district and school ID and subsets the data to only a few columns. The SRS sample data is illustrated below: options(tidyverse.quiet = TRUE) library(tidyverse) library(survey) library(srvyr) data(api) apisrs_slim &lt;- apisrs %&gt;% as_tibble() %&gt;% arrange(dnum, snum) %&gt;% select(cds, dnum, snum, dname, sname, fpc, pw) apisrs_slim ## # A tibble: 200 × 7 ## cds dnum snum dname sname fpc pw ## &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 19642126061220 1 1121 ABC Unified Haske… 6194 31.0 ## 2 19642126066716 1 1124 ABC Unified Stowe… 6194 31.0 ## 3 36675876035174 5 3895 Adelanto Elementary Adela… 6194 31.0 ## 4 33669776031512 19 3347 Alvord Unified Arlan… 6194 31.0 ## 5 33669776031595 19 3352 Alvord Unified Wells… 6194 31.0 ## 6 31667876031033 39 3271 Auburn Union Elementary Cain … 6194 31.0 ## 7 19642876011407 42 1169 Baldwin Park Unified Deanz… 6194 31.0 ## 8 19642876011464 42 1175 Baldwin Park Unified Heath… 6194 31.0 ## 9 19642956011589 48 1187 Bassett Unified Erwin… 6194 31.0 ## 10 41688586043392 49 4948 Bayshore Elementary Baysh… 6194 31.0 ## # … with 190 more rows School districts have identifiers dnum within counties and schools have identifiers of snum within districts along with their names, dname and sname. The unique identifier for a school is cds which is unique within the state. Additionally, the fpc is included as fpc and the weight as pw. To create the tbl_survey object for this SRS data, the design should be specified as: des_apisrs &lt;- apisrs_slim %&gt;% as_survey_design(weights = pw, fpc = fpc) des_apisrs ## Independent Sampling design ## Called via srvyr ## Sampling variables: ## - ids: `1` ## - fpc: fpc ## - weights: pw ## Data variables: cds (chr), dnum (int), snum (dbl), dname (chr), sname ## (chr), fpc (dbl), pw (dbl) summary(des_apisrs) ## Independent Sampling design ## Called via srvyr ## Probabilities: ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.0323 0.0323 0.0323 0.0323 0.0323 0.0323 ## Population size (PSUs): 6194 ## Data variables: ## [1] &quot;cds&quot; &quot;dnum&quot; &quot;snum&quot; &quot;dname&quot; &quot;sname&quot; &quot;fpc&quot; &quot;pw&quot; In the printed design object above, the design is described as an “Independent Sampling design” which is another terminology for SRS. The ids are specified as 1 which means there is no clustering (a topic described later in this chapter), the fpc variable is indicated, and the weights are indicated. When looking at the summary of the design object, the population size is given as a summary of the probabilities (inverse of the weights). 5.1.2 Simple random sample with replacement Description: The simple random sample with replacement (SRSWR) is a sampling design where a sample is selected from a sampling frame with the units being replaced before drawing again, so units can be selected more than once. Requirements: The sampling frame must include the entire population. Advantages: SRSWR requires no information about the units apart from contact information. Disadvantages: The sampling frame may not be available for entire population. This design is not generally feasible for in-person data collection. Units can be selected more than once resulting in a smaller realized sample size. For small populations, SRSWR has larger standard errors than SRS designs. Example: A professor puts all students names on paper slips and selects them randomly to ask students questions but the professor replaces the paper after calling on the student so they can be selected again at any time. The math The estimate for the population mean of variable \\(y\\) is: \\[\\bar{y}=\\frac{1}{n}\\sum_{i=1}^n y_i\\] and the estimate of the standard error of mean is: \\[se(\\bar{y})=\\sqrt{\\frac{s^2}{n}}\\] where \\[s^2=\\frac{1}{n-1}\\sum_{i=1}^n\\left(y_i-\\bar{y}\\right)^2.\\] To calculate the estimated proportion, we define \\(x_i\\) as the indicator that the outcome is observed (as we did with SRS): \\[\\hat{p}=\\frac{1}{n}\\sum_{i=1}^n x_i \\] and the estimated standard error of the proportion is: \\[se(\\hat{p})=\\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}} \\] The syntax If you had a sample that was drawn through SRSWR and had no nonresponse or other weighting adjustments, in R, you should specify this design as: des_srswr1 &lt;- dat %&gt;% as_survey_design() where dat is a tibble or data.frame with your survey data. If some post-survey adjustments were implemented and the weights are not all equal, specify the design as: des_srswr2 &lt;- dat %&gt;% as_survey_design(weights = wtvar) where wtvar is the variable for the weight on the data. Example The {survey} package does not include an example of SRSWR so we create an example from the population data provided. We call this new dataset apisrswr. set.seed(409963) apisrswr &lt;- apipop %&gt;% as_tibble() %&gt;% slice_sample(n = 200, replace = TRUE) %&gt;% select(cds, dnum, snum, dname, sname) %&gt;% mutate( weight = nrow(apipop)/200 ) head(apisrswr) ## # A tibble: 6 × 6 ## cds dnum snum dname sname weight ## &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 43696416060065 533 5348 Palo Alto Unified Jordan (Da… 31.0 ## 2 07618046005060 650 509 San Ramon Valley Unified Alamo Elem… 31.0 ## 3 19648086085674 457 2134 Montebello Unified La Merced … 31.0 ## 4 07617056003719 346 377 Knightsen Elementary Knightsen … 31.0 ## 5 19650606023022 744 2351 Torrance Unified Carr (Evel… 31.0 ## 6 01611196090120 6 13 Alameda City Unified Paden (Wil… 31.0 Because this is a SRS design with replacement there will be duplicates in the data. It is important to keep the duplicates in the data for proper estimation, but for reference here are the duplicates in the example we just created. apisrswr %&gt;% group_by(cds) %&gt;% filter(n()&gt;1) %&gt;% arrange(cds) ## # A tibble: 4 × 6 ## # Groups: cds [2] ## cds dnum snum dname sname weight ## &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 15633216008841 41 869 Bakersfield City Elem Chipman Junio… 31.0 ## 2 15633216008841 41 869 Bakersfield City Elem Chipman Junio… 31.0 ## 3 39686766042782 716 4880 Stockton City Unified Tyler Skills … 31.0 ## 4 39686766042782 716 4880 Stockton City Unified Tyler Skills … 31.0 A weight variable was added which is the inverse of the probability of selection. To specify the sampling design for apisrswr, the following syntax should be used: des_apisrswr &lt;- apisrswr %&gt;% as_survey_design(weights = weight) des_apisrswr ## Independent Sampling design (with replacement) ## Called via srvyr ## Sampling variables: ## - ids: `1` ## - weights: weight ## Data variables: cds (chr), dnum (int), snum (dbl), dname (chr), sname ## (chr), weight (dbl) summary(des_apisrswr) ## Independent Sampling design (with replacement) ## Called via srvyr ## Probabilities: ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.0323 0.0323 0.0323 0.0323 0.0323 0.0323 ## Data variables: ## [1] &quot;cds&quot; &quot;dnum&quot; &quot;snum&quot; &quot;dname&quot; &quot;sname&quot; &quot;weight&quot; In the chunk above, the design object is printed and the object summary is shown. Both of these note that the sampling is done “with replacement” because no fpc was specified. In the summary, the probabilities, which are derived from the weights, are summarized. 5.1.3 Stratified sampling Description: A population is divided into mutually exclusive subpopulations (strata) and then samples are selected independently within each stratum. Requirements: The sampling frame must include the information to divide the population into groups for every unit. Advantages: This design ensures sample representation in all subpopulations. Often, for the same sample size as a SRS sample, the standard errors are smaller so it is a more efficient design. This is true if the strata are correlated with outcomes. Disadvantages: Auxiliary data may not exist to divide sampling frame into groups or the data may be outdated. Examples: Example 1: A population of North Carolina residents could be separated into urban and rural areas and then a SRS of residents from both rural and urban areas is selected independently. This ensures there are rural residents in the sample. Example 2: There are 3 primary general purpose law enforcement agencies in the US - local police, sheriff’s departments, and state police. In a survey of law enforcement agencies, the agency type could be used to form strata. The math Let \\(\\bar{y}_h\\) be the sample mean for stratum \\(h\\), \\(N_h\\) be the population size of stratum \\(h\\), and \\(n_h\\) be the sample size of stratum \\(h\\). Then the estimate for the population mean under stratified SRS sampling is: \\[\\bar{y}=\\frac{1}{N}\\sum_{h=1}^H N_h\\bar{y}_h\\] and the estimate of the standard error of \\(\\bar{y}\\) is: \\[se(\\bar{y})=\\sqrt{\\frac{1}{N^2} \\sum_{h=1}^H N_h^2 s_h^2\\left(1-\\frac{n_h}{N_h}\\right)} \\] where \\[s_h^2=\\frac{1}{n_h-1}\\sum_{i=1}^{n_h}\\left(y_{i,h}-\\bar{y}_h\\right)^2.\\] For estimates of proportions, let \\(\\hat{p}_h\\) be the estimated proportion in stratum \\(h\\). Then the population proportion estimate is: \\[\\hat{p}= \\frac{1}{N}\\sum_{h=1}^H N_h \\hat{p}_h\\] and the standard error of the proportion is: \\[se(\\hat{p}) = \\frac{1}{N} \\sqrt{ \\sum_{h=1}^H N_h^2 \\frac{\\hat{p}_h(1-\\hat{p}_h)}{n_h-1} \\left(1-\\frac{n_h}{N_h}\\right)}\\] The syntax To specify a stratified SRS design in {srvyr} where the population sizes of the strata are not too large and are known, that is you are using the fpc, specify the design as: des_stsrs1 &lt;- dat %&gt;% as_survey_design(fpc = fpcvar, strata = stratvar) where fpcvar is a variable on your data which indicates \\(N_h\\) for each row and stratavar is a variable indicating the stratum for each row. You can omit the fpc if it is not applicable. Additionally, you can indicate the weight variable if it is present where wtvar is a variable on your data with a numeric weight. des_stsrs2 &lt;- dat %&gt;% as_survey_design(weights = wtvar, strata = stratvar) Example In the example API data, apistrat is a stratified random sample, stratified by school type (stype). As with the SRS example above, we sort and select specific variables for use of printing. The data are illustrated below including a count of the number of cases per stratum: apistrat_slim &lt;- apistrat %&gt;% as_tibble() %&gt;% arrange(dnum, snum) %&gt;% select(cds, dnum, snum, dname, sname, stype, fpc, pw) apistrat_slim %&gt;% count(stype, fpc) ## # A tibble: 3 × 3 ## stype fpc n ## &lt;fct&gt; &lt;dbl&gt; &lt;int&gt; ## 1 E 4421 100 ## 2 H 755 50 ## 3 M 1018 50 The fpc is the same within each stratum and 100 elementary schools were sampled while 50 schools were sampled from both the middle and high school levels. This design should be specified as: des_apistrat &lt;- apistrat_slim %&gt;% as_survey_design(strata = stype, weights = pw, fpc = fpc) des_apistrat ## Stratified Independent Sampling design ## Called via srvyr ## Sampling variables: ## - ids: `1` ## - strata: stype ## - fpc: fpc ## - weights: pw ## Data variables: cds (chr), dnum (int), snum (dbl), dname (chr), sname ## (chr), stype (fct), fpc (dbl), pw (dbl) summary(des_apistrat) ## Stratified Independent Sampling design ## Called via srvyr ## Probabilities: ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.0226 0.0226 0.0359 0.0401 0.0534 0.0662 ## Stratum Sizes: ## E H M ## obs 100 50 50 ## design.PSU 100 50 50 ## actual.PSU 100 50 50 ## Population stratum sizes (PSUs): ## E H M ## 4421 755 1018 ## Data variables: ## [1] &quot;cds&quot; &quot;dnum&quot; &quot;snum&quot; &quot;dname&quot; &quot;sname&quot; &quot;stype&quot; &quot;fpc&quot; &quot;pw&quot; When printing the object, it is specified as a “Stratified Independent Sampling design” also known as a stratified SRS and the strata variable is included. In the summary, a numeric summary of the probabilities of selection are displayed as well as the sample and population stratum sizes. 5.1.4 Clustered sampling Description: A population is divided into mutually exclusive subgroups called clusters or primary sampling units (PSUs). A random selection of PSUs are sampled and then another level of sampling is done within these clusters. There can be multiple levels of this selection. Clustered sampling is often used when a list of the entire population is not available or data collection involves interviewers needing direct contact with respondents. Requirements: There must have be a way to divide the population into clusters. Clusters are commonly structural such as institutions (e.g., schools, prisons) or geographic (e.g., states, counties). Advantages: Clustered sampling is advantageous when data collection is done in person so interviewers are sent to specific sampled areas rather than completely at random across a country. With cluster sampling, a list of the entire population is not necessary. For example, if sampling students, you do not need a list of all students but only a list of all schools. Once the schools are sampled, lists of students can be obtained within the sampled schools. Disadvantages: Compared to a simple random sample, for the same sample size, clustered samples generally have larger standard errors of estimates. Examples: Example 1: Consider a study needing a sample of 6th grade students in the United States, no list likely exists of all these students. However, it is more likely to be possible to obtain a list of schools that have 6th graders, so a study design could select a random sample of schools that have 6th graders. The selected schools can then provide a list of students to do a second stage of sampling where 6th grade students are randomly sampled within each of the sampled schools. This is a one-stage sample design and will be the type of design we will discuss in formulas below. Example 2: Consider a study sending interviewers to households for a survey. This is a more complicated example that requires two levels of selection, to efficiently use interviewers in geographic clusters. First, in the U.S. counties could be selected as the PSU, then Census block groups within counties could be selected as the secondary sampling unit (SSU). Households could then randomly sampled within the block groups. This type of design is popular for in-person survey as it reduces the travel necessary for interviewers. The math Consider a population where the are \\(N\\) clusters and \\(n\\) clusters are sampled via SRS. Units within each sampled cluster are sampled via SRS as well. Let \\(M_i\\) be the number of units in cluster \\(i\\) and \\(\\bar{y}_i\\) be the sample mean of cluster \\(i\\). Then, a ratio estimator of the population mean is: \\[\\bar{y}=\\frac{\\sum_{i=1}^n M_i \\bar{y}_i}{ \\sum_{i=1}^n M_i}\\] Note this is a consistent but biased estimator. Often the population size is not known so this is a method to estimate a mean without knowing the population size. The estimated standard error of the mean is: \\[se(\\bar{y})=\\frac{1}{\\hat{N}_{pop} } \\sqrt{\\frac{N^2 (1-\\frac{n}{N})}{n}\\frac{1}{n-1} \\sum_{i=1}^n (M_i\\bar{y}_i -\\hat{t}/N)^2 + \\frac{N}{n} \\sum_{i=1}^n \\frac{M_i^2}{m_i}\\left(1-\\frac{m_i}{M_i}\\right)s^2_i }\\] where \\(\\hat{N}_{pop}\\) is the estimated population size, \\(\\hat{t}\\) is the estimated total, and \\(s_i^2\\) is the sample variance of cluster \\(i\\). For estimates of proportions, the estimated proportion is: \\[\\hat{p}=\\frac{\\sum_{i=1}^n M_i \\hat{p}_i}{ \\sum_{i=1}^n M_i}\\] and the associated standard error estimate is: \\[se(\\hat{p})=\\frac{1}{\\hat{N}_{pop} } \\sqrt{\\frac{N^2 (1-\\frac{n}{N})}{n}\\frac{1}{n-1} \\sum_{i=1}^n (M_i\\hat{p}_i -\\hat{t}/N)^2 + \\frac{N}{n} \\sum_{i=1}^n \\frac{M_i^2}{m_i}\\left(1-\\frac{m_i}{M_i}\\right)s^2_i }\\] where \\(s^2_i\\) is defined as: \\[s^2_i = \\frac{m_hp_h(1-p_h)}{m_h-1}\\]. The syntax To specify a two-stage clustered design without replacement, use the following syntax: des_clus2 &lt;- dat %&gt;% as_survey_design(weights = wtvar, ids = c(PSU, SSU), fpc = c(N, M)) where PSU and SSU are the variables indicating the PSU and SSU identifiers and N and M are the variables indicating the population sizes for each level (i.e., N is the number of clusters and M is the number of units within each cluster). Note that N will be the same for all records (within a strata) and M will be the same for all records within the same cluster. If clusters were sampled with replacement or from a very large population, a fpc is not necessary. Additionally, only the first stage of selection is necessary regardless of whether the units were selected with replacement at any stage. The subsequent stages of selection are ignored in computation as their contribution to the variance is overpowered by the first stage, see Särndal, Swensson, and Wretman (2003) or Wolter (2007) for a more in-depth discussion. The syntax below will yield the same estimates in the end: des_clus2wra &lt;- dat %&gt;% as_survey_design(weights = wtvar, ids = c(PSU, SSU)) des_clus2wrb &lt;- dat %&gt;% as_survey_design(weights = wtvar, ids = PSU) Example The survey package includes a two-stage cluster sample data, apiclus2, in which school districts were sampled and then a random sample of 5 schools was selected within each district. For districts with fewer than 5 schools, all schools were sampled. School districts are identified by dnum and schools are identified by snum. The variable fpc1 indicates how many districts there are in California (N) and fpc2 indicates how many schools were in a given district with at least 100 students (M). The data has a row for each school. In the data printed below, there are 757 school districts as indicated by fpc1 and there are 9 schools in district 731, one school in district 742, 2 schools in district 768, and so on as indicated by fpc2. For illustration purposes, the object apiclus2_slim has been created from apiclus2, which subsets the data to only the necessary columns and sorts data. apiclus2_slim &lt;- apiclus2 %&gt;% as_tibble() %&gt;% arrange(desc(dnum), snum) %&gt;% select(cds, dnum, snum, fpc1, fpc2, pw) apiclus2_slim ## # A tibble: 126 × 6 ## cds dnum snum fpc1 fpc2 pw ## &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int[1d]&gt; &lt;dbl&gt; ## 1 47704826050942 795 5552 757 1 18.9 ## 2 07618126005169 781 530 757 6 22.7 ## 3 07618126005177 781 531 757 6 22.7 ## 4 07618126005185 781 532 757 6 22.7 ## 5 07618126005193 781 533 757 6 22.7 ## 6 07618126005243 781 535 757 6 22.7 ## 7 19650786023337 768 2371 757 2 18.9 ## 8 19650786023345 768 2372 757 2 18.9 ## 9 54722076054423 742 5898 757 1 18.9 ## 10 50712906053086 731 5781 757 9 34.1 ## # … with 116 more rows To specify this design in R, the following syntax should be used: des_apiclus2 &lt;- apiclus2_slim %&gt;% as_survey_design(ids = c(dnum, snum), fpc = c(fpc1, fpc2), weights=pw) des_apiclus2 ## 2 - level Cluster Sampling design ## With (40, 126) clusters. ## Called via srvyr ## Sampling variables: ## - ids: `dnum + snum` ## - fpc: `fpc1 + fpc2` ## - weights: pw ## Data variables: cds (chr), dnum (int), snum (dbl), fpc1 (dbl), fpc2 ## (int[1d]), pw (dbl) summary(des_apiclus2) ## 2 - level Cluster Sampling design ## With (40, 126) clusters. ## Called via srvyr ## Probabilities: ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.00367 0.03774 0.05284 0.04239 0.05284 0.05284 ## Population size (PSUs): 757 ## Data variables: ## [1] &quot;cds&quot; &quot;dnum&quot; &quot;snum&quot; &quot;fpc1&quot; &quot;fpc2&quot; &quot;pw&quot; The design objects are described as “2 - level Cluster Sampling design” and includes the ids (cluster), fpc, and weight variables. In the summary, it is noted that the sample includes 40 first-level clusters (PSUs) which are school districts and 126 second-level clusters (SSUs) which are schools. Additionally, the summary includes a numeric summary of the probabilities and the population size (number of PSUs) as 757. 5.2 Replicate weights Replicate weights are often included on analysis files instead of, or in addition to, the design variables (strata and PSUs). Replicate weights are used as another method to estimate variability and often used specifically so that design variables are not published as a measure to limit disclosure risk. There are several types of replicate weights including balanced repeated replication (BRR), Fay’s BRR, jackknife, and bootstrap methods. An overview of the process for using replicate weights is: Divide the sample into subsample replicates that mirror the design of the sample Calculate weights for each replicate using the same procedures for full-sample weight (i.e., nonresponse and post-stratification) Calculate estimates for each replicate using the same method as the full-sample estimate Calculate the estimated variance which will be proportional to the variance of the replicate estimates The different types of replicate weights largely differ in step 1 - how the sample is divided into subsamples and step 4 - which multiplication factors (scales) are used to multiply the variance. 5.2.1 BRR method The BRR method requires a stratified sample design with two PSUs in each stratum. Each replicate is constructed by deleting one PSU per stratum using a Hadamard matrix. For the PSU that is included, the weight is generally multiplied by 2 but may have other adjustments, such as post-stratification. A Hadamard matrix is a special square matrix with entries of +1 or -1 with mutually orthogonal rows. Hadamard matrices must have 1 row, 2 rows, or a multiple of 4 rows. An example of a \\(4\\times4\\) Hadamard matrix is below: \\[ \\begin{array}{rrrr} +1 &amp;+1 &amp;+1 &amp;+1\\\\ +1&amp;-1&amp;+1&amp;-1\\\\ +1&amp;+1&amp;-1&amp;-1\\\\ +1 &amp;-1&amp;-1&amp;+1 \\end{array} \\] The columns specify the strata and the rows the replicate. In the first replicate all the values are +1, so in each stratum the first PSU would be used in the estimate. In the second replicate, the first PSU would be used in stratum 1 and 3, while the second PSU would be used in stratum 2 and 4. In the third replicate, the first PSU would be used in stratum 1 and 2, while the second PSU would be used in stratum 3 and 4. Finally, in the fourth replicate, the first PSU would be used in stratum 1 and 4, while the second PSU would be used in stratum 2 and 3. The math A weighted estimate for the full sample is calculated as \\(\\hat{\\theta}\\) and then a weighted estimate for each replicate is calculated as \\(\\hat{\\theta}_r\\) for \\(R\\) replicates. Then the standard error of the estimate is calculated as: \\[se(\\hat{\\theta})=\\sqrt{\\frac{1}{R} \\sum_{r=1}^R \\left( \\hat{\\theta}_r-\\hat{\\theta}\\right)^2}\\] Specifying replicate weights in R requires specifying the type of replicate weights, the main weight variable, the replicate weight variables, and some other options. One of the key options is for mse. If mse=TRUE, variances are computed around the point estimate \\((\\hat{\\theta})\\), whereas if mse=FALSE, variances are computed around the mean of the replicates \\((\\bar{\\theta})\\) instead which looks like this: \\[se(\\hat{\\theta})=\\sqrt{\\frac{1}{R} \\sum_{r=1}^R \\left( \\hat{\\theta}_r-\\bar{\\theta}\\right)^2}\\] where \\[\\bar{\\theta}=\\frac{1}{R}\\sum_{r=1}^R \\hat{\\theta}_r\\] The default option for mse is to use the global option of “survey.replicates.mse” which is set to FALSE initially unless a user changes it. Unless documentation states otherwise, for BRR, set mse to TRUE. The syntax Replicate weights generally come in groups and are sequentially numbered such as PWGTP1, PWGTP2, …, PWGTP80 in the American Community Survey (ACS) or BRRWT1, BRRWT2, …, BRRWT96 in the 2015 Residential Energy Consumption Survey (RECS). The {srvyr} package relies on tidy selection2 to choose variables. If replicate weight variables need to be specified with a character vector, use the all_of function to select variables from a character vector. Some other methods are also illustrated below in the examples but these apply to any type of replicate weights and not just BRR. If a dataset had WT0 for the main weight and had 20 BRR weights indicated WT1, WT2, …, WT20, use the following syntax (both are equivalent): des_brr &lt;- dat %&gt;% as_survey_rep(weights = WT0, repweights= all_of(str_c(&quot;WT&quot;, 1:20)), type=&quot;BRR&quot;, mse=TRUE) des_brr &lt;- dat %&gt;% as_survey_rep(weights = WT0, repweights= num_range(&quot;WT&quot;, 1:20), type=&quot;BRR&quot;, mse=TRUE) If a dataset had WT for the main weight and had 20 BRR weights indicated REPWT1, REPWT2, …, REPWT20, the following syntax could be used (both are equivalent): des_brr &lt;- dat %&gt;% as_survey_rep(weights = WT, repweights= all_of(str_c(&quot;REPWT&quot;, 1:20)), type=&quot;BRR&quot;, mse=TRUE) des_brr &lt;- dat %&gt;% as_survey_rep(weights = WT, repweights= starts_with(&quot;REPWT&quot;), type=&quot;BRR&quot;, mse=TRUE) If the replicate weight variables are on the file consecutively, the following syntax can also be used: des_brr &lt;- dat %&gt;% as_survey_rep(weights = WT, repweights= REPWT1:REPWT20, type=&quot;BRR&quot;, mse=TRUE) Typically, the replicate weights sum to a value similar to the main weight as they are both supposed to provide population estimates. Rarely, an alternative method will be used where the replicate weights have values of 0 or 2 in the case of BRR weights. This would be indicated in the documentation and in Section 5.3, we discuss how to understand documentation. In this case, the replicate weights are not combined and the option combined_weights = FALSE should be indicated, as the default value for this argument is TRUE. This specific syntax is shown below: des_brr &lt;- dat %&gt;% as_survey_rep(weights = WT, repweights= starts_with(&quot;REPWT&quot;), type=&quot;BRR&quot;, combined_weights = FALSE, mse=TRUE) Example The {survey} package includes a data example from Section 12.2 of Levy and Lemeshow (2013). In this fictional data, two out of five ambulance stations were sampled from each of three emergency service areas (ESAs) thus BRR weights are appropriate with 2 PSUs (stations) sampled in each stratum (ESA). In the code below, BRR weights are created as was done in Levy and Lemeshow (2013). data(scd) scdbrr &lt;- scd %&gt;% as_tibble() %&gt;% mutate( wt=5/2, rep1 = 2 * c(1, 0, 1, 0, 1, 0), rep2 = 2 * c(1, 0, 0, 1, 0, 1), rep3 = 2 * c(0, 1, 1, 0, 0, 1), rep4 = 2 * c(0, 1, 0, 1, 1, 0)) scdbrr ## # A tibble: 6 × 9 ## ESA ambulance arrests alive wt rep1 rep2 rep3 rep4 ## &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 1 120 25 2.5 2 2 0 0 ## 2 1 2 78 24 2.5 0 0 2 2 ## 3 2 1 185 30 2.5 2 0 2 0 ## 4 2 2 228 49 2.5 0 2 0 2 ## 5 3 1 670 80 2.5 2 0 0 2 ## 6 3 2 530 70 2.5 0 2 2 0 To specify the BRR weights, the following syntax is used: des_brr_scd &lt;- scdbrr %&gt;% as_survey_rep(type = &quot;BRR&quot;, repweights = starts_with(&quot;rep&quot;), combined_weights = FALSE, weight=wt) des_brr_scd ## Call: Called via srvyr ## Balanced Repeated Replicates with 4 replicates. ## Sampling variables: ## - repweights: `rep1 + rep2 + rep3 + rep4` ## - weights: wt ## Data variables: ESA (int), ambulance (int), arrests (dbl), alive (dbl), ## wt (dbl), rep1 (dbl), rep2 (dbl), rep3 (dbl), rep4 (dbl) summary(des_brr_scd) ## Call: Called via srvyr ## Balanced Repeated Replicates with 4 replicates. ## Sampling variables: ## - repweights: `rep1 + rep2 + rep3 + rep4` ## - weights: wt ## Data variables: ESA (int), ambulance (int), arrests (dbl), alive (dbl), ## wt (dbl), rep1 (dbl), rep2 (dbl), rep3 (dbl), rep4 (dbl) ## Variables: ## [1] &quot;ESA&quot; &quot;ambulance&quot; &quot;arrests&quot; &quot;alive&quot; &quot;wt&quot; ## [6] &quot;rep1&quot; &quot;rep2&quot; &quot;rep3&quot; &quot;rep4&quot; Note that combined_weights was specified as FALSE because these weights are simply specified as 0 and 2 and do not incorporate the overall weight. When printing the object, the type of replication is noted as Balanced Repeated Replicates, the replicate weights are specified, and the weight variable. When looking at the summary, the only additional information provided are the variables included. 5.2.2 Fay’s BRR Method Fay’s BRR method for replicate weights still uses a Hadamard matrix to construct replicate weights but rather than deleting PSUs for each replicate, half of the PSUs have a replicate weight which is the main weight multiplied by \\(\\rho\\) and the other half have the main weight multiplied by \\((2-\\rho)\\) where \\(0 \\le \\rho &lt; 1\\). Note that when \\(\\rho=0\\), this is equivalent to the standard BRR weights and as \\(\\rho\\) becomes closer to 1, this method is more similar to jackknife discussed in the next section. To obtain the value of \\(\\rho\\), it is necessary to read the documentation as discussed in Section 5.3. The math The standard error estimate for \\(\\hat{\\theta}\\) is slightly different and calculated as: \\[se(\\hat{\\theta})=\\sqrt{\\frac{1}{R (1-\\rho)^2} \\sum_{r=1}^R \\left( \\hat{\\theta}_r-\\hat{\\theta}\\right)^2}\\] The syntax The syntax is very similar for BRR and Fay’s BRR. If a dataset had WT0 for the main weight and had 20 BRR weights indicated WT1, WT2, …, WT20, and Fay’s multiplier is 0.5, use the following syntax: des_fay &lt;- dat %&gt;% as_survey_rep(weights = WT0, repweights= num_range(&quot;WT&quot;, 1:20), type=&quot;Fay&quot;, mse=TRUE, rho=0.5) Example The 2015 RECS uses Fay’s BRR weights with the final weight as NWEIGHT and replicate weights as BRRWT1 - BRRWT96 with \\(\\rho=0.5\\)3. On the file, DOEID is a unique identifier for each respondent, TOTALDOL is the total cost of energy, TOTSQFT_EN is the total square footage of the residence, and REGOINC is the Census region. To specify this design, use the following syntax: recs_in &lt;- read_csv( here::here(&quot;RawData&quot;, &quot;RECS_2015&quot;, &quot;recs2015_public_v4.csv&quot;)) ## Rows: 5686 Columns: 759 ## ── Column specification ──────────────────────────────────────────────── ## Delimiter: &quot;,&quot; ## chr (4): METROMICRO, UATYP10, CLIMATE_REGION_PUB, IECC_CLIMATE_PUB ## dbl (755): DOEID, REGIONC, DIVISION, TYPEHUQ, ZTYPEHUQ, CELLAR, ZCEL... ## ## ℹ Use `spec()` to retrieve the full column specification for this data. ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message. des_recs &lt;- recs_in %&gt;% as_survey_rep( weights = NWEIGHT, repweights = BRRWT1:BRRWT96, type = &quot;Fay&quot;, rho = 0.5, mse = TRUE, variables = c(DOEID, TOTALDOL, TOTSQFT_EN, REGIONC) ) des_recs ## Call: Called via srvyr ## Fay&#39;s variance method (rho= 0.5 ) with 96 replicates and MSE variances. ## Sampling variables: ## - repweights: `BRRWT1 + BRRWT2 + BRRWT3 + BRRWT4 + BRRWT5 + BRRWT6 + BRRWT7 + BRRWT8 + BRRWT9 + BRRWT10 + BRRWT11 + BRRWT12 + BRRWT13 + BRRWT14 + BRRWT15 + BRRWT16 + BRRWT17 + BRRWT18 + BRRWT19 + BRRWT20 + BRRWT21 + BRRWT22 + BRRWT23 + BRRWT24 + BRRWT25 + BRRWT26 + BRRWT27 + BRRWT28 + BRRWT29 + BRRWT30 + BRRWT31 + BRRWT32 + BRRWT33 + BRRWT34 + BRRWT35 + BRRWT36 + BRRWT37 + BRRWT38 + BRRWT39 + BRRWT40 + BRRWT41 + BRRWT42 + BRRWT43 + BRRWT44 + BRRWT45 + BRRWT46 + BRRWT47 + BRRWT48 + BRRWT49 + BRRWT50 + BRRWT51 + \\n BRRWT52 + BRRWT53 + BRRWT54 + BRRWT55 + BRRWT56 + BRRWT57 + BRRWT58 + BRRWT59 + BRRWT60 + BRRWT61 + BRRWT62 + BRRWT63 + BRRWT64 + BRRWT65 + BRRWT66 + BRRWT67 + BRRWT68 + BRRWT69 + BRRWT70 + BRRWT71 + BRRWT72 + BRRWT73 + BRRWT74 + BRRWT75 + BRRWT76 + BRRWT77 + BRRWT78 + BRRWT79 + BRRWT80 + BRRWT81 + BRRWT82 + BRRWT83 + BRRWT84 + BRRWT85 + BRRWT86 + BRRWT87 + BRRWT88 + BRRWT89 + BRRWT90 + BRRWT91 + BRRWT92 + BRRWT93 + BRRWT94 + BRRWT95 + BRRWT96` ## - weights: NWEIGHT ## Data variables: DOEID (dbl), TOTALDOL (dbl), TOTSQFT_EN (dbl), REGIONC ## (dbl) summary(des_recs) ## Call: Called via srvyr ## Fay&#39;s variance method (rho= 0.5 ) with 96 replicates and MSE variances. ## Sampling variables: ## - repweights: `BRRWT1 + BRRWT2 + BRRWT3 + BRRWT4 + BRRWT5 + BRRWT6 + BRRWT7 + BRRWT8 + BRRWT9 + BRRWT10 + BRRWT11 + BRRWT12 + BRRWT13 + BRRWT14 + BRRWT15 + BRRWT16 + BRRWT17 + BRRWT18 + BRRWT19 + BRRWT20 + BRRWT21 + BRRWT22 + BRRWT23 + BRRWT24 + BRRWT25 + BRRWT26 + BRRWT27 + BRRWT28 + BRRWT29 + BRRWT30 + BRRWT31 + BRRWT32 + BRRWT33 + BRRWT34 + BRRWT35 + BRRWT36 + BRRWT37 + BRRWT38 + BRRWT39 + BRRWT40 + BRRWT41 + BRRWT42 + BRRWT43 + BRRWT44 + BRRWT45 + BRRWT46 + BRRWT47 + BRRWT48 + BRRWT49 + BRRWT50 + BRRWT51 + \\n BRRWT52 + BRRWT53 + BRRWT54 + BRRWT55 + BRRWT56 + BRRWT57 + BRRWT58 + BRRWT59 + BRRWT60 + BRRWT61 + BRRWT62 + BRRWT63 + BRRWT64 + BRRWT65 + BRRWT66 + BRRWT67 + BRRWT68 + BRRWT69 + BRRWT70 + BRRWT71 + BRRWT72 + BRRWT73 + BRRWT74 + BRRWT75 + BRRWT76 + BRRWT77 + BRRWT78 + BRRWT79 + BRRWT80 + BRRWT81 + BRRWT82 + BRRWT83 + BRRWT84 + BRRWT85 + BRRWT86 + BRRWT87 + BRRWT88 + BRRWT89 + BRRWT90 + BRRWT91 + BRRWT92 + BRRWT93 + BRRWT94 + BRRWT95 + BRRWT96` ## - weights: NWEIGHT ## Data variables: DOEID (dbl), TOTALDOL (dbl), TOTSQFT_EN (dbl), REGIONC ## (dbl) ## Variables: ## [1] &quot;DOEID&quot; &quot;TOTALDOL&quot; &quot;TOTSQFT_EN&quot; &quot;REGIONC&quot; In specifying the design, the variables option was also used to include which variables might be used in analyses. This is optional but can make your object smaller. When printing the design object or looking at the summary, the replicate weight type is re-iterated as Fay's variance method (rho= 0.5) with 96 replicates and MSE variances and the variables are included. No weight or probability summary is included as was done in some other design objects. 5.2.3 Jackknife method There are three jackknife estimators implemented in {srvyr} - Jackknife 1 (JK1), Jackknife n (JKn), and Jackknife 2 (JK2). The JK1 method can be used for unstratified designs and replicates are created by removing one PSU at a time so the number of replicates is the same as the number of PSUs. If there is no clustering, then the PSU is the ultimate sampling unit (e.g., unit). The JKn method is used for stratified designs and requires 2 or more PSUs per stratum. In this case, each replicate is created by deleting one PSU from each stratum so the number of replicates is the number of total PSUs across all strata. The JK2 method is a special case of JKn when there are exactly 2 PSUs sampled per stratum. For variance estimation, scaling constants must also be specified. The math For the JK1 method, the standard error estimate for \\(\\hat{\\theta}\\) is calculated as: \\[se(\\hat{\\theta})=\\sqrt{\\frac{R-1}{R} \\sum_{r=1}^R \\left( \\hat{\\theta}_r-\\hat{\\theta}\\right)^2}\\] The JKn method is a bit more complex but the coefficients are generally provided with restricted and public use files. For each replicate, one stratum has a PSU removed and the weights are adjusted by \\(n_h/(n_h-1)\\) where \\(n_h\\) is the number of PSUs in the stratum. The coefficients in other strata are set to 1. Denote the coefficient that results from this process for replicate \\(r\\) as \\(\\alpha_r\\) then the standard error estimate for \\(\\hat{\\theta}\\) is calculated as: \\[se(\\hat{\\theta})=\\sqrt{\\sum_{r=1}^R \\left(\\alpha_r \\hat{\\theta}_r-\\hat{\\theta}\\right)^2}\\] The syntax To specify the Jackknife method, the type would be JK1, JKn, or JK2. Additionally, the overall multiplier for JK1 is specified with the scale argument, whereas the replicate specific multiplier ($_r) is specified with the rscales argument. Consider a case for the JK1 method where the multiplier, \\((R-1)/R=19/20=0.95\\) and the dataset had WT0 for the main weight and had 20 JK1 weights indicated WT1, WT2, …, WT20, then the syntax would be des_jk1 &lt;- dat %&gt;% as_survey_rep(weights = WT0, repweights= num_range(&quot;WT&quot;, 1:20), type=&quot;JK1&quot;, mse=TRUE, scale=0.95) Consider a case for the JKn method where \\(\\alpha_r=0.1\\) for all replicates and the dataset had WT0 for the main weight and had 20 JK1 weights indicated WT1, WT2, …, WT20, then the syntax would be: des_jkn &lt;- dat %&gt;% as_survey_rep(weights = WT0, repweights= num_range(&quot;WT&quot;, 1:20), type=&quot;JKN&quot;, mse=TRUE, rscales=rep(0.1, 20)) Example The American Community Survey releases public use microdata with JK1 weights at the person and household level. This example includes data at the household level where the replicate weights are specified as WGTP1, …, WGTP80 and the main weight is WGTP4. Using the {tidycensus} package5, data is downloaded from the Census API. This request gets data for each person in each household in two Public Use Microdata Areas (PUMAs) in Durham County, NC6. The variables requested are NP (number of persons in household), BDSP (number of bedrooms), HINCP (household income), and TYPEHUGQ (type of household). By default, several other variables will come along including SERIALNO (a unique identifier for each household), SPORDER (a unique identifier for each person within each household), PUMA, ST (state), person weight (PWGTP), and the household weights (WGTP, WGTP1, …, WGTP80). Filtering to records where SPORDER=1 yields only one record per household and TYPEHUGQ=1 filters to only households and not group quarters. library(tidycensus) pums_in &lt;- get_pums(variables=c(&quot;NP&quot;, &quot;BDSP&quot;, &quot;HINCP&quot;), state=&quot;37&quot;, puma=c(&quot;01301&quot;, &quot;01302&quot;), rep_weights = &quot;housing&quot;, year=2020, survey=&quot;acs5&quot;, variables_filter=list(SPORDER=1, TYPEHUGQ=1)) ## Getting data from the 2016-2020 5-year ACS Public Use Microdata Sample ## Warning: • You have not set a Census API key. Users without a key are limited to 500 ## queries per day and may experience performance limitations. ## ℹ For best results, get a Census API key at ## http://api.census.gov/data/key_signup.html and then supply the key to the ## `census_api_key()` function to use it throughout your tidycensus session. ## This warning is displayed once per session. pums_in ## # A tibble: 4,853 × 90 ## SERIALNO SPORDER NP BDSP HINCP PUMA ST TYPEH…¹ WGTP PWGTP ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 201700090… 1 1 3 7400 01301 37 1 19 19 ## 2 201700090… 1 3 4 56700 01301 37 1 14 14 ## 3 201700091… 1 1 2 61000 01302 37 1 14 15 ## 4 201700091… 1 4 3 143000 01302 37 1 16 16 ## 5 201700091… 1 5 4 87700 01301 37 1 14 13 ## 6 201700091… 1 4 2 20500 01302 37 1 11 11 ## 7 201700091… 1 1 1 65000 01301 37 1 33 33 ## 8 201700091… 1 3 4 555000 01301 37 1 16 15 ## 9 201700091… 1 4 3 127000 01301 37 1 11 11 ## 10 201700091… 1 3 3 104260 01302 37 1 20 21 ## # … with 4,843 more rows, 80 more variables: WGTP1 &lt;dbl&gt;, WGTP2 &lt;dbl&gt;, ## # WGTP3 &lt;dbl&gt;, WGTP4 &lt;dbl&gt;, WGTP5 &lt;dbl&gt;, WGTP6 &lt;dbl&gt;, WGTP7 &lt;dbl&gt;, ## # WGTP8 &lt;dbl&gt;, WGTP9 &lt;dbl&gt;, WGTP10 &lt;dbl&gt;, WGTP11 &lt;dbl&gt;, WGTP12 &lt;dbl&gt;, ## # WGTP13 &lt;dbl&gt;, WGTP14 &lt;dbl&gt;, WGTP15 &lt;dbl&gt;, WGTP16 &lt;dbl&gt;, ## # WGTP17 &lt;dbl&gt;, WGTP18 &lt;dbl&gt;, WGTP19 &lt;dbl&gt;, WGTP20 &lt;dbl&gt;, ## # WGTP21 &lt;dbl&gt;, WGTP22 &lt;dbl&gt;, WGTP23 &lt;dbl&gt;, WGTP24 &lt;dbl&gt;, ## # WGTP25 &lt;dbl&gt;, WGTP26 &lt;dbl&gt;, WGTP27 &lt;dbl&gt;, WGTP28 &lt;dbl&gt;, … des_acs &lt;- pums_in %&gt;% as_survey_rep(weights = WGTP, repweights= num_range(&quot;WGTP&quot;, 1:80), type=&quot;JK1&quot;, mse=TRUE, scale=4/80) des_acs ## Call: Called via srvyr ## Unstratified cluster jacknife (JK1) with 80 replicates and MSE variances. ## Sampling variables: ## - repweights: `WGTP1 + WGTP2 + WGTP3 + WGTP4 + WGTP5 + WGTP6 + WGTP7 + WGTP8 + WGTP9 + WGTP10 + WGTP11 + WGTP12 + WGTP13 + WGTP14 + WGTP15 + WGTP16 + WGTP17 + WGTP18 + WGTP19 + WGTP20 + WGTP21 + WGTP22 + WGTP23 + WGTP24 + WGTP25 + WGTP26 + WGTP27 + WGTP28 + WGTP29 + WGTP30 + WGTP31 + WGTP32 + WGTP33 + WGTP34 + WGTP35 + WGTP36 + WGTP37 + WGTP38 + WGTP39 + WGTP40 + WGTP41 + WGTP42 + WGTP43 + WGTP44 + WGTP45 + WGTP46 + WGTP47 + WGTP48 + WGTP49 + WGTP50 + WGTP51 + WGTP52 + WGTP53 + WGTP54 + WGTP55 + WGTP56 + WGTP57 + \\n WGTP58 + WGTP59 + WGTP60 + WGTP61 + WGTP62 + WGTP63 + WGTP64 + WGTP65 + WGTP66 + WGTP67 + WGTP68 + WGTP69 + WGTP70 + WGTP71 + WGTP72 + WGTP73 + WGTP74 + WGTP75 + WGTP76 + WGTP77 + WGTP78 + WGTP79 + WGTP80` ## - weights: WGTP ## Data variables: SERIALNO (chr), SPORDER (dbl), NP (dbl), BDSP (dbl), ## HINCP (dbl), PUMA (chr), ST (chr), TYPEHUGQ (chr), WGTP (dbl), PWGTP ## (dbl), WGTP1 (dbl), WGTP2 (dbl), WGTP3 (dbl), WGTP4 (dbl), WGTP5 ## (dbl), WGTP6 (dbl), WGTP7 (dbl), WGTP8 (dbl), WGTP9 (dbl), WGTP10 ## (dbl), WGTP11 (dbl), WGTP12 (dbl), WGTP13 (dbl), WGTP14 (dbl), WGTP15 ## (dbl), WGTP16 (dbl), WGTP17 (dbl), WGTP18 (dbl), WGTP19 (dbl), WGTP20 ## (dbl), WGTP21 (dbl), WGTP22 (dbl), WGTP23 (dbl), WGTP24 (dbl), WGTP25 ## (dbl), WGTP26 (dbl), WGTP27 (dbl), WGTP28 (dbl), WGTP29 (dbl), WGTP30 ## (dbl), WGTP31 (dbl), WGTP32 (dbl), WGTP33 (dbl), WGTP34 (dbl), WGTP35 ## (dbl), WGTP36 (dbl), WGTP37 (dbl), WGTP38 (dbl), WGTP39 (dbl), WGTP40 ## (dbl), WGTP41 (dbl), WGTP42 (dbl), WGTP43 (dbl), WGTP44 (dbl), WGTP45 ## (dbl), WGTP46 (dbl), WGTP47 (dbl), WGTP48 (dbl), WGTP49 (dbl), WGTP50 ## (dbl), WGTP51 (dbl), WGTP52 (dbl), WGTP53 (dbl), WGTP54 (dbl), WGTP55 ## (dbl), WGTP56 (dbl), WGTP57 (dbl), WGTP58 (dbl), WGTP59 (dbl), WGTP60 ## (dbl), WGTP61 (dbl), WGTP62 (dbl), WGTP63 (dbl), WGTP64 (dbl), WGTP65 ## (dbl), WGTP66 (dbl), WGTP67 (dbl), WGTP68 (dbl), WGTP69 (dbl), WGTP70 ## (dbl), WGTP71 (dbl), WGTP72 (dbl), WGTP73 (dbl), WGTP74 (dbl), WGTP75 ## (dbl), WGTP76 (dbl), WGTP77 (dbl), WGTP78 (dbl), WGTP79 (dbl), WGTP80 ## (dbl) summary(des_acs) ## Call: Called via srvyr ## Unstratified cluster jacknife (JK1) with 80 replicates and MSE variances. ## Sampling variables: ## - repweights: `WGTP1 + WGTP2 + WGTP3 + WGTP4 + WGTP5 + WGTP6 + WGTP7 + WGTP8 + WGTP9 + WGTP10 + WGTP11 + WGTP12 + WGTP13 + WGTP14 + WGTP15 + WGTP16 + WGTP17 + WGTP18 + WGTP19 + WGTP20 + WGTP21 + WGTP22 + WGTP23 + WGTP24 + WGTP25 + WGTP26 + WGTP27 + WGTP28 + WGTP29 + WGTP30 + WGTP31 + WGTP32 + WGTP33 + WGTP34 + WGTP35 + WGTP36 + WGTP37 + WGTP38 + WGTP39 + WGTP40 + WGTP41 + WGTP42 + WGTP43 + WGTP44 + WGTP45 + WGTP46 + WGTP47 + WGTP48 + WGTP49 + WGTP50 + WGTP51 + WGTP52 + WGTP53 + WGTP54 + WGTP55 + WGTP56 + WGTP57 + \\n WGTP58 + WGTP59 + WGTP60 + WGTP61 + WGTP62 + WGTP63 + WGTP64 + WGTP65 + WGTP66 + WGTP67 + WGTP68 + WGTP69 + WGTP70 + WGTP71 + WGTP72 + WGTP73 + WGTP74 + WGTP75 + WGTP76 + WGTP77 + WGTP78 + WGTP79 + WGTP80` ## - weights: WGTP ## Data variables: SERIALNO (chr), SPORDER (dbl), NP (dbl), BDSP (dbl), ## HINCP (dbl), PUMA (chr), ST (chr), TYPEHUGQ (chr), WGTP (dbl), PWGTP ## (dbl), WGTP1 (dbl), WGTP2 (dbl), WGTP3 (dbl), WGTP4 (dbl), WGTP5 ## (dbl), WGTP6 (dbl), WGTP7 (dbl), WGTP8 (dbl), WGTP9 (dbl), WGTP10 ## (dbl), WGTP11 (dbl), WGTP12 (dbl), WGTP13 (dbl), WGTP14 (dbl), WGTP15 ## (dbl), WGTP16 (dbl), WGTP17 (dbl), WGTP18 (dbl), WGTP19 (dbl), WGTP20 ## (dbl), WGTP21 (dbl), WGTP22 (dbl), WGTP23 (dbl), WGTP24 (dbl), WGTP25 ## (dbl), WGTP26 (dbl), WGTP27 (dbl), WGTP28 (dbl), WGTP29 (dbl), WGTP30 ## (dbl), WGTP31 (dbl), WGTP32 (dbl), WGTP33 (dbl), WGTP34 (dbl), WGTP35 ## (dbl), WGTP36 (dbl), WGTP37 (dbl), WGTP38 (dbl), WGTP39 (dbl), WGTP40 ## (dbl), WGTP41 (dbl), WGTP42 (dbl), WGTP43 (dbl), WGTP44 (dbl), WGTP45 ## (dbl), WGTP46 (dbl), WGTP47 (dbl), WGTP48 (dbl), WGTP49 (dbl), WGTP50 ## (dbl), WGTP51 (dbl), WGTP52 (dbl), WGTP53 (dbl), WGTP54 (dbl), WGTP55 ## (dbl), WGTP56 (dbl), WGTP57 (dbl), WGTP58 (dbl), WGTP59 (dbl), WGTP60 ## (dbl), WGTP61 (dbl), WGTP62 (dbl), WGTP63 (dbl), WGTP64 (dbl), WGTP65 ## (dbl), WGTP66 (dbl), WGTP67 (dbl), WGTP68 (dbl), WGTP69 (dbl), WGTP70 ## (dbl), WGTP71 (dbl), WGTP72 (dbl), WGTP73 (dbl), WGTP74 (dbl), WGTP75 ## (dbl), WGTP76 (dbl), WGTP77 (dbl), WGTP78 (dbl), WGTP79 (dbl), WGTP80 ## (dbl) ## Variables: ## [1] &quot;SERIALNO&quot; &quot;SPORDER&quot; &quot;NP&quot; &quot;BDSP&quot; &quot;HINCP&quot; &quot;PUMA&quot; ## [7] &quot;ST&quot; &quot;TYPEHUGQ&quot; &quot;WGTP&quot; &quot;PWGTP&quot; &quot;WGTP1&quot; &quot;WGTP2&quot; ## [13] &quot;WGTP3&quot; &quot;WGTP4&quot; &quot;WGTP5&quot; &quot;WGTP6&quot; &quot;WGTP7&quot; &quot;WGTP8&quot; ## [19] &quot;WGTP9&quot; &quot;WGTP10&quot; &quot;WGTP11&quot; &quot;WGTP12&quot; &quot;WGTP13&quot; &quot;WGTP14&quot; ## [25] &quot;WGTP15&quot; &quot;WGTP16&quot; &quot;WGTP17&quot; &quot;WGTP18&quot; &quot;WGTP19&quot; &quot;WGTP20&quot; ## [31] &quot;WGTP21&quot; &quot;WGTP22&quot; &quot;WGTP23&quot; &quot;WGTP24&quot; &quot;WGTP25&quot; &quot;WGTP26&quot; ## [37] &quot;WGTP27&quot; &quot;WGTP28&quot; &quot;WGTP29&quot; &quot;WGTP30&quot; &quot;WGTP31&quot; &quot;WGTP32&quot; ## [43] &quot;WGTP33&quot; &quot;WGTP34&quot; &quot;WGTP35&quot; &quot;WGTP36&quot; &quot;WGTP37&quot; &quot;WGTP38&quot; ## [49] &quot;WGTP39&quot; &quot;WGTP40&quot; &quot;WGTP41&quot; &quot;WGTP42&quot; &quot;WGTP43&quot; &quot;WGTP44&quot; ## [55] &quot;WGTP45&quot; &quot;WGTP46&quot; &quot;WGTP47&quot; &quot;WGTP48&quot; &quot;WGTP49&quot; &quot;WGTP50&quot; ## [61] &quot;WGTP51&quot; &quot;WGTP52&quot; &quot;WGTP53&quot; &quot;WGTP54&quot; &quot;WGTP55&quot; &quot;WGTP56&quot; ## [67] &quot;WGTP57&quot; &quot;WGTP58&quot; &quot;WGTP59&quot; &quot;WGTP60&quot; &quot;WGTP61&quot; &quot;WGTP62&quot; ## [73] &quot;WGTP63&quot; &quot;WGTP64&quot; &quot;WGTP65&quot; &quot;WGTP66&quot; &quot;WGTP67&quot; &quot;WGTP68&quot; ## [79] &quot;WGTP69&quot; &quot;WGTP70&quot; &quot;WGTP71&quot; &quot;WGTP72&quot; &quot;WGTP73&quot; &quot;WGTP74&quot; ## [85] &quot;WGTP75&quot; &quot;WGTP76&quot; &quot;WGTP77&quot; &quot;WGTP78&quot; &quot;WGTP79&quot; &quot;WGTP80&quot; When printing the design object or looking at the summary, the replicate weight type is re-iterated as Unstratified cluster jacknife (JK1) with 80 replicates and MSE variances and the variables are included. No weight or probability summary is included as was done in some other design objects. 5.2.4 Bootstrap method In bootstrap resampling, replicates are created by selecting random samples of the PSUs with replacement. If there are \\(M\\) PSUs in the sample, then each replicate will be created by selecting a random sample of \\(M\\) PSUs with replacement. Each replicate is created independently and the weights for each replicate are adjusted to reflect the population, generally using the same method as how the analysis weight was adjusted. The math A weighted estimate for the full sample is calculated as \\(\\hat{\\theta}\\) and then a weighted estimate for each replicate is calculated as \\(\\hat{\\theta}_r\\) for \\(R\\) replicates. Then the standard error of the estimate is calculated as: \\[se(\\hat{\\theta})=\\sqrt{\\alpha \\sum_{r=1}^R \\left( \\hat{\\theta}_r-\\hat{\\theta}\\right)^2}\\] The syntax If a dataset had WT0 for the main weight, 20 bootstrap weights indicated WT1, WT2, …, WT20, and \\(\\alpha=.02\\), use the following syntax: des_bs &lt;- dat %&gt;% as_survey_rep(weights = WT0, repweights= num_range(&quot;WT&quot;, 1:20), type=&quot;bootstrap&quot;, mse=TRUE, scale=.02) Note that the scale is usually provided in documentation and is a constant, so is not provided as a variable in the tibble. Example Returning to the api example, bootstrap weights were constructed for a one cluster design. 50 replicate weights were created on a dataset apiclus1_slim which has some familiar variables including cds, dnum, fpc, and pw but now additionally includes bootstrap weights pw1, …, pw50. The scale \\((\\alpha)\\) is \\(15/(14*49)=0.02186589\\) apiclus1_slim ## # A tibble: 183 × 54 ## cds dnum fpc pw pw1 pw2 pw3 pw4 pw5 pw6 pw7 ## &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 43693776… 61 757 33.8 33.8 0 0 33.8 0 33.8 0 ## 2 43693776… 61 757 33.8 33.8 0 0 33.8 0 33.8 0 ## 3 43693776… 61 757 33.8 33.8 0 0 33.8 0 33.8 0 ## 4 43693776… 61 757 33.8 33.8 0 0 33.8 0 33.8 0 ## 5 43693776… 61 757 33.8 33.8 0 0 33.8 0 33.8 0 ## 6 43693776… 61 757 33.8 33.8 0 0 33.8 0 33.8 0 ## 7 43693776… 61 757 33.8 33.8 0 0 33.8 0 33.8 0 ## 8 43693776… 61 757 33.8 33.8 0 0 33.8 0 33.8 0 ## 9 43693776… 61 757 33.8 33.8 0 0 33.8 0 33.8 0 ## 10 43693776… 61 757 33.8 33.8 0 0 33.8 0 33.8 0 ## # … with 173 more rows, and 43 more variables: pw8 &lt;dbl&gt;, pw9 &lt;dbl&gt;, ## # pw10 &lt;dbl&gt;, pw11 &lt;dbl&gt;, pw12 &lt;dbl&gt;, pw13 &lt;dbl&gt;, pw14 &lt;dbl&gt;, ## # pw15 &lt;dbl&gt;, pw16 &lt;dbl&gt;, pw17 &lt;dbl&gt;, pw18 &lt;dbl&gt;, pw19 &lt;dbl&gt;, ## # pw20 &lt;dbl&gt;, pw21 &lt;dbl&gt;, pw22 &lt;dbl&gt;, pw23 &lt;dbl&gt;, pw24 &lt;dbl&gt;, ## # pw25 &lt;dbl&gt;, pw26 &lt;dbl&gt;, pw27 &lt;dbl&gt;, pw28 &lt;dbl&gt;, pw29 &lt;dbl&gt;, ## # pw30 &lt;dbl&gt;, pw31 &lt;dbl&gt;, pw32 &lt;dbl&gt;, pw33 &lt;dbl&gt;, pw34 &lt;dbl&gt;, ## # pw35 &lt;dbl&gt;, pw36 &lt;dbl&gt;, pw37 &lt;dbl&gt;, pw38 &lt;dbl&gt;, pw39 &lt;dbl&gt;, … des_api1_bs &lt;- apiclus1_slim %&gt;% as_survey_rep(weights=pw, repweights=pw1:pw50, type=&quot;bootstrap&quot;, scale=0.02186589, mse=TRUE) des_api1_bs ## Call: Called via srvyr ## Survey bootstrap with 50 replicates and MSE variances. ## Sampling variables: ## - repweights: `pw1 + pw2 + pw3 + pw4 + pw5 + pw6 + pw7 + pw8 + pw9 + pw10 + pw11 + pw12 + pw13 + pw14 + pw15 + pw16 + pw17 + pw18 + pw19 + pw20 + pw21 + pw22 + pw23 + pw24 + pw25 + pw26 + pw27 + pw28 + pw29 + pw30 + pw31 + pw32 + pw33 + pw34 + pw35 + pw36 + pw37 + pw38 + pw39 + pw40 + pw41 + pw42 + pw43 + pw44 + pw45 + pw46 + pw47 + pw48 + pw49 + pw50` ## - weights: pw ## Data variables: cds (chr), dnum (int), fpc (dbl), pw (dbl), pw1 (dbl), ## pw2 (dbl), pw3 (dbl), pw4 (dbl), pw5 (dbl), pw6 (dbl), pw7 (dbl), pw8 ## (dbl), pw9 (dbl), pw10 (dbl), pw11 (dbl), pw12 (dbl), pw13 (dbl), ## pw14 (dbl), pw15 (dbl), pw16 (dbl), pw17 (dbl), pw18 (dbl), pw19 ## (dbl), pw20 (dbl), pw21 (dbl), pw22 (dbl), pw23 (dbl), pw24 (dbl), ## pw25 (dbl), pw26 (dbl), pw27 (dbl), pw28 (dbl), pw29 (dbl), pw30 ## (dbl), pw31 (dbl), pw32 (dbl), pw33 (dbl), pw34 (dbl), pw35 (dbl), ## pw36 (dbl), pw37 (dbl), pw38 (dbl), pw39 (dbl), pw40 (dbl), pw41 ## (dbl), pw42 (dbl), pw43 (dbl), pw44 (dbl), pw45 (dbl), pw46 (dbl), ## pw47 (dbl), pw48 (dbl), pw49 (dbl), pw50 (dbl) summary(des_api1_bs) ## Call: Called via srvyr ## Survey bootstrap with 50 replicates and MSE variances. ## Sampling variables: ## - repweights: `pw1 + pw2 + pw3 + pw4 + pw5 + pw6 + pw7 + pw8 + pw9 + pw10 + pw11 + pw12 + pw13 + pw14 + pw15 + pw16 + pw17 + pw18 + pw19 + pw20 + pw21 + pw22 + pw23 + pw24 + pw25 + pw26 + pw27 + pw28 + pw29 + pw30 + pw31 + pw32 + pw33 + pw34 + pw35 + pw36 + pw37 + pw38 + pw39 + pw40 + pw41 + pw42 + pw43 + pw44 + pw45 + pw46 + pw47 + pw48 + pw49 + pw50` ## - weights: pw ## Data variables: cds (chr), dnum (int), fpc (dbl), pw (dbl), pw1 (dbl), ## pw2 (dbl), pw3 (dbl), pw4 (dbl), pw5 (dbl), pw6 (dbl), pw7 (dbl), pw8 ## (dbl), pw9 (dbl), pw10 (dbl), pw11 (dbl), pw12 (dbl), pw13 (dbl), ## pw14 (dbl), pw15 (dbl), pw16 (dbl), pw17 (dbl), pw18 (dbl), pw19 ## (dbl), pw20 (dbl), pw21 (dbl), pw22 (dbl), pw23 (dbl), pw24 (dbl), ## pw25 (dbl), pw26 (dbl), pw27 (dbl), pw28 (dbl), pw29 (dbl), pw30 ## (dbl), pw31 (dbl), pw32 (dbl), pw33 (dbl), pw34 (dbl), pw35 (dbl), ## pw36 (dbl), pw37 (dbl), pw38 (dbl), pw39 (dbl), pw40 (dbl), pw41 ## (dbl), pw42 (dbl), pw43 (dbl), pw44 (dbl), pw45 (dbl), pw46 (dbl), ## pw47 (dbl), pw48 (dbl), pw49 (dbl), pw50 (dbl) ## Variables: ## [1] &quot;cds&quot; &quot;dnum&quot; &quot;fpc&quot; &quot;pw&quot; &quot;pw1&quot; &quot;pw2&quot; &quot;pw3&quot; &quot;pw4&quot; &quot;pw5&quot; ## [10] &quot;pw6&quot; &quot;pw7&quot; &quot;pw8&quot; &quot;pw9&quot; &quot;pw10&quot; &quot;pw11&quot; &quot;pw12&quot; &quot;pw13&quot; &quot;pw14&quot; ## [19] &quot;pw15&quot; &quot;pw16&quot; &quot;pw17&quot; &quot;pw18&quot; &quot;pw19&quot; &quot;pw20&quot; &quot;pw21&quot; &quot;pw22&quot; &quot;pw23&quot; ## [28] &quot;pw24&quot; &quot;pw25&quot; &quot;pw26&quot; &quot;pw27&quot; &quot;pw28&quot; &quot;pw29&quot; &quot;pw30&quot; &quot;pw31&quot; &quot;pw32&quot; ## [37] &quot;pw33&quot; &quot;pw34&quot; &quot;pw35&quot; &quot;pw36&quot; &quot;pw37&quot; &quot;pw38&quot; &quot;pw39&quot; &quot;pw40&quot; &quot;pw41&quot; ## [46] &quot;pw42&quot; &quot;pw43&quot; &quot;pw44&quot; &quot;pw45&quot; &quot;pw46&quot; &quot;pw47&quot; &quot;pw48&quot; &quot;pw49&quot; &quot;pw50&quot; As with other replicate design objects, when printing the object or looking at the summary, the replicate weights are provided along with the data variables. 5.3 Understanding survey design documentation SRS, stratified, and clustered designs are the backbone of sampling designs and the features are often combined in one design. Additionally, rather than using SRS for selection, other sampling mechanisms are commonly used such as probability proportional to size (PPS), systematic sampling, or selection with unequal probabilities which are briefly described here. In PPS sampling, a size measure is constructed for each unit - perhaps the population of the PSU or the number of occupied housing units, and then units with larger size measures are more likely to be sampled. Systematic sampling is commonly used to ensure representation across a population. Units are sorted by a feature and then every \\(k\\) units are selected from a random start point so the sample is spread across the population. In addition to PPS, other unequal probabilities of selection may be used. As an example, in a study of establishments that conducts a survey every year, an establishment that recently participated (e.g., participated last year) has a reduced chance of selection in a subsequent round to reduce the burden on the establishment. To learn more about sampling designs, refer to Valliant, Dever, and Kreuter (2013), Cox et al. (2011), Cochran (1977), and Deming (1991). A common method of sampling is to stratify PSUs, select PSUs within stratum using PPS selection, and then select units within the PSUs either with SRS or PPS. Reading survey documentation is an important first step of survey analysis to understand the design and variables necessary to specify the design. Good documentation will highlight the variables necessary to specify the design. This is often found in User’s Guides, methodology, analysis guides, or technical documentation. For example, the 2017-2019 National Survey of Family Growth (NSFG)7 had a stratified multi-stage area probability sample. Counties or collections of counties were the primary sampling units which were stratified by Census region/division, size (population), and MSA status. Within each stratum, PSUs were selected via PPS. At the second stage, neighborhoods were selected within the sampled PSUs using PPS selection. At the third stage, housing units were selected within the sampled neighborhoods. At the fourth stage, a person was randomly chosen within the selected housing units among eligible persons using unequal probabilities based on person’s age and sex. The public use file does not include all these levels of selection and instead includes pseudo-strata and pseudo-clusters which are the variables used in R to specify the design. As specified on page 4 of the documentation, the stratum variable is SEST, the cluster variable is SECU, and the weight variable is WGT2017_2019. Thus, to specify this design in R, one would use the following syntax: des_nsfg &lt;- nsfgdata %&gt;% as_survey_design(ids = SECU, strata = SEST, weights = WGT2017_2019) 5.4 Exercises The American National Election Studies (ANES) collect data before and after elections approximately every 4 years around the presidential election cycle. Each year with the data release, a user’s guide is also released8. What is the syntax for specifying the analysis of the full sample post-election data? svy_anes &lt;- anes_data %&gt;% as_survey_design(weight) The General Social Survey is a survey that has been administered since 1972 on social, behavioral, and attitudinal topics. The 2016-2020 GSS Panel codebook9 provides examples of setting up syntax in SAS and Stata but not R. How would you specify the design in R? svy_gss &lt;- gss_data %&gt;% as_survey_design(ids = VPSU_2, strata = VSTRAT_2, weights = WTSSNR_2) References "],["c06.html", "Chapter 6 Descriptive analyses in srvyr", " Chapter 6 Descriptive analyses in srvyr "],["c07.html", "Chapter 7 Statistical testing", " Chapter 7 Statistical testing "],["c08.html", "Chapter 8 Modeling", " Chapter 8 Modeling "],["c09.html", "Chapter 9 Presenting results", " Chapter 9 Presenting results "],["more-to-say.html", "A More to Say", " A More to Say Yeah! I have finished my book, but I have more to say about some topics. Let me explain them in this appendix. To know more about bookdown, see https://bookdown.org. This is for testing GH Actions. "],["references.html", "References", " References "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
