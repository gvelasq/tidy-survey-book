# Understanding survey data files {#understanding-survey-data-files}

```{r}
#| include: false

library(tidyverse)
```

Reading survey documentation is an essential first step in survey analysis. Survey documentation includes technical guides, questionnaires, codebooks, errata, and additional resources. Thanks to the Internet, these files are often grouped and accessible on a survey website. Below are brief overviews of vital documentation to review. We should comprehensively review all survey documentation files to conduct our survey analysis.

## Types of survey documentation

### Technical documentation
<!-- this is adapted from chapter 05 ending -->
The technical documentation, which may be called user guides or methodology/analysis guides, will highlight the variables necessary to specify the design. 

Survey documentation can vary in its organization, thoroughness, and ease of use. We recommend focusing on key sections when beginning an analysis:

* **Introduction:** The introduction orients us to the survey. Generally, this section provides the project's background, the study's purpose, and the main research questions.
* **Study design:** The study design section describes how the survey was prepared and administered.
* **Sample:** The sample section describes the sampling of the survey: how cases were selected, any sampling error that occurred, and the limitations of the sample. This section can contain recommendations on how to use sampling weights. This documentation is critical in successfully running our analysis. More detail on sample designs is available in [Chapter 05: Specifying sample designs in srvyr](#c05).

Look for weight information, whether the survey design is strata and/or clusters/PSUs or replicate weights, and any population sizes or finite population correction. Some keywords to look out for are methodology, design, analysis guide, or technical documentation. The documentation may include syntax for SAS, SUDAAN, Stata, and/or R. It can also clarify how missing values are stored in the files. The detail contained in the technical documentation ensures that we accurately conduct our survey analysis.

### Questionnaires

A questionnaire provides details about each of the questions asked in the survey, such as question name, question wording, response options, question logic, randomizations, display specification, mode differences, and the universe (if only a subset of respondents were asked the question). 

Below, we show a question from the ANES 2020 questionnaire. This part shows a particular question's question name (`postvote_rvote`), description (Did R Vote?), full wording of the question and responses, response order, universe, question logic (if `vote_pre` = 0), and other specifications. It also includes the variable name, which can be used to link to the codebook.

![](images/questionnaire-example.jpg)

A survey may have one questionnaire or multiple, depending on its scale and scope.

### Codebooks

While a questionnaire provides information about the questions asked to respondents, the codebook contains information about variables that appear in the dataset. The codebook identifies details on the variables, such as variable names, variable label, variable meaning, codes for missing data, values labels, and value type (whether it is numeric, character, etc.).

Below, we show a question from the ANES 2020 codebook. This part shows a particular variable's name (`V202066`), question wording, value labels, universe, and associated survey question (`postvote_rvote`).

![](images/codebook-example.jpg)

It is important to review both in parallel, as questions and variables are not one-to-one. A single question may have multiple associated variables, or a single variable may summarize multiple questions. Reviewing the codebook will clarify how to analyze the variables.

### Errata
<!-- can you use errata as singular?-->
An errata documents any known errors in the survey. Be sure to review these lists before conducting any analysis. There may be explicit instructions to help avoid issues, such as letting us know to drop a case from a data file.

### Additional resources

Surveys may have additional resources, such as interviewer instructions and "show cards" held up to respondents. Review the survey website to find out what was used.

### Example: American National Election Studies (ANES) 2020 survey documentation

Let's look at the survey documentation for the American National Election Studies (ANES) 2020. The survey website is located at [https://electionstudies.org/data-center/2020-time-series-study/](https://electionstudies.org/data-center/2020-time-series-study/). 

Navigating to "User Guide and Codebook," we can download the PDF that contains the survey documentation, titled "ANES 2020 Time Series Study Full Release: User Guide and Codebook". The PDF is 796 pages long, which can be daunting, except we know to focus on the most critical sections.

#### Introduction {-}

The first section in the User Guide explains that the ANES 2020 Times Series Study is a continuation of a series of election surveys conducted since 1948. These surveys contain data on public opinion and voting behavior in U.S. presidential elections. It states that interviewers used one of three modes (web, video, or telephone). The introduction then summarizes the number of pre-election interviews (8,280) and post-election re-interviews (7,449).

#### Sample Design and Respondent Recruitment {-}

The section "Sample Design and Respondent Recruitment" describes how the survey was conducted: 

> ...a contactless, mixed-mode design.... a sequential mixed-mode design was implemented that included self-administered online surveys, live video interviews conducted online, and telephone interviews.

In addition to respondents who participated in 2016 ANES, the 2020 survey included a freshly drawn cross-section:

> The target population for the fresh cross-section was the 231 million non-institutional U.S. citizens aged 18 or older living in the 50 U.S. states or the District of Columbia.

The document continues with more details on the sample groups.

#### Data Analysis, Weights, and Variance Estimation {-}

The section "Data Analysis, Weights, and Variance Estimation" includes information on weights and strata/cluster variables. Reading through, we can find the full sample weight variables:

> For analysis of the complete set of cases using pre-election data only, including all cases and representative of the 2020 electorate, use the full sample pre-election weight, **V200010a**. For analysis including post-election data for the complete set of participants (i.e., analysis of post-election data only or a combination of pre- and post-election data), use the full sample post-election weight, **V200010b**. Additional weights are provided for analysis of subsets of the data...

The table below this paragraph provides more information about the variables, summarized below:

For weight | Use variance unit/PSU/cluster | and use variance stratum
-----------|-------------------------------|-------------------------
V200010a| V200010c| V200010d
V200010b| V200010c| V200010d

As mentioned above, we want to conduct ANES data analysis with weights to accurately represent the population. A supplemental document called ("How to Analyze ANES Survey Data")^[DeBell, Matthew. 2010. How to Analyze ANES Survey Data. ANES Technical Report Series no. nes012492. Palo Alto, CA, and Ann Arbor, MI: Stanford University and the University of Michigan] provided in the technical documentation is a 'how-to guide' to do this properly. Recall the "Sample Design and Respondent Recruitment" section:

> The target population for the fresh cross-section was the 231 million non-institutional U.S. citizens aged 18 or older living in the 50 US states or the District of Columbia.

We will use Current Population Survey (CPS) to find a number of the non-institutional U.S. citizens aged 18 or older living in the 50 U.S. states or D.C.

The information in this section gives us what we need to create the post-election survey object with {srvyr}. Specifying the appropriate (pseudo-)strata and (pseudo-)cluster variables performs the calculation of sampling errors that we need:

```{r}
#| eval: FALSE
library(tidyverse)
library(here)
library(srvyr)

anes <- read_rds(here("Data", "anes_2020.rds")) %>%
  mutate(Weight = V200010b / sum(V200010b) * 231592693)

anes_des <- anes %>%
  as_survey_design(
    weights = Weight,
    strata = V200010d,
    ids = V200010c,
    nest = TRUE
  )

summary(anes_des)
```

#### Codebook {-}

The second piece of documentation is the Codebook.

### Example: 2017-2019 National Survey of Family Growth (NSFG)

The 2017-2019 National Survey of Family Growth (NSFG)^[2017-2019 National Survey of Family Growth (NSFG): Sample Design Documentation -  https://www.cdc.gov/nchs/data/nsfg/NSFG-2017-2019-Sample-Design-Documentation-508.pdf] has a stratified multi-stage area probability sample. Counties or collections of counties were the primary sampling units which were stratified by Census region/division, size (population), and MSA status. 

Within each stratum, PSUs were selected via PPS. In the second stage, neighborhoods were selected within the sampled PSUs using PPS selection. In the third stage, housing units were selected within the sampled neighborhoods. In the fourth stage, a person was randomly chosen within the selected housing units among eligible persons using unequal probabilities based on the person's age and sex. 

The public use file does not include all these levels of selection and instead has pseudo-strata and pseudo-clusters, which are the variables used in R to specify the design. As page 4 of the documentation specifies, the stratum variable is `SEST`, the cluster variable is `SECU`, and the weight variable is `WGT2017_2019`. To specify this design in R, we would use the following syntax:

```r
des_nsfg <- nsfgdata %>%
  as_survey_design(ids = SECU, strata = SEST, weights = WGT2017_2019)
```

## Working with missing data

If a respondent does not reply to a survey question, the documentation identifies the missing data with a code. For example, a survey may have "Yes" responses coded to 1, "No" responses coded to 2, and missing responses coded to -9. When we are running analysis in R, we want to ensure that we are treating missing responses as missing data (i.e., `NA`) and not numeric data.

As survey analysts, we have to consider the implications of missing data in our analyses. For instance, we can perform listwise deletion, a method that drops all rows from a data frame with a missing value in any column, using `drop_na()` from {tidyr}. In the example tibble below, only the first row will remain:

```{r}
dat <- tibble::tribble(
  ~col1, ~col2, ~col3,
    "a",    "d",   "e",
    "b",    NA,    NA,
    "c",    NA,    "f"
  )

dat %>% 
  tidyr::drop_na()
```

However, if our data is not missing completely at random, listwise deletion may produce biased estimates (there may be a pattern of respondents who do not respond to specific questions). In these circumstances, other options are better for analysis. See Allison (2002) for more detail.
<!--TODO: I don't think it fits this chapter, but we should mention best pratices for reporting missing data-->

## Accounting for skip patterns



### Searching for public-use survey data

A common question for aspiring survey analysts is, "What are some examples of public-use survey data?". When writing this book, we asked ourselves this question to provide relevant, engaging, and high-quality examples for our readers.

A few things we considered were whether a survey had both continuous and discrete data, how difficult it was to  

* Analyze Survey Data for Free ([asdfree.com](https://asdfree.com))

### Exercises
<!--TODO: add exercises-->
<!--TODO: cite ANES, How to Analyze ANES Survey Data-->