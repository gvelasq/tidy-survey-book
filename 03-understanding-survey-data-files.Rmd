# Understanding survey data files {#understanding-survey-data-files}

<!--TODO: Add intro-->

## Reading survey documentation
<!-- this is adapted from chapter 05 ending -->
### Technical documentation
Reading survey documentation is an important first step of survey analysis. The survey documentation will highlight the variables necessary to specify the design. Crucial information can be found in User's Guides, methodology/analysis guides, or technical documentation.

Survey documentation can vary in its organization, thoroughness, and ease of use. We recommend focusing on key sections when beginning an analysis:

* **Introduction:** The introduction orients us to the survey. Generally, this section provides the background of the project, purpose of the study, and main research questions.
* **Study design:** The study design section describes how the survey was prepared and administered.
* **Sample:** The sample section describes the sampling of the survey: how cases were selected, any sampling error that occurred, and limitations of the sample. This section can contain recommendations on how to use sampling weights. This documentation is critical in successfully running our analysis. More detail on sample designs is available in [Chapter 05: Specifying sample designs in srvyr](#c05).

Look for weight information, whether the survey design is strata and/or clusters/PSUs or replicate weights, and any population sizes or finite population correction. Some keywords to look out for are methodology, design, analysis guide, or technical documentation. The documentation may include syntax for SAS, SUDAAN, Stata, and/or R. It can also clarify how missing values are stored in the files. This information provides us with the proper starting point for our survey analysis.

### Other documentation

There are other files to review beyond user guides. Thanks to the Internet, often they are grouped together and accessible on a survey website. Below are brief overviews of important documentation to review. We should do a comprehensive review of all survey documentation files to accurately and effectively conduct our survey analysis.

#### Questionnaires {-}

A questionnaire provides details about each of the questions asked in the survey, such as: question name, question wording, response options, question logic, randomizations, display specification, mode differences, and universe (if only a subset of respondents were asked the question).

<!--TODO: add image of questionnaire-->

A survey may have one questionnaire or multiple, depending on its scale and scope.

#### Codebooks {-}

While a questionnaire provides information about the questions asked to respondents, the codebook contains information about variables that appear in the dataset. The codebook identifies details on the variables, such as: variable names, variable descriptions, codes for missing data, possible values, and value type (whether it is numeric, character, etc.).

<!--TODO: add image of codebook-->

It is important to review both in parallel as questions and variables are not one-to-one. A single question may have multiple associated variables, or multiple questions may be summarized in a single variable. Reviewing the codebook will clarify how to analyze the variables.

#### Errata {-}
<!-- can you use errata as singular?-->
An errata documents any known errors in the survey. Be sure to review these lists before conducting any analysis. There may be explicit instructions to help avoid issues, such as letting us know to drop a case from a data file.

#### Additional resources {-}

Surveys may have additional resources, such as interviewer instructions and "show cards" held up to respondents. Review the survey website to find documentation on these materials.

### Example: American National Election Studies (ANES) 2020 survey documentation

Let's take a look at the survey documentation for the American National Election Studies (ANES) 2020. The survey website is located at [https://electionstudies.org/data-center/2020-time-series-study/](https://electionstudies.org/data-center/2020-time-series-study/). 

Navigating to "User Guide and Codebook", we can download the PDF that contains the survey documentation, titled "ANES 2020 Time Series Study Full Release: User Guide and Codebook". The PDF is 796 pages long, which can be daunting, except we know to focus our attention on the most critical sections.

#### Introduction {-}

The first section in the User Guide explains that the ANES 2020 Times Series Study is a continuation of a series of election surveys conducted since 1948. These surveys contain data on public opinion and voting behavior in U.S. presidential elections. It states that interviews were done by one of three modes (web, video, or telephone) and summarizes the number of pre-election interviews (8,280) and post-election re-interviews (7,449).

#### Sample Design and Respondent Recruitment {-}

The section "Sample Design and Respondent Recruitment" describes how the survey was conducted: 

> ...a contactless, mixed-mode design.... a sequential mixed-mode design was implemented that included self-administered online surveys, live video interviews conducted online, and telephone interviews.

In addition to respondents who participated in 2016 ANES, the 2020 survey included a freshly drawn cross-section:

> The target population for the fresh cross-section was the 231 million non-institutional U.S. citizens aged 18 or older living in the 50 US states or the District of Columbia.

The document continues with more details on the sample groups.

#### Data Analysis, Weights, and Variance Estimation {-}

The section "Data Analysis, Weights, and Variance Estimation" includes information on weights and strata/cluster variables. Reading through, we can find the full sample weight variables:

> For analysis of the complete set of cases using pre-election data only, including all cases and representative of the 2020 electorate, use the full sample pre-election weight, **V200010a**. For analysis including post-election data for the complete set of participants (i.e., analysis of post-election data only or a combination of pre- and post-election data), use the full sample post-election weight, **V200010b**. Additional weights are provided for analysis of subsets of the data...

The table below this paragraph provides more information about the variables, summarized below:

For weight | Use variance unit/PSU/cluster | and use variance stratum
-----------|-------------------------------|-------------------------
V200010a| V200010c| V200010d
V200010b| V200010c| V200010d

As mentioned above, we want to conduct ANES data analysis with weights to accurately represent the population. A supplemental document called ["How to Analyze ANES Survey Data"]^(DeBell, Matthew. 2010. How to Analyze ANES Survey Data. ANES Technical Report Series no. nes012492. Palo Alto, CA, and Ann Arbor, MI: Stanford University and the University of Michigan) provided in the technical documentation is a 'how-to guide' to do this properly. Recall that "Sample Design and Respondent Recruitment" section mentioned:

> The target population for the fresh cross-section was the 231 million non-institutional U.S. citizens aged 18 or older living in the 50 US states or the District of Columbia.

We will use Current Population Survey (CPS) to find a number for the non-institutional U.S. citizens aged 18 or older living in the 50 U.S. state or D.C.

The information in this section gives us what we need to create the post-election survey object with {srvyr}. Specifying the appropriate (pseudo-)strata and (pseudo-)cluster variables performs the calculation of sampling errors that we need:

```{r}
#| eval: FALSE
library(tidyverse)
library(here)
library(srvyr)

anes <- read_rds(here("Data", "anes_2020.rds")) %>%
  mutate(Weight = V200010b / sum(V200010b) * 231592693)

anes_des <- anes %>%
  as_survey_design(
    weights = Weight,
    strata = V200010d,
    ids = V200010c,
    nest = TRUE
  )

summary(anes_des)
```

#### Codebook {-}

The section below the 
The codebook also lets us know how missing values are coded (in this case, as `-8`).

### Example: 2017-2019 National Survey of Family Growth (NSFG)

The 2017-2019 National Survey of Family Growth (NSFG)^[2017-2019 National Survey of Family Growth (NSFG): Sample Design Documentation -  https://www.cdc.gov/nchs/data/nsfg/NSFG-2017-2019-Sample-Design-Documentation-508.pdf] has a stratified multi-stage area probability sample. Counties or collections of counties were the primary sampling units which were stratified by Census region/division, size (population), and MSA status. Within each stratum, PSUs were selected via PPS. At the second stage, neighborhoods were selected within the sampled PSUs using PPS selection. At the third stage, housing units were selected within the sampled neighborhoods. At the fourth stage, a person was randomly chosen within the selected housing units among eligible persons using unequal probabilities based on person's age and sex. 

The public use file does not include all these levels of selection and instead includes pseudo-strata and pseudo-clusters which are the variables used in R to specify the design. As specified on page 4 of the documentation, the stratum variable is `SEST`, the cluster variable is `SECU`, and the weight variable is `WGT2017_2019`. To specify this design in R, we would use the following syntax:

```r
des_nsfg <- nsfgdata %>%
  as_survey_design(ids = SECU, strata = SEST, weights = WGT2017_2019)
```

## Working with missing data

If a respondent does not reply to a survey question, we indicate the missing data with a code in the data file. For example, a "Yes" response can be coded to 1, a "No" response to 2, and a missing response to 9. When we are running analysis in R, we want to ensure that we are treating missing responses as missing data (i.e., `NA`) and not numeric data.

As survey analysts, we have to consider the implications of missing data in our analyses. For instance, we can perform listwise deletion, a method that drops all rows from a data frame that have a missing value in any column, using `drop_na()` from {tidyr}. In the example tibble below, only the first row will remain:

```{r}
dat <- tibble::tribble(
  ~col1, ~col2, ~col3,
    "a",    "d",   "e",
    "b",    NA,    NA,
    "c",    NA,    "f"
  )

dat %>% 
  tidyr::drop_na()
```

However, if our data is not missing completely at random, listwise deletion may produce biased estimates (there may be a pattern of respondents who do not respond to certain questions). In these circumstances, other options are better for analysis. See Allison (2002) for more detail.
<!--TODO: I don't think it fits this chapter, but we should mention best pratices for reporting missing data-->

## Accounting for skip patterns



### Searching for public-use survey data

A common question that comes up for aspiring survey analysts is, "What are some examples of public-use survey data?". When writing this book, we asked ourselves this question to provide relevant, interesting, and high-quality examples for our readers.

A few things we considered were whether a survey had both continuous and discrete data, how difficult it was to  

* Analyze Survey Data for Free ([asdfree.com](https://asdfree.com))

### Exercises


<!--TODO: cite ANES, How to Analyze ANES Survey Data-->